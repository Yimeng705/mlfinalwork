INFO:root:Namespace(model_name='ADRec', model_mode='')
INFO:root:--------------------------------------------- BEGIN: 2025-12-19 22:19:00 ---------------------------------------------
INFO:root:
===============================================
 Arguments              | Values               
===============================================
 batch_size             | 256                 
 ce_loss_weight         | 0.3                 
 cfg_dropout_rate       | 0.1                 
 cfg_scale              | 1.5                 
 data_appendix          |                     
 dataset                | Grocery_and_Gourm...
 diffusion_loss_weight  | 0.7                 
 diffusion_steps        | 50                  
 dropout                | 0.3                 
 early_stop             | 20                  
 emb_size               | 128                 
 epoch                  | 100                 
 eval_batch_size        | 256                 
 gpu                    | 0                   
 hidden_size            | 128                 
 history_max            | 20                  
 l2                     | 1e-05               
 lambda_uncertainty     | 0.001               
 lr                     | 0.0005              
 main_metric            |                     
 noise_schedule         | linear              
 num_blocks             | 4                   
 num_heads              | 4                   
 num_neg                | 1                   
 num_workers            | 5                   
 optimizer              | Adam                
 random_seed            | 0                   
 rescale_timesteps      | False               
 save_final_results     | 1                   
 test_all               | 0                   
 topk                   | 5,10,20,50          
 use_partial_generation | 1                   
===============================================
INFO:root:Device: cpu
INFO:root:Load corpus from data/Grocery_and_Gourmet_Food\SeqReader.pkl
INFO:root:#params: 2300416
INFO:root:ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
        (3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (transformer): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=512, bias=True)
            (dropout): Dropout(p=0.3, inplace=False)
            (linear2): Linear(in_features=512, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.3, inplace=False)
            (dropout2): Dropout(p=0.3, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=512, bias=True)
            (dropout): Dropout(p=0.3, inplace=False)
            (linear2): Linear(in_features=512, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.3, inplace=False)
            (dropout2): Dropout(p=0.3, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=512, bias=True)
            (dropout): Dropout(p=0.3, inplace=False)
            (linear2): Linear(in_features=512, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.3, inplace=False)
            (dropout2): Dropout(p=0.3, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=512, bias=True)
            (dropout): Dropout(p=0.3, inplace=False)
            (linear2): Linear(in_features=512, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.3, inplace=False)
            (dropout2): Dropout(p=0.3, inplace=False)
          )
        )
      )
      (position_embeddings): Embedding(1000, 128)
    )
  )
  (ce_loss): CrossEntropyLoss()
)
INFO:root:Test Before Training: (HR@5:0.0497,NDCG@5:0.0293,HR@10:0.1015,NDCG@10:0.0457,HR@20:0.2071,NDCG@20:0.0721,HR@50:0.5092,NDCG@50:0.1311)
INFO:root:Optimizer: Adam
INFO:root:Loss is Nan. Stop training at 1.

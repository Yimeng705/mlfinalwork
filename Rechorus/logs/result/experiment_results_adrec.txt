开始运行所有实验...
========================
1. 模型对比实验 - Grocery_and_Gourmet_Food 数据集
-------------------------------------------------
运行 ADRec...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 17:24:02 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 100                 
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5522 [6.5 s]	dev=(HR@5:0.2346,NDCG@5:0.1531) [6.9 s] *
Epoch 2     loss=0.3603 [7.6 s]	dev=(HR@5:0.2596,NDCG@5:0.1766) [7.2 s] *
Epoch 3     loss=0.2605 [5.3 s]	dev=(HR@5:0.2676,NDCG@5:0.1856) [7.0 s] *
Epoch 4     loss=0.1924 [5.6 s]	dev=(HR@5:0.2666,NDCG@5:0.1868) [7.1 s] *
Epoch 5     loss=0.1457 [6.9 s]	dev=(HR@5:0.2671,NDCG@5:0.1872) [7.6 s] *
Epoch 6     loss=0.1128 [6.2 s]	dev=(HR@5:0.2616,NDCG@5:0.1839) [7.4 s] *
Epoch 7     loss=0.0909 [7.1 s]	dev=(HR@5:0.2644,NDCG@5:0.1858) [7.0 s] *
Epoch 8     loss=0.0770 [6.7 s]	dev=(HR@5:0.2639,NDCG@5:0.1845) [7.3 s] *
Epoch 9     loss=0.0653 [7.6 s]	dev=(HR@5:0.2599,NDCG@5:0.1827) [7.3 s] *
Epoch 10    loss=0.4772 [10.8 s]	dev=(HR@5:0.2551,NDCG@5:0.1751) [7.4 s] *
Epoch 11    loss=0.4624 [8.7 s]	dev=(HR@5:0.2522,NDCG@5:0.1723) [8.1 s] *
Epoch 12    loss=0.4587 [9.9 s]	dev=(HR@5:0.2525,NDCG@5:0.1721) [7.4 s] *
Epoch 13    loss=0.4590 [10.5 s]	dev=(HR@5:0.2526,NDCG@5:0.1720) [7.6 s] *
Epoch 14    loss=0.4584 [10.1 s]	dev=(HR@5:0.2535,NDCG@5:0.1723) [8.1 s] *
Epoch 15    loss=0.5267 [12.4 s]	dev=(HR@5:0.2558,NDCG@5:0.1703) [7.3 s] *
Epoch 16    loss=0.4534 [10.1 s]	dev=(HR@5:0.2682,NDCG@5:0.1783) [7.4 s] *
Epoch 17    loss=0.4325 [10.9 s]	dev=(HR@5:0.2712,NDCG@5:0.1788) [7.4 s] *
Epoch 18    loss=0.4261 [12.3 s]	dev=(HR@5:0.2684,NDCG@5:0.1784) [7.5 s] *
Epoch 19    loss=0.4196 [9.0 s]	dev=(HR@5:0.2684,NDCG@5:0.1792) [7.3 s] *
Epoch 20    loss=0.4185 [9.8 s]	dev=(HR@5:0.2673,NDCG@5:0.1809) [7.4 s] *
Epoch 21    loss=0.4115 [11.2 s]	dev=(HR@5:0.2673,NDCG@5:0.1793) [7.4 s] *
Epoch 22    loss=0.4128 [11.6 s]	dev=(HR@5:0.2693,NDCG@5:0.1822) [7.5 s] *
Epoch 23    loss=0.4113 [10.6 s]	dev=(HR@5:0.2708,NDCG@5:0.1822) [7.8 s] *
Epoch 24    loss=0.4101 [11.9 s]	dev=(HR@5:0.2671,NDCG@5:0.1802) [8.0 s] *
Epoch 25    loss=0.4080 [11.2 s]	dev=(HR@5:0.2671,NDCG@5:0.1775) [7.4 s] *
Epoch 26    loss=0.4069 [11.8 s]	dev=(HR@5:0.2712,NDCG@5:0.1808) [7.4 s] *
Epoch 27    loss=0.4081 [10.3 s]	dev=(HR@5:0.2684,NDCG@5:0.1780) [8.0 s] *
Epoch 28    loss=0.4067 [11.4 s]	dev=(HR@5:0.2689,NDCG@5:0.1790) [7.3 s] *
Epoch 29    loss=0.4062 [12.2 s]	dev=(HR@5:0.2706,NDCG@5:0.1796) [8.0 s] *
Epoch 30    loss=0.4029 [10.7 s]	dev=(HR@5:0.2702,NDCG@5:0.1799) [8.0 s] *
Epoch 31    loss=0.4040 [13.4 s]	dev=(HR@5:0.2727,NDCG@5:0.1825) [8.4 s] *
Epoch 32    loss=0.4044 [11.9 s]	dev=(HR@5:0.2693,NDCG@5:0.1792) [7.8 s] *
Epoch 33    loss=0.4027 [10.4 s]	dev=(HR@5:0.2712,NDCG@5:0.1802) [8.2 s] *
Epoch 34    loss=0.4024 [12.5 s]	dev=(HR@5:0.2700,NDCG@5:0.1802) [8.0 s] *
Epoch 35    loss=0.3996 [12.1 s]	dev=(HR@5:0.2733,NDCG@5:0.1822) [8.0 s] *
Epoch 36    loss=0.4004 [13.0 s]	dev=(HR@5:0.2680,NDCG@5:0.1789) [7.8 s] *
Epoch 37    loss=0.4020 [11.9 s]	dev=(HR@5:0.2715,NDCG@5:0.1804) [9.2 s] *
Epoch 38    loss=0.4015 [9.8 s]	dev=(HR@5:0.2748,NDCG@5:0.1828) [7.8 s] *
Epoch 39    loss=0.4001 [12.1 s]	dev=(HR@5:0.2707,NDCG@5:0.1811) [7.4 s] *
Epoch 40    loss=0.3984 [12.2 s]	dev=(HR@5:0.2726,NDCG@5:0.1833) [7.5 s] *
Epoch 41    loss=0.4000 [9.9 s]	dev=(HR@5:0.2671,NDCG@5:0.1785) [7.6 s] *
Epoch 42    loss=0.3989 [8.9 s]	dev=(HR@5:0.2694,NDCG@5:0.1804) [7.2 s] *
Epoch 43    loss=0.3991 [11.4 s]	dev=(HR@5:0.2647,NDCG@5:0.1769) [7.7 s] *
Epoch 44    loss=0.3989 [9.1 s]	dev=(HR@5:0.2683,NDCG@5:0.1797) [7.4 s] *
Epoch 45    loss=0.3972 [12.0 s]	dev=(HR@5:0.2701,NDCG@5:0.1804) [7.3 s] *
Epoch 46    loss=0.3990 [12.2 s]	dev=(HR@5:0.2663,NDCG@5:0.1769) [8.1 s] *
Epoch 47    loss=0.3982 [13.2 s]	dev=(HR@5:0.2680,NDCG@5:0.1781) [7.8 s] *
Epoch 48    loss=0.3988 [12.5 s]	dev=(HR@5:0.2665,NDCG@5:0.1764) [7.5 s] *
Epoch 49    loss=0.3964 [11.2 s]	dev=(HR@5:0.2725,NDCG@5:0.1815) [7.5 s] *
Epoch 50    loss=0.3983 [12.4 s]	dev=(HR@5:0.2724,NDCG@5:0.1824) [7.6 s] *
Epoch 51    loss=0.3972 [11.7 s]	dev=(HR@5:0.2711,NDCG@5:0.1817) [7.5 s] *
Epoch 52    loss=0.3960 [9.8 s]	dev=(HR@5:0.2711,NDCG@5:0.1813) [7.1 s] *
Epoch 53    loss=0.3970 [12.6 s]	dev=(HR@5:0.2693,NDCG@5:0.1790) [7.3 s] *
Epoch 54    loss=0.3954 [11.1 s]	dev=(HR@5:0.2699,NDCG@5:0.1824) [8.0 s] *
Epoch 55    loss=0.3946 [11.1 s]	dev=(HR@5:0.2674,NDCG@5:0.1784) [7.5 s] *
Epoch 56    loss=0.3956 [10.2 s]	dev=(HR@5:0.2700,NDCG@5:0.1799) [8.0 s] *
Epoch 57    loss=0.3961 [13.0 s]	dev=(HR@5:0.2733,NDCG@5:0.1806) [8.0 s] *
Epoch 58    loss=0.3945 [11.9 s]	dev=(HR@5:0.2702,NDCG@5:0.1810) [7.2 s] *
Epoch 59    loss=0.3956 [11.5 s]	dev=(HR@5:0.2680,NDCG@5:0.1791) [7.6 s] *
Epoch 60    loss=0.3958 [10.2 s]	dev=(HR@5:0.2673,NDCG@5:0.1789) [7.8 s] *
Epoch 61    loss=0.3949 [12.0 s]	dev=(HR@5:0.2693,NDCG@5:0.1790) [7.4 s] *
Epoch 62    loss=0.3959 [11.8 s]	dev=(HR@5:0.2714,NDCG@5:0.1814) [7.3 s] *
Epoch 63    loss=0.3957 [10.0 s]	dev=(HR@5:0.2679,NDCG@5:0.1789) [8.2 s] *
Epoch 64    loss=0.3948 [13.0 s]	dev=(HR@5:0.2706,NDCG@5:0.1810) [7.4 s] *
Epoch 65    loss=0.3953 [12.6 s]	dev=(HR@5:0.2678,NDCG@5:0.1799) [7.4 s] *
Epoch 66    loss=0.3923 [12.9 s]	dev=(HR@5:0.2693,NDCG@5:0.1798) [7.4 s] *
Epoch 67    loss=0.3961 [13.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1803) [7.6 s] *
Epoch 68    loss=0.3923 [11.3 s]	dev=(HR@5:0.2706,NDCG@5:0.1815) [7.6 s] *
Epoch 69    loss=0.3947 [11.9 s]	dev=(HR@5:0.2675,NDCG@5:0.1791) [7.6 s] *
Epoch 70    loss=0.3943 [11.5 s]	dev=(HR@5:0.2694,NDCG@5:0.1803) [8.1 s] *
Epoch 71    loss=0.3927 [9.3 s]	dev=(HR@5:0.2695,NDCG@5:0.1811) [7.4 s] *
Epoch 72    loss=0.3936 [10.9 s]	dev=(HR@5:0.2702,NDCG@5:0.1812) [7.7 s] *
Epoch 73    loss=0.3957 [11.8 s]	dev=(HR@5:0.2706,NDCG@5:0.1808) [7.5 s] *
Epoch 74    loss=0.3926 [11.0 s]	dev=(HR@5:0.2697,NDCG@5:0.1808) [7.6 s] *
Epoch 75    loss=0.3940 [12.8 s]	dev=(HR@5:0.2703,NDCG@5:0.1814) [7.3 s] *
Epoch 76    loss=0.3944 [13.0 s]	dev=(HR@5:0.2703,NDCG@5:0.1815) [7.4 s] *
Epoch 77    loss=0.3923 [10.6 s]	dev=(HR@5:0.2695,NDCG@5:0.1806) [7.3 s] *
Epoch 78    loss=0.3920 [11.3 s]	dev=(HR@5:0.2686,NDCG@5:0.1815) [7.3 s] *
Epoch 79    loss=0.3935 [12.0 s]	dev=(HR@5:0.2680,NDCG@5:0.1792) [7.4 s] *
Epoch 80    loss=0.3935 [10.7 s]	dev=(HR@5:0.2703,NDCG@5:0.1811) [7.9 s] *
Epoch 81    loss=0.3914 [8.7 s]	dev=(HR@5:0.2708,NDCG@5:0.1808) [7.6 s] *
Epoch 82    loss=0.3937 [11.3 s]	dev=(HR@5:0.2718,NDCG@5:0.1810) [7.5 s] *
Epoch 83    loss=0.3937 [12.1 s]	dev=(HR@5:0.2740,NDCG@5:0.1819) [7.8 s] *
Epoch 84    loss=0.3921 [12.2 s]	dev=(HR@5:0.2663,NDCG@5:0.1780) [7.5 s] *
Epoch 85    loss=0.3915 [12.0 s]	dev=(HR@5:0.2701,NDCG@5:0.1806) [7.9 s] *
Epoch 86    loss=0.3935 [10.4 s]	dev=(HR@5:0.2667,NDCG@5:0.1787) [7.6 s] *
Epoch 87    loss=0.3939 [11.3 s]	dev=(HR@5:0.2674,NDCG@5:0.1798) [7.4 s] *
Epoch 88    loss=0.3929 [11.9 s]	dev=(HR@5:0.2667,NDCG@5:0.1789) [7.9 s] *
Epoch 89    loss=0.3919 [13.5 s]	dev=(HR@5:0.2684,NDCG@5:0.1800) [7.8 s] *
Epoch 90    loss=0.3914 [12.2 s]	dev=(HR@5:0.2696,NDCG@5:0.1799) [7.3 s] *
Epoch 91    loss=0.3927 [12.3 s]	dev=(HR@5:0.2689,NDCG@5:0.1797) [7.5 s] *
Epoch 92    loss=0.3909 [10.2 s]	dev=(HR@5:0.2691,NDCG@5:0.1807) [7.5 s] *
Epoch 93    loss=0.3936 [11.7 s]	dev=(HR@5:0.2679,NDCG@5:0.1795) [7.4 s] *
Epoch 94    loss=0.3923 [12.3 s]	dev=(HR@5:0.2712,NDCG@5:0.1810) [7.6 s] *
Epoch 95    loss=0.3929 [8.5 s]	dev=(HR@5:0.2693,NDCG@5:0.1789) [7.0 s] *
Epoch 96    loss=0.3921 [10.6 s]	dev=(HR@5:0.2691,NDCG@5:0.1798) [7.7 s] *
Epoch 97    loss=0.3936 [10.7 s]	dev=(HR@5:0.2671,NDCG@5:0.1789) [7.8 s] *
Epoch 98    loss=0.3910 [11.5 s]	dev=(HR@5:0.2701,NDCG@5:0.1802) [7.5 s] *
Epoch 99    loss=0.3925 [12.0 s]	dev=(HR@5:0.2691,NDCG@5:0.1795) [7.3 s] *
Epoch 100   loss=0.3911 [12.5 s]	dev=(HR@5:0.2682,NDCG@5:0.1791) [8.1 s] *
Best Iter(dev)=    5	 dev=(HR@5:0.2671,NDCG@5:0.1872) [1854.2 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.2682,NDCG@5:0.1791,HR@10:0.3943,NDCG@10:0.2197,HR@20:0.5316,NDCG@20:0.2544,HR@50:0.7339,NDCG@50:0.2945)
Test After Training: (HR@5:0.2306,NDCG@5:0.1501,HR@10:0.3434,NDCG@10:0.1865,HR@20:0.4712,NDCG@20:0.2187,HR@50:0.6782,NDCG@50:0.2597)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 17:55:39 ---------------------------------------------
1. 模型对比实验 - MovieLens_1M 数据集
-------------------------------------
运行 ADRec...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 17:55:42 ---------------------------------------------
======================================
 Arguments             | Values       
======================================
 batch_size            | 256         
 ce_loss_weight        | 0.3         
 cfg_dropout_rate      | 0.1         
 cfg_scale             | 1.2         
 data_appendix         |             
 dataset               | MovieLens_1M
 diffusion_loss_weight | 0.7         
 diffusion_steps       | 50          
 dropout               | 0.3         
 early_stop            | 100         
 emb_size              | 128         
 epoch                 | 100         
 eval_batch_size       | 256         
 gpu                   | 0           
 hidden_size           | 128         
 history_max           | 20          
 independent_diffusion | False       
 l2                    | 1e-05       
 lambda_uncertainty    | 0.001       
 lr                    | 0.0005      
 main_metric           |             
 noise_schedule        | linear      
 num_blocks            | 4           
 num_neg               | 1           
 num_workers           | 5           
 optimizer             | Adam        
 pretrain_epochs       | 10          
 random_seed           | 0           
 rescale_timesteps     | False       
 save_final_results    | 1           
 test_all              | 0           
 topk                  | 5,10,20,50  
 training_stage        | stage1      
 warmup_epochs         | 5           
======================================
Device: cuda
Reading data from "data/", dataset = "MovieLens_1M" 
Counting dataset statistics...
"# user": 6032, "# item": 3125, "# entry": 574197
Appending history info...
Save corpus to data/MovieLens_1M/SeqReader.pkl
#params: 400384
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(3126, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                            | 0/2562 [00:00<?, ?it/s]
Test Before Training: (HR@5:0.0470,NDCG@5:0.0276,HR@10:0.0981,NDCG@10:0.0438,HR@20:0.1935,NDCG@20:0.0676,HR@50:0.4962,NDCG@50:0.1267)
Optimizer: Adam
Epoch 1     loss=0.2985 [36.1 s]	dev=(HR@5:0.4005,NDCG@5:0.2713) [1.6 s] *
Epoch 2     loss=0.2035 [36.9 s]	dev=(HR@5:0.4106,NDCG@5:0.2817) [1.7 s] *
Epoch 3     loss=0.1874 [38.0 s]	dev=(HR@5:0.4075,NDCG@5:0.2840) [1.8 s] *
Epoch 4     loss=0.1792 [38.8 s]	dev=(HR@5:0.4087,NDCG@5:0.2832) [1.7 s] *
Epoch 5     loss=0.1745 [37.6 s]	dev=(HR@5:0.4016,NDCG@5:0.2840) [1.7 s] *
Epoch 6     loss=0.1696 [30.5 s]	dev=(HR@5:0.4009,NDCG@5:0.2806) [1.9 s] *
Epoch 7     loss=0.1656 [29.6 s]	dev=(HR@5:0.4067,NDCG@5:0.2804) [1.7 s] *
Epoch 8     loss=0.1622 [34.5 s]	dev=(HR@5:0.4157,NDCG@5:0.2873) [1.6 s] *
Epoch 9     loss=0.1593 [36.5 s]	dev=(HR@5:0.4055,NDCG@5:0.2809) [1.6 s] *
Epoch 10    loss=0.2815 [56.2 s]	dev=(HR@5:0.4145,NDCG@5:0.2878) [2.3 s] *
Epoch 11    loss=0.2796 [57.3 s]	dev=(HR@5:0.4173,NDCG@5:0.2898) [1.9 s] *
Epoch 12    loss=0.2785 [47.6 s]	dev=(HR@5:0.4192,NDCG@5:0.2901) [1.8 s] *
Epoch 13    loss=0.2778 [54.1 s]	dev=(HR@5:0.4215,NDCG@5:0.2916) [2.0 s] *
Epoch 14    loss=0.2780 [54.7 s]	dev=(HR@5:0.4215,NDCG@5:0.2920) [1.8 s] *
Epoch 15    loss=0.2724 [56.2 s]	dev=(HR@5:0.4079,NDCG@5:0.2827) [2.1 s] *
Epoch 16    loss=0.2621 [59.4 s]	dev=(HR@5:0.4137,NDCG@5:0.2875) [1.9 s] *
Epoch 17    loss=0.2551 [56.4 s]	dev=(HR@5:0.4173,NDCG@5:0.2911) [1.8 s] *
Epoch 18    loss=0.2512 [56.9 s]	dev=(HR@5:0.4153,NDCG@5:0.2865) [1.9 s] *
Epoch 19    loss=0.2474 [54.9 s]	dev=(HR@5:0.4114,NDCG@5:0.2860) [1.9 s] *
Epoch 20    loss=0.2443 [50.6 s]	dev=(HR@5:0.4145,NDCG@5:0.2910) [1.7 s] *
Epoch 21    loss=0.2428 [61.7 s]	dev=(HR@5:0.4098,NDCG@5:0.2877) [2.0 s] *
Epoch 22    loss=0.2403 [64.4 s]	dev=(HR@5:0.4009,NDCG@5:0.2786) [2.5 s] *
Epoch 23    loss=0.2380 [55.8 s]	dev=(HR@5:0.4071,NDCG@5:0.2833) [1.9 s] *
Epoch 24    loss=0.2368 [59.6 s]	dev=(HR@5:0.3962,NDCG@5:0.2755) [2.4 s] *
Epoch 25    loss=0.2347 [60.2 s]	dev=(HR@5:0.4009,NDCG@5:0.2799) [1.9 s] *
Epoch 26    loss=0.2327 [56.2 s]	dev=(HR@5:0.4036,NDCG@5:0.2808) [2.0 s] *
Epoch 27    loss=0.2322 [57.4 s]	dev=(HR@5:0.4083,NDCG@5:0.2833) [2.4 s] *
Epoch 28    loss=0.2307 [45.2 s]	dev=(HR@5:0.3997,NDCG@5:0.2750) [1.9 s] *
Epoch 29    loss=0.2290 [52.1 s]	dev=(HR@5:0.3993,NDCG@5:0.2789) [2.0 s] *
Epoch 30    loss=0.2276 [53.7 s]	dev=(HR@5:0.4059,NDCG@5:0.2786) [2.3 s] *
Epoch 31    loss=0.2273 [56.5 s]	dev=(HR@5:0.4048,NDCG@5:0.2797) [1.9 s] *
Epoch 32    loss=0.2276 [58.1 s]	dev=(HR@5:0.4024,NDCG@5:0.2777) [2.1 s] *
Epoch 33    loss=0.2261 [62.7 s]	dev=(HR@5:0.4020,NDCG@5:0.2759) [1.8 s] *
Epoch 34    loss=0.2261 [60.2 s]	dev=(HR@5:0.4106,NDCG@5:0.2786) [1.8 s] *
Epoch 35    loss=0.2247 [59.6 s]	dev=(HR@5:0.3962,NDCG@5:0.2744) [2.0 s] *
Epoch 36    loss=0.2238 [56.1 s]	dev=(HR@5:0.3993,NDCG@5:0.2747) [1.8 s] *
Epoch 37    loss=0.2245 [54.8 s]	dev=(HR@5:0.4044,NDCG@5:0.2755) [2.0 s] *
Epoch 38    loss=0.2231 [53.5 s]	dev=(HR@5:0.4126,NDCG@5:0.2812) [1.8 s] *
Epoch 39    loss=0.2228 [55.8 s]	dev=(HR@5:0.3977,NDCG@5:0.2705) [1.9 s] *
Epoch 40    loss=0.2218 [58.5 s]	dev=(HR@5:0.4048,NDCG@5:0.2722) [1.8 s] *
Epoch 41    loss=0.2223 [56.7 s]	dev=(HR@5:0.4048,NDCG@5:0.2760) [2.0 s] *
Epoch 42    loss=0.2222 [60.3 s]	dev=(HR@5:0.4040,NDCG@5:0.2780) [2.0 s] *
Epoch 43    loss=0.2208 [60.4 s]	dev=(HR@5:0.4040,NDCG@5:0.2779) [2.0 s] *
Epoch 44    loss=0.2207 [57.3 s]	dev=(HR@5:0.3989,NDCG@5:0.2763) [2.0 s] *
Epoch 45    loss=0.2213 [60.8 s]	dev=(HR@5:0.4016,NDCG@5:0.2761) [2.2 s] *
Epoch 46    loss=0.2207 [59.6 s]	dev=(HR@5:0.4001,NDCG@5:0.2757) [1.9 s] *
Epoch 47    loss=0.2211 [55.8 s]	dev=(HR@5:0.4016,NDCG@5:0.2724) [1.9 s] *
Epoch 48    loss=0.2206 [59.4 s]	dev=(HR@5:0.4016,NDCG@5:0.2746) [1.9 s] *
Epoch 49    loss=0.2199 [56.2 s]	dev=(HR@5:0.3907,NDCG@5:0.2706) [2.3 s] *
Epoch 50    loss=0.2191 [58.3 s]	dev=(HR@5:0.3962,NDCG@5:0.2744) [1.8 s] *
Epoch 51    loss=0.2197 [54.3 s]	dev=(HR@5:0.4024,NDCG@5:0.2780) [1.9 s] *
Epoch 52    loss=0.2186 [53.4 s]	dev=(HR@5:0.3919,NDCG@5:0.2697) [1.9 s] *
Epoch 53    loss=0.2177 [62.2 s]	dev=(HR@5:0.3938,NDCG@5:0.2725) [1.9 s] *
Epoch 54    loss=0.2188 [57.9 s]	dev=(HR@5:0.3981,NDCG@5:0.2758) [1.8 s] *
Epoch 55    loss=0.2183 [60.6 s]	dev=(HR@5:0.3946,NDCG@5:0.2734) [1.9 s] *
Epoch 56    loss=0.2180 [58.5 s]	dev=(HR@5:0.4024,NDCG@5:0.2762) [2.2 s] *
Epoch 57    loss=0.2174 [51.7 s]	dev=(HR@5:0.3985,NDCG@5:0.2748) [2.2 s] *
Epoch 58    loss=0.2178 [51.3 s]	dev=(HR@5:0.4009,NDCG@5:0.2767) [1.8 s] *
Epoch 59    loss=0.2176 [56.1 s]	dev=(HR@5:0.3938,NDCG@5:0.2733) [2.0 s] *
Epoch 60    loss=0.2176 [56.0 s]	dev=(HR@5:0.4024,NDCG@5:0.2774) [1.8 s] *
Epoch 61    loss=0.2180 [59.5 s]	dev=(HR@5:0.3895,NDCG@5:0.2728) [1.9 s] *
Epoch 62    loss=0.2193 [58.7 s]	dev=(HR@5:0.4005,NDCG@5:0.2786) [1.9 s] *
Epoch 63    loss=0.2166 [56.8 s]	dev=(HR@5:0.3973,NDCG@5:0.2763) [2.0 s] *
Epoch 64    loss=0.2170 [59.1 s]	dev=(HR@5:0.4012,NDCG@5:0.2787) [2.0 s] *
Epoch 65    loss=0.2174 [56.6 s]	dev=(HR@5:0.3934,NDCG@5:0.2792) [1.9 s] *
Epoch 66    loss=0.2162 [51.9 s]	dev=(HR@5:0.3942,NDCG@5:0.2738) [1.9 s] *
Epoch 67    loss=0.2167 [60.2 s]	dev=(HR@5:0.3942,NDCG@5:0.2740) [1.9 s] *
Epoch 68    loss=0.2176 [56.4 s]	dev=(HR@5:0.3962,NDCG@5:0.2778) [1.9 s] *
Epoch 69    loss=0.2162 [55.0 s]	dev=(HR@5:0.3915,NDCG@5:0.2729) [1.9 s] *
Epoch 70    loss=0.2164 [59.8 s]	dev=(HR@5:0.4016,NDCG@5:0.2791) [1.9 s] *
Epoch 71    loss=0.2163 [57.3 s]	dev=(HR@5:0.4063,NDCG@5:0.2815) [2.0 s] *
Epoch 72    loss=0.2166 [53.0 s]	dev=(HR@5:0.3993,NDCG@5:0.2773) [1.9 s] *
Epoch 73    loss=0.2153 [60.3 s]	dev=(HR@5:0.4012,NDCG@5:0.2765) [1.9 s] *
Epoch 74    loss=0.2155 [55.0 s]	dev=(HR@5:0.3981,NDCG@5:0.2746) [2.4 s] *
Epoch 75    loss=0.2156 [60.1 s]	dev=(HR@5:0.4001,NDCG@5:0.2752) [2.0 s] *
Epoch 76    loss=0.2153 [58.1 s]	dev=(HR@5:0.4067,NDCG@5:0.2795) [1.9 s] *
Epoch 77    loss=0.2160 [61.1 s]	dev=(HR@5:0.4005,NDCG@5:0.2747) [1.8 s] *
Epoch 78    loss=0.2159 [57.9 s]	dev=(HR@5:0.4009,NDCG@5:0.2752) [1.9 s] *
Epoch 79    loss=0.2163 [54.5 s]	dev=(HR@5:0.4067,NDCG@5:0.2841) [1.9 s] *
Epoch 80    loss=0.2150 [53.6 s]	dev=(HR@5:0.3993,NDCG@5:0.2775) [1.8 s] *
Epoch 81    loss=0.2147 [56.0 s]	dev=(HR@5:0.4012,NDCG@5:0.2798) [1.9 s] *
Epoch 82    loss=0.2151 [58.7 s]	dev=(HR@5:0.4079,NDCG@5:0.2811) [1.9 s] *
Epoch 83    loss=0.2141 [57.6 s]	dev=(HR@5:0.3934,NDCG@5:0.2741) [1.9 s] *
Epoch 84    loss=0.2150 [56.9 s]	dev=(HR@5:0.3899,NDCG@5:0.2708) [1.9 s] *
Epoch 85    loss=0.2145 [58.0 s]	dev=(HR@5:0.3958,NDCG@5:0.2750) [1.9 s] *
Epoch 86    loss=0.2159 [57.9 s]	dev=(HR@5:0.3962,NDCG@5:0.2747) [1.8 s] *
Epoch 87    loss=0.2160 [52.3 s]	dev=(HR@5:0.3919,NDCG@5:0.2737) [1.8 s] *
Epoch 88    loss=0.2144 [55.9 s]	dev=(HR@5:0.3880,NDCG@5:0.2697) [1.8 s] *
Epoch 89    loss=0.2152 [55.9 s]	dev=(HR@5:0.3942,NDCG@5:0.2755) [1.8 s] *
Epoch 90    loss=0.2146 [47.7 s]	dev=(HR@5:0.3919,NDCG@5:0.2741) [1.9 s] *
Epoch 91    loss=0.2150 [57.3 s]	dev=(HR@5:0.4032,NDCG@5:0.2769) [2.0 s] *
Epoch 92    loss=0.2160 [57.6 s]	dev=(HR@5:0.3989,NDCG@5:0.2754) [1.8 s] *
Epoch 93    loss=0.2154 [54.6 s]	dev=(HR@5:0.4024,NDCG@5:0.2781) [1.9 s] *
Epoch 94    loss=0.2147 [61.7 s]	dev=(HR@5:0.3942,NDCG@5:0.2742) [2.1 s] *
Epoch 95    loss=0.2141 [56.2 s]	dev=(HR@5:0.3958,NDCG@5:0.2733) [2.0 s] *
Epoch 96    loss=0.2153 [56.5 s]	dev=(HR@5:0.3977,NDCG@5:0.2751) [1.9 s] *
Epoch 97    loss=0.2151 [55.8 s]	dev=(HR@5:0.3985,NDCG@5:0.2748) [1.9 s] *
Epoch 98    loss=0.2154 [54.2 s]	dev=(HR@5:0.3993,NDCG@5:0.2744) [1.9 s] *
Epoch 99    loss=0.2151 [55.1 s]	dev=(HR@5:0.4106,NDCG@5:0.2854) [2.0 s] *
Epoch 100   loss=0.2148 [55.2 s]	dev=(HR@5:0.4009,NDCG@5:0.2760) [2.0 s] *
Best Iter(dev)=   14	 dev=(HR@5:0.4215,NDCG@5:0.2920) [5671.6 s] 
Load model from ../model/ADRec/ADRec__MovieLens_1M__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.4009,NDCG@5:0.2760,HR@10:0.5585,NDCG@10:0.3267,HR@20:0.7256,NDCG@20:0.3688,HR@50:0.9180,NDCG@50:0.4075)
Test After Training: (HR@5:0.4287,NDCG@5:0.3084,HR@10:0.5772,NDCG@10:0.3564,HR@20:0.7450,NDCG@20:0.3987,HR@50:0.9196,NDCG@50:0.4338)
make dirs: ../log/ADRec/ADRec__MovieLens_1M__0__lr=0
Saving top-100 recommendation results to: ../log/ADRec/ADRec__MovieLens_1M__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__MovieLens_1M__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 19:30:27 ---------------------------------------------
2. 扩散模型对比实验
-------------------
运行 ADRec...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 19:30:30 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.0                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 2                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-1): 2 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  46%|█████████████████████████████████████████████████████████████████▍                                                                           | 6814/14681 [00:00<00:00, 68136.65it/s]
  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 13912/14681 [00:00<00:00, 69807.65it/s]
Test Before Training: (HR@5:0.0557,NDCG@5:0.0321,HR@10:0.1028,NDCG@10:0.0472,HR@20:0.1988,NDCG@20:0.0712,HR@50:0.4894,NDCG@50:0.1278)
Optimizer: Adam
Epoch 1     loss=0.5527 [4.9 s]	dev=(HR@5:0.2370,NDCG@5:0.1551) [4.4 s] *
Epoch 2     loss=0.3605 [5.6 s]	dev=(HR@5:0.2632,NDCG@5:0.1770) [4.6 s] *
Epoch 3     loss=0.2616 [5.9 s]	dev=(HR@5:0.2680,NDCG@5:0.1855) [4.5 s] *
Epoch 4     loss=0.1940 [5.0 s]	dev=(HR@5:0.2669,NDCG@5:0.1859) [4.3 s] *
Epoch 5     loss=0.1465 [5.2 s]	dev=(HR@5:0.2693,NDCG@5:0.1879) [4.5 s] *
Epoch 6     loss=0.1139 [6.4 s]	dev=(HR@5:0.2647,NDCG@5:0.1854) [4.5 s] *
Epoch 7     loss=0.0916 [6.2 s]	dev=(HR@5:0.2669,NDCG@5:0.1860) [4.5 s] *
Epoch 8     loss=0.0772 [6.9 s]	dev=(HR@5:0.2672,NDCG@5:0.1864) [4.5 s] *
Epoch 9     loss=0.0645 [6.0 s]	dev=(HR@5:0.2577,NDCG@5:0.1808) [4.5 s] *
Epoch 10    loss=0.4512 [8.3 s]	dev=(HR@5:0.2541,NDCG@5:0.1751) [4.7 s] *
Epoch 11    loss=0.4370 [8.9 s]	dev=(HR@5:0.2507,NDCG@5:0.1728) [4.6 s] *
Epoch 12    loss=0.4323 [8.7 s]	dev=(HR@5:0.2507,NDCG@5:0.1723) [4.7 s] *
Epoch 13    loss=0.4317 [7.6 s]	dev=(HR@5:0.2505,NDCG@5:0.1722) [4.4 s] *
Epoch 14    loss=0.4318 [9.0 s]	dev=(HR@5:0.2511,NDCG@5:0.1725) [4.5 s] *
Epoch 15    loss=0.5069 [10.3 s]	dev=(HR@5:0.2582,NDCG@5:0.1719) [4.5 s] *
Epoch 16    loss=0.4210 [10.6 s]	dev=(HR@5:0.2635,NDCG@5:0.1755) [4.7 s] *
Epoch 17    loss=0.4017 [8.4 s]	dev=(HR@5:0.2699,NDCG@5:0.1815) [4.7 s] *
Epoch 18    loss=0.3946 [8.7 s]	dev=(HR@5:0.2728,NDCG@5:0.1840) [4.4 s] *
Epoch 19    loss=0.3882 [10.2 s]	dev=(HR@5:0.2691,NDCG@5:0.1815) [4.6 s] *
Epoch 20    loss=0.3870 [10.8 s]	dev=(HR@5:0.2738,NDCG@5:0.1840) [4.7 s] *
Epoch 21    loss=0.3813 [9.7 s]	dev=(HR@5:0.2691,NDCG@5:0.1828) [4.8 s] *
Epoch 22    loss=0.3810 [9.1 s]	dev=(HR@5:0.2697,NDCG@5:0.1824) [4.6 s] *
Epoch 23    loss=0.3802 [10.8 s]	dev=(HR@5:0.2711,NDCG@5:0.1834) [4.9 s] *
Epoch 24    loss=0.3788 [8.2 s]	dev=(HR@5:0.2727,NDCG@5:0.1835) [4.7 s] *
Epoch 25    loss=0.3760 [11.0 s]	dev=(HR@5:0.2708,NDCG@5:0.1827) [4.6 s] *
Epoch 26    loss=0.3758 [6.8 s]	dev=(HR@5:0.2676,NDCG@5:0.1802) [4.5 s] *
Epoch 27    loss=0.3759 [10.3 s]	dev=(HR@5:0.2704,NDCG@5:0.1814) [5.1 s] *
Epoch 28    loss=0.3742 [10.7 s]	dev=(HR@5:0.2693,NDCG@5:0.1824) [4.7 s] *
Epoch 29    loss=0.3745 [10.0 s]	dev=(HR@5:0.2712,NDCG@5:0.1819) [4.6 s] *
Epoch 30    loss=0.3715 [9.6 s]	dev=(HR@5:0.2723,NDCG@5:0.1823) [4.8 s] *
Epoch 31    loss=0.3726 [7.4 s]	dev=(HR@5:0.2738,NDCG@5:0.1845) [4.6 s] *
Epoch 32    loss=0.3728 [9.8 s]	dev=(HR@5:0.2671,NDCG@5:0.1792) [4.6 s] *
Epoch 33    loss=0.3714 [8.7 s]	dev=(HR@5:0.2701,NDCG@5:0.1816) [4.5 s] *
Epoch 34    loss=0.3706 [9.2 s]	dev=(HR@5:0.2697,NDCG@5:0.1818) [4.5 s] *
Early stop at 34 based on dev result.
Best Iter(dev)=    5	 dev=(HR@5:0.2693,NDCG@5:0.1879) [441.9 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.2697,NDCG@5:0.1818,HR@10:0.3914,NDCG@10:0.2209,HR@20:0.5312,NDCG@20:0.2563,HR@50:0.7329,NDCG@50:0.2963)
Test After Training: (HR@5:0.2291,NDCG@5:0.1506,HR@10:0.3401,NDCG@10:0.1862,HR@20:0.4750,NDCG@20:0.2203,HR@50:0.6782,NDCG@50:0.2605)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 19:38:19 ---------------------------------------------
3. 消融实验
------------
运行 ADRec (完整版)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 19:38:21 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 32                  
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 32                  
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 278912
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 32)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): SiLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  47%|██████████████████████████████████████████████████████████████████▏                                                                          | 6897/14681 [00:00<00:00, 68964.48it/s]
  96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 14045/14681 [00:00<00:00, 70442.61it/s]
Test Before Training: (HR@5:0.0506,NDCG@5:0.0298,HR@10:0.1000,NDCG@10:0.0455,HR@20:0.2053,NDCG@20:0.0719,HR@50:0.5064,NDCG@50:0.1305)
Optimizer: Adam
Epoch 1     loss=0.6131 [6.1 s]	dev=(HR@5:0.2188,NDCG@5:0.1391) [1.6 s] *
Epoch 2     loss=0.4589 [5.9 s]	dev=(HR@5:0.2415,NDCG@5:0.1534) [1.5 s] *
Epoch 3     loss=0.3847 [6.4 s]	dev=(HR@5:0.2555,NDCG@5:0.1652) [1.6 s] *
Epoch 4     loss=0.3375 [6.4 s]	dev=(HR@5:0.2637,NDCG@5:0.1752) [1.7 s] *
Epoch 5     loss=0.2988 [6.8 s]	dev=(HR@5:0.2679,NDCG@5:0.1808) [1.7 s] *
Epoch 6     loss=0.2672 [6.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1822) [1.7 s] *
Epoch 7     loss=0.2391 [7.2 s]	dev=(HR@5:0.2655,NDCG@5:0.1844) [1.8 s] *
Epoch 8     loss=0.2188 [7.5 s]	dev=(HR@5:0.2658,NDCG@5:0.1831) [1.7 s] *
Epoch 9     loss=0.1992 [6.8 s]	dev=(HR@5:0.2624,NDCG@5:0.1825) [1.7 s] *
Epoch 10    loss=0.4875 [7.7 s]	dev=(HR@5:0.2613,NDCG@5:0.1786) [1.7 s] *
Epoch 11    loss=0.4746 [8.6 s]	dev=(HR@5:0.2575,NDCG@5:0.1755) [1.7 s] *
Epoch 12    loss=0.4662 [10.9 s]	dev=(HR@5:0.2583,NDCG@5:0.1752) [1.8 s] *
Epoch 13    loss=0.4647 [9.6 s]	dev=(HR@5:0.2580,NDCG@5:0.1745) [2.3 s] *
Epoch 14    loss=0.4635 [9.1 s]	dev=(HR@5:0.2578,NDCG@5:0.1740) [2.0 s] *
Epoch 15    loss=0.4870 [11.6 s]	dev=(HR@5:0.2565,NDCG@5:0.1705) [1.7 s] *
Epoch 16    loss=0.4557 [10.4 s]	dev=(HR@5:0.2631,NDCG@5:0.1732) [1.9 s] *
Epoch 17    loss=0.4435 [11.7 s]	dev=(HR@5:0.2721,NDCG@5:0.1801) [1.7 s] *
Epoch 18    loss=0.4382 [8.8 s]	dev=(HR@5:0.2684,NDCG@5:0.1786) [1.7 s] *
Epoch 19    loss=0.4324 [11.2 s]	dev=(HR@5:0.2725,NDCG@5:0.1828) [1.7 s] *
Epoch 20    loss=0.4323 [10.0 s]	dev=(HR@5:0.2715,NDCG@5:0.1807) [1.7 s] *
Epoch 21    loss=0.4259 [8.7 s]	dev=(HR@5:0.2700,NDCG@5:0.1806) [1.8 s] *
Epoch 22    loss=0.4247 [9.3 s]	dev=(HR@5:0.2734,NDCG@5:0.1827) [1.7 s] *
Epoch 23    loss=0.4209 [8.7 s]	dev=(HR@5:0.2733,NDCG@5:0.1827) [1.7 s] *
Epoch 24    loss=0.4210 [10.3 s]	dev=(HR@5:0.2701,NDCG@5:0.1807) [1.6 s] *
Epoch 25    loss=0.4184 [9.9 s]	dev=(HR@5:0.2673,NDCG@5:0.1780) [1.8 s] *
Epoch 26    loss=0.4172 [10.7 s]	dev=(HR@5:0.2738,NDCG@5:0.1839) [1.8 s] *
Epoch 27    loss=0.4165 [8.6 s]	dev=(HR@5:0.2680,NDCG@5:0.1787) [1.7 s] *
Epoch 28    loss=0.4148 [9.7 s]	dev=(HR@5:0.2735,NDCG@5:0.1824) [1.7 s] *
Epoch 29    loss=0.4170 [11.8 s]	dev=(HR@5:0.2730,NDCG@5:0.1826) [1.6 s] *
Epoch 30    loss=0.4127 [11.0 s]	dev=(HR@5:0.2702,NDCG@5:0.1817) [1.8 s] *
Epoch 31    loss=0.4129 [8.2 s]	dev=(HR@5:0.2740,NDCG@5:0.1831) [1.8 s] *
Epoch 32    loss=0.4125 [10.2 s]	dev=(HR@5:0.2716,NDCG@5:0.1800) [1.7 s] *
Epoch 33    loss=0.4107 [11.5 s]	dev=(HR@5:0.2718,NDCG@5:0.1818) [1.9 s] *
Epoch 34    loss=0.4103 [11.9 s]	dev=(HR@5:0.2706,NDCG@5:0.1812) [1.8 s] *
Epoch 35    loss=0.4071 [9.0 s]	dev=(HR@5:0.2716,NDCG@5:0.1806) [1.8 s] *
Epoch 36    loss=0.4071 [11.0 s]	dev=(HR@5:0.2757,NDCG@5:0.1843) [1.9 s] *
Early stop at 36 based on dev result.
Best Iter(dev)=    7	 dev=(HR@5:0.2655,NDCG@5:0.1844) [392.5 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=32.pt
Dev  After Training: (HR@5:0.2757,NDCG@5:0.1843,HR@10:0.3958,NDCG@10:0.2229,HR@20:0.5359,NDCG@20:0.2584,HR@50:0.7382,NDCG@50:0.2984)
Test After Training: (HR@5:0.2347,NDCG@5:0.1537,HR@10:0.3450,NDCG@10:0.1892,HR@20:0.4754,NDCG@20:0.2222,HR@50:0.6847,NDCG@50:0.2636)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 19:45:07 ---------------------------------------------
运行 ADRec (去掉三阶段训练)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 19:45:10 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 32                  
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 32                  
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage3              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 337760
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 32)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): SiLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  46%|█████████████████████████████████████████████████████████████████▎                                                                           | 6802/14681 [00:00<00:00, 68015.36it/s]
  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 13677/14681 [00:00<00:00, 68440.23it/s]
Test Before Training: (HR@5:0.0506,NDCG@5:0.0298,HR@10:0.1000,NDCG@10:0.0455,HR@20:0.2053,NDCG@20:0.0719,HR@50:0.5064,NDCG@50:0.1305)
Optimizer: Adam
Epoch 1     loss=0.6131 [5.9 s]	dev=(HR@5:0.2188,NDCG@5:0.1391) [1.7 s] *
Epoch 2     loss=0.4589 [7.6 s]	dev=(HR@5:0.2415,NDCG@5:0.1534) [1.6 s] *
Epoch 3     loss=0.3847 [5.1 s]	dev=(HR@5:0.2555,NDCG@5:0.1652) [1.6 s] *
Epoch 4     loss=0.3375 [5.4 s]	dev=(HR@5:0.2637,NDCG@5:0.1752) [1.6 s] *
Epoch 5     loss=0.2988 [4.3 s]	dev=(HR@5:0.2679,NDCG@5:0.1808) [1.5 s] *
Epoch 6     loss=0.2672 [5.2 s]	dev=(HR@5:0.2671,NDCG@5:0.1822) [1.6 s] *
Epoch 7     loss=0.2391 [5.1 s]	dev=(HR@5:0.2655,NDCG@5:0.1844) [1.5 s] *
Epoch 8     loss=0.2188 [4.9 s]	dev=(HR@5:0.2658,NDCG@5:0.1831) [1.7 s]
Epoch 9     loss=0.1992 [6.2 s]	dev=(HR@5:0.2624,NDCG@5:0.1825) [1.6 s]
Epoch 10    loss=0.4875 [7.9 s]	dev=(HR@5:0.2613,NDCG@5:0.1786) [1.9 s]
Epoch 11    loss=0.4746 [10.4 s]	dev=(HR@5:0.2575,NDCG@5:0.1755) [1.6 s]
Epoch 12    loss=0.4662 [8.6 s]	dev=(HR@5:0.2583,NDCG@5:0.1752) [1.7 s]
Epoch 13    loss=0.4647 [10.0 s]	dev=(HR@5:0.2580,NDCG@5:0.1745) [1.7 s]
Epoch 14    loss=0.4635 [8.7 s]	dev=(HR@5:0.2578,NDCG@5:0.1740) [1.7 s]
Epoch 15    loss=0.4870 [10.1 s]	dev=(HR@5:0.2565,NDCG@5:0.1705) [1.7 s]
Epoch 16    loss=0.4557 [10.4 s]	dev=(HR@5:0.2631,NDCG@5:0.1732) [1.6 s]
Epoch 17    loss=0.4435 [9.6 s]	dev=(HR@5:0.2721,NDCG@5:0.1801) [1.6 s]
Epoch 18    loss=0.4382 [9.4 s]	dev=(HR@5:0.2684,NDCG@5:0.1786) [1.7 s]
Epoch 19    loss=0.4324 [7.7 s]	dev=(HR@5:0.2725,NDCG@5:0.1828) [1.6 s]
Epoch 20    loss=0.4323 [10.6 s]	dev=(HR@5:0.2715,NDCG@5:0.1807) [1.7 s]
Epoch 21    loss=0.4259 [10.2 s]	dev=(HR@5:0.2700,NDCG@5:0.1806) [1.6 s]
Epoch 22    loss=0.4247 [9.3 s]	dev=(HR@5:0.2734,NDCG@5:0.1827) [1.7 s]
Epoch 23    loss=0.4209 [11.4 s]	dev=(HR@5:0.2733,NDCG@5:0.1827) [1.8 s]
Epoch 24    loss=0.4210 [9.8 s]	dev=(HR@5:0.2701,NDCG@5:0.1807) [1.7 s]
Epoch 25    loss=0.4184 [10.0 s]	dev=(HR@5:0.2673,NDCG@5:0.1780) [1.7 s]
Epoch 26    loss=0.4172 [9.3 s]	dev=(HR@5:0.2738,NDCG@5:0.1839) [1.7 s]
Epoch 27    loss=0.4165 [11.5 s]	dev=(HR@5:0.2680,NDCG@5:0.1787) [1.8 s]
Epoch 28    loss=0.4148 [9.6 s]	dev=(HR@5:0.2735,NDCG@5:0.1824) [1.8 s]
Epoch 29    loss=0.4170 [10.5 s]	dev=(HR@5:0.2730,NDCG@5:0.1826) [1.8 s]
Epoch 30    loss=0.4127 [10.2 s]	dev=(HR@5:0.2702,NDCG@5:0.1817) [2.0 s]
Epoch 31    loss=0.4129 [11.4 s]	dev=(HR@5:0.2740,NDCG@5:0.1831) [1.8 s]
Epoch 32    loss=0.4125 [11.3 s]	dev=(HR@5:0.2716,NDCG@5:0.1800) [1.9 s]
Epoch 33    loss=0.4107 [11.0 s]	dev=(HR@5:0.2718,NDCG@5:0.1818) [1.9 s]
Epoch 34    loss=0.4103 [9.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1812) [2.4 s]
Epoch 35    loss=0.4071 [10.8 s]	dev=(HR@5:0.2716,NDCG@5:0.1806) [2.4 s]
Epoch 36    loss=0.4071 [11.4 s]	dev=(HR@5:0.2757,NDCG@5:0.1843) [1.8 s]
Early stop at 36 based on dev result.
Best Iter(dev)=    7	 dev=(HR@5:0.2655,NDCG@5:0.1844) [383.4 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=32.pt
Dev  After Training: (HR@5:0.2655,NDCG@5:0.1844,HR@10:0.3782,NDCG@10:0.2207,HR@20:0.5130,NDCG@20:0.2548,HR@50:0.7147,NDCG@50:0.2948)
Test After Training: (HR@5:0.2367,NDCG@5:0.1625,HR@10:0.3347,NDCG@10:0.1940,HR@20:0.4686,NDCG@20:0.2279,HR@50:0.6681,NDCG@50:0.2673)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 19:51:48 ---------------------------------------------
运行 ADRec (去掉token-level diffusion)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 19:51:51 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 32                  
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 32                  
 history_max           | 20                  
 independent_diffusion | True                
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 278912
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 32)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): SiLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  42%|███████████████████████████████████████████████████████████▌                                                                                 | 6198/14681 [00:00<00:00, 61968.24it/s]
  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 13109/14681 [00:00<00:00, 66166.94it/s]
Test Before Training: (HR@5:0.0506,NDCG@5:0.0298,HR@10:0.1000,NDCG@10:0.0455,HR@20:0.2053,NDCG@20:0.0719,HR@50:0.5064,NDCG@50:0.1305)
Optimizer: Adam
Epoch 1     loss=0.6131 [4.6 s]	dev=(HR@5:0.2188,NDCG@5:0.1391) [1.6 s] *
Epoch 2     loss=0.4589 [6.2 s]	dev=(HR@5:0.2415,NDCG@5:0.1534) [1.6 s] *
Epoch 3     loss=0.3847 [6.0 s]	dev=(HR@5:0.2555,NDCG@5:0.1652) [1.6 s] *
Epoch 4     loss=0.3375 [5.8 s]	dev=(HR@5:0.2637,NDCG@5:0.1752) [1.9 s] *
Epoch 5     loss=0.2988 [8.3 s]	dev=(HR@5:0.2679,NDCG@5:0.1808) [1.9 s] *
Epoch 6     loss=0.2672 [7.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1822) [1.8 s] *
Epoch 7     loss=0.2391 [5.4 s]	dev=(HR@5:0.2655,NDCG@5:0.1844) [2.0 s] *
Epoch 8     loss=0.2188 [7.0 s]	dev=(HR@5:0.2658,NDCG@5:0.1831) [1.8 s] *
Epoch 9     loss=0.1992 [5.7 s]	dev=(HR@5:0.2624,NDCG@5:0.1825) [1.7 s] *
Traceback (most recent call last):
  File "/mlfinalwork-master/Rechorus/src/main.py", line 197, in <module>
    main()
  File "/mlfinalwork-master/Rechorus/src/main.py", line 84, in main
    runner.train(data_dict)
  File "/mlfinalwork-master/Rechorus/src/helpers/BaseRunner.py", line 126, in train
    loss = self.fit(data_dict['train'], epoch=epoch + 1)
  File "/mlfinalwork-master/Rechorus/src/helpers/BaseRunner.py", line 196, in fit
    out_dict = model(batch)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlfinalwork-master/Rechorus/src/models/sequential/ADRec.py", line 789, in forward
    out_dict = ADRecBase.forward(self, feed_dict)
  File "/mlfinalwork-master/Rechorus/src/models/sequential/ADRec.py", line 649, in forward
    diffusion_loss, pred_emb = self.diffusion.compute_loss(
  File "/mlfinalwork-master/Rechorus/src/models/sequential/ADRec.py", line 323, in compute_loss
    predicted_flat = self.denoise_net(
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlfinalwork-master/Rechorus/src/models/sequential/ADRec.py", line 98, in forward
    out = self.decoder(rep_diffu, mask_seq)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlfinalwork-master/Rechorus/src/models/sequential/ADRec.py", line 46, in forward
    out = layer(out)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mlfinalwork-master/Rechorus/src/models/sequential/ADRec.py", line 22, in forward
    return x * torch.sigmoid(x)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 11.28 GiB. GPU 0 has a total capacty of 23.59 GiB of which 6.10 GiB is free. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 17.16 GiB is allocated by PyTorch, and 9.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
4. 超参数实验
--------------
运行 ADRec (T=5)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 19:53:10 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 5                   
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  46%|█████████████████████████████████████████████████████████████████                                                                            | 6779/14681 [00:00<00:00, 67784.73it/s]
  95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 13946/14681 [00:00<00:00, 70067.89it/s]
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5517 [6.6 s]	dev=(HR@5:0.2357,NDCG@5:0.1537) [1.2 s] *
Epoch 2     loss=0.3595 [5.4 s]	dev=(HR@5:0.2622,NDCG@5:0.1772) [1.1 s] *
Epoch 3     loss=0.2609 [6.9 s]	dev=(HR@5:0.2657,NDCG@5:0.1834) [1.3 s] *
Epoch 4     loss=0.1926 [4.9 s]	dev=(HR@5:0.2680,NDCG@5:0.1865) [1.2 s] *
Epoch 5     loss=0.1454 [6.3 s]	dev=(HR@5:0.2642,NDCG@5:0.1854) [1.2 s] *
Epoch 6     loss=0.1130 [7.3 s]	dev=(HR@5:0.2646,NDCG@5:0.1847) [1.5 s] *
Epoch 7     loss=0.0914 [7.5 s]	dev=(HR@5:0.2655,NDCG@5:0.1858) [1.5 s] *
Epoch 8     loss=0.0766 [7.9 s]	dev=(HR@5:0.2622,NDCG@5:0.1837) [1.3 s] *
Epoch 9     loss=0.0645 [6.8 s]	dev=(HR@5:0.2602,NDCG@5:0.1826) [1.2 s] *
Epoch 10    loss=0.4777 [7.6 s]	dev=(HR@5:0.2547,NDCG@5:0.1757) [1.5 s] *
Epoch 11    loss=0.4621 [11.0 s]	dev=(HR@5:0.2521,NDCG@5:0.1734) [1.3 s] *
Epoch 12    loss=0.4588 [10.4 s]	dev=(HR@5:0.2522,NDCG@5:0.1728) [1.2 s] *
Epoch 13    loss=0.4582 [9.3 s]	dev=(HR@5:0.2524,NDCG@5:0.1725) [1.2 s] *
Epoch 14    loss=0.4578 [8.5 s]	dev=(HR@5:0.2525,NDCG@5:0.1725) [1.4 s] *
Epoch 15    loss=0.5238 [10.8 s]	dev=(HR@5:0.2575,NDCG@5:0.1716) [1.3 s] *
Epoch 16    loss=0.4526 [11.0 s]	dev=(HR@5:0.2657,NDCG@5:0.1761) [1.3 s] *
Epoch 17    loss=0.4338 [11.5 s]	dev=(HR@5:0.2697,NDCG@5:0.1802) [1.3 s] *
Epoch 18    loss=0.4272 [10.0 s]	dev=(HR@5:0.2669,NDCG@5:0.1765) [1.2 s] *
Epoch 19    loss=0.4200 [9.3 s]	dev=(HR@5:0.2703,NDCG@5:0.1815) [1.3 s] *
Epoch 20    loss=0.4177 [11.6 s]	dev=(HR@5:0.2624,NDCG@5:0.1766) [1.3 s] *
Epoch 21    loss=0.4120 [12.5 s]	dev=(HR@5:0.2643,NDCG@5:0.1769) [1.7 s] *
Epoch 22    loss=0.4137 [11.9 s]	dev=(HR@5:0.2728,NDCG@5:0.1855) [1.5 s] *
Epoch 23    loss=0.4122 [9.8 s]	dev=(HR@5:0.2681,NDCG@5:0.1816) [1.6 s] *
Epoch 24    loss=0.4109 [11.9 s]	dev=(HR@5:0.2679,NDCG@5:0.1802) [1.7 s] *
Epoch 25    loss=0.4081 [12.3 s]	dev=(HR@5:0.2622,NDCG@5:0.1760) [1.5 s] *
Epoch 26    loss=0.4068 [11.1 s]	dev=(HR@5:0.2691,NDCG@5:0.1803) [1.6 s] *
Epoch 27    loss=0.4070 [10.4 s]	dev=(HR@5:0.2697,NDCG@5:0.1798) [1.4 s] *
Epoch 28    loss=0.4072 [13.0 s]	dev=(HR@5:0.2686,NDCG@5:0.1790) [1.6 s] *
Epoch 29    loss=0.4060 [13.1 s]	dev=(HR@5:0.2722,NDCG@5:0.1808) [1.7 s] *
Epoch 30    loss=0.4029 [12.7 s]	dev=(HR@5:0.2703,NDCG@5:0.1798) [1.6 s] *
Epoch 31    loss=0.4046 [12.4 s]	dev=(HR@5:0.2738,NDCG@5:0.1835) [1.5 s] *
Epoch 32    loss=0.4046 [11.9 s]	dev=(HR@5:0.2713,NDCG@5:0.1800) [1.5 s] *
Epoch 33    loss=0.4034 [13.4 s]	dev=(HR@5:0.2675,NDCG@5:0.1790) [1.6 s] *
Early stop at 33 based on dev result.
Best Iter(dev)=    4	 dev=(HR@5:0.2680,NDCG@5:0.1865) [373.5 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.2675,NDCG@5:0.1790,HR@10:0.3899,NDCG@10:0.2184,HR@20:0.5301,NDCG@20:0.2540,HR@50:0.7348,NDCG@50:0.2945)
Test After Training: (HR@5:0.2317,NDCG@5:0.1506,HR@10:0.3396,NDCG@10:0.1853,HR@20:0.4704,NDCG@20:0.2184,HR@50:0.6814,NDCG@50:0.2600)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 19:59:37 ---------------------------------------------
运行 ADRec (T=10)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 19:59:40 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  44%|█████████████████████████████████████████████████████████████▌                                                                               | 6415/14681 [00:00<00:00, 64142.41it/s]
  89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 13079/14681 [00:00<00:00, 65604.19it/s]
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5516 [7.2 s]	dev=(HR@5:0.2360,NDCG@5:0.1538) [2.3 s] *
Epoch 2     loss=0.3598 [7.2 s]	dev=(HR@5:0.2623,NDCG@5:0.1773) [2.3 s] *
Epoch 3     loss=0.2614 [8.4 s]	dev=(HR@5:0.2672,NDCG@5:0.1852) [2.4 s] *
Epoch 4     loss=0.1923 [7.8 s]	dev=(HR@5:0.2699,NDCG@5:0.1881) [2.4 s] *
Epoch 5     loss=0.1447 [8.7 s]	dev=(HR@5:0.2652,NDCG@5:0.1869) [2.3 s] *
Epoch 6     loss=0.1129 [7.3 s]	dev=(HR@5:0.2633,NDCG@5:0.1848) [2.3 s] *
Epoch 7     loss=0.0918 [6.8 s]	dev=(HR@5:0.2669,NDCG@5:0.1870) [2.3 s] *
Epoch 8     loss=0.0764 [8.2 s]	dev=(HR@5:0.2648,NDCG@5:0.1841) [2.3 s] *
Epoch 9     loss=0.0655 [7.2 s]	dev=(HR@5:0.2616,NDCG@5:0.1827) [2.1 s] *
Epoch 10    loss=0.4771 [11.4 s]	dev=(HR@5:0.2566,NDCG@5:0.1752) [2.0 s] *
Epoch 11    loss=0.4633 [8.3 s]	dev=(HR@5:0.2549,NDCG@5:0.1739) [2.0 s] *
Epoch 12    loss=0.4591 [12.1 s]	dev=(HR@5:0.2545,NDCG@5:0.1740) [2.4 s] *
Epoch 13    loss=0.4598 [12.2 s]	dev=(HR@5:0.2533,NDCG@5:0.1726) [2.2 s] *
Epoch 14    loss=0.4580 [12.1 s]	dev=(HR@5:0.2539,NDCG@5:0.1731) [2.4 s] *
Epoch 15    loss=0.5195 [12.4 s]	dev=(HR@5:0.2610,NDCG@5:0.1728) [2.4 s] *
Epoch 16    loss=0.4512 [14.3 s]	dev=(HR@5:0.2643,NDCG@5:0.1757) [2.3 s] *
Epoch 17    loss=0.4346 [13.5 s]	dev=(HR@5:0.2706,NDCG@5:0.1800) [2.4 s] *
Epoch 18    loss=0.4289 [11.9 s]	dev=(HR@5:0.2676,NDCG@5:0.1789) [2.4 s] *
Epoch 19    loss=0.4220 [14.2 s]	dev=(HR@5:0.2711,NDCG@5:0.1822) [2.4 s] *
Epoch 20    loss=0.4187 [13.9 s]	dev=(HR@5:0.2642,NDCG@5:0.1770) [2.4 s] *
Epoch 21    loss=0.4144 [13.5 s]	dev=(HR@5:0.2659,NDCG@5:0.1788) [2.3 s] *
Epoch 22    loss=0.4142 [13.0 s]	dev=(HR@5:0.2716,NDCG@5:0.1827) [2.2 s] *
Epoch 23    loss=0.4122 [13.4 s]	dev=(HR@5:0.2709,NDCG@5:0.1816) [2.2 s] *
Epoch 24    loss=0.4119 [13.6 s]	dev=(HR@5:0.2679,NDCG@5:0.1793) [2.2 s] *
Epoch 25    loss=0.4095 [12.8 s]	dev=(HR@5:0.2662,NDCG@5:0.1766) [2.3 s] *
Epoch 26    loss=0.4075 [14.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1808) [2.3 s] *
Epoch 27    loss=0.4095 [14.1 s]	dev=(HR@5:0.2708,NDCG@5:0.1802) [2.4 s] *
Epoch 28    loss=0.4071 [12.3 s]	dev=(HR@5:0.2696,NDCG@5:0.1781) [2.3 s] *
Epoch 29    loss=0.4063 [13.6 s]	dev=(HR@5:0.2736,NDCG@5:0.1808) [2.4 s] *
Epoch 30    loss=0.4053 [13.8 s]	dev=(HR@5:0.2686,NDCG@5:0.1781) [1.9 s] *
Epoch 31    loss=0.4055 [9.5 s]	dev=(HR@5:0.2759,NDCG@5:0.1843) [2.0 s] *
Epoch 32    loss=0.4047 [9.6 s]	dev=(HR@5:0.2717,NDCG@5:0.1790) [1.9 s] *
Epoch 33    loss=0.4031 [12.4 s]	dev=(HR@5:0.2702,NDCG@5:0.1798) [2.0 s] *
Early stop at 33 based on dev result.
Best Iter(dev)=    4	 dev=(HR@5:0.2699,NDCG@5:0.1881) [445.6 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.2702,NDCG@5:0.1798,HR@10:0.3933,NDCG@10:0.2194,HR@20:0.5325,NDCG@20:0.2547,HR@50:0.7360,NDCG@50:0.2950)
Test After Training: (HR@5:0.2303,NDCG@5:0.1511,HR@10:0.3414,NDCG@10:0.1868,HR@20:0.4726,NDCG@20:0.2200,HR@50:0.6831,NDCG@50:0.2615)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 20:07:21 ---------------------------------------------
运行 ADRec (T=20)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 20:07:24 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 20                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5517 [5.6 s]	dev=(HR@5:0.2372,NDCG@5:0.1544) [3.1 s] *
Epoch 2     loss=0.3598 [6.0 s]	dev=(HR@5:0.2629,NDCG@5:0.1774) [3.2 s] *
Epoch 3     loss=0.2607 [6.1 s]	dev=(HR@5:0.2659,NDCG@5:0.1843) [3.2 s] *
Epoch 4     loss=0.1925 [5.8 s]	dev=(HR@5:0.2675,NDCG@5:0.1869) [3.2 s] *
Epoch 5     loss=0.1454 [6.6 s]	dev=(HR@5:0.2639,NDCG@5:0.1854) [3.2 s] *
Epoch 6     loss=0.1128 [6.2 s]	dev=(HR@5:0.2637,NDCG@5:0.1850) [3.2 s] *
Epoch 7     loss=0.0913 [4.8 s]	dev=(HR@5:0.2648,NDCG@5:0.1863) [3.2 s] *
Epoch 8     loss=0.0766 [5.8 s]	dev=(HR@5:0.2629,NDCG@5:0.1836) [3.3 s] *
Epoch 9     loss=0.0656 [6.4 s]	dev=(HR@5:0.2618,NDCG@5:0.1825) [3.2 s] *
Epoch 10    loss=0.4769 [9.9 s]	dev=(HR@5:0.2539,NDCG@5:0.1750) [3.2 s] *
Epoch 11    loss=0.4626 [7.7 s]	dev=(HR@5:0.2534,NDCG@5:0.1732) [3.2 s] *
Epoch 12    loss=0.4584 [10.5 s]	dev=(HR@5:0.2545,NDCG@5:0.1733) [3.3 s] *
Epoch 13    loss=0.4582 [10.5 s]	dev=(HR@5:0.2541,NDCG@5:0.1729) [3.2 s] *
Epoch 14    loss=0.4585 [9.8 s]	dev=(HR@5:0.2543,NDCG@5:0.1732) [3.5 s] *
Epoch 15    loss=0.5207 [10.9 s]	dev=(HR@5:0.2571,NDCG@5:0.1726) [3.4 s] *
Epoch 16    loss=0.4514 [10.4 s]	dev=(HR@5:0.2671,NDCG@5:0.1755) [3.6 s] *
Epoch 17    loss=0.4341 [9.3 s]	dev=(HR@5:0.2727,NDCG@5:0.1813) [3.3 s] *
Epoch 18    loss=0.4278 [11.2 s]	dev=(HR@5:0.2682,NDCG@5:0.1774) [3.4 s] *
Epoch 19    loss=0.4198 [8.2 s]	dev=(HR@5:0.2670,NDCG@5:0.1781) [3.3 s] *
Epoch 20    loss=0.4200 [12.0 s]	dev=(HR@5:0.2667,NDCG@5:0.1795) [3.4 s] *
Epoch 21    loss=0.4137 [11.7 s]	dev=(HR@5:0.2644,NDCG@5:0.1769) [3.3 s] *
Epoch 22    loss=0.4144 [11.3 s]	dev=(HR@5:0.2722,NDCG@5:0.1828) [3.4 s] *
Epoch 23    loss=0.4107 [12.4 s]	dev=(HR@5:0.2708,NDCG@5:0.1823) [3.4 s] *
Epoch 24    loss=0.4116 [9.8 s]	dev=(HR@5:0.2710,NDCG@5:0.1790) [3.4 s] *
Epoch 25    loss=0.4066 [11.9 s]	dev=(HR@5:0.2676,NDCG@5:0.1783) [3.3 s] *
Epoch 26    loss=0.4078 [12.1 s]	dev=(HR@5:0.2732,NDCG@5:0.1827) [3.5 s] *
Epoch 27    loss=0.4081 [8.2 s]	dev=(HR@5:0.2714,NDCG@5:0.1806) [3.2 s] *
Epoch 28    loss=0.4057 [13.2 s]	dev=(HR@5:0.2697,NDCG@5:0.1777) [3.6 s] *
Epoch 29    loss=0.4064 [11.2 s]	dev=(HR@5:0.2735,NDCG@5:0.1802) [3.7 s] *
Epoch 30    loss=0.4035 [12.3 s]	dev=(HR@5:0.2703,NDCG@5:0.1798) [3.7 s] *
Epoch 31    loss=0.4047 [9.5 s]	dev=(HR@5:0.2729,NDCG@5:0.1825) [3.7 s] *
Epoch 32    loss=0.4054 [7.7 s]	dev=(HR@5:0.2686,NDCG@5:0.1769) [3.2 s] *
Epoch 33    loss=0.4029 [11.0 s]	dev=(HR@5:0.2721,NDCG@5:0.1798) [3.5 s] *
Early stop at 33 based on dev result.
Best Iter(dev)=    4	 dev=(HR@5:0.2675,NDCG@5:0.1869) [417.1 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.2721,NDCG@5:0.1798,HR@10:0.3919,NDCG@10:0.2183,HR@20:0.5323,NDCG@20:0.2538,HR@50:0.7348,NDCG@50:0.2939)
Test After Training: (HR@5:0.2313,NDCG@5:0.1503,HR@10:0.3432,NDCG@10:0.1862,HR@20:0.4746,NDCG@20:0.2194,HR@50:0.6827,NDCG@50:0.2605)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 20:14:42 ---------------------------------------------
运行 ADRec (T=50)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-26 20:14:45 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 100                 
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0-1): 2 x Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0-3): 4 x Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
   0%|                                                                                                                                                           | 0/14681 [00:00<?, ?it/s]
  46%|█████████████████████████████████████████████████████████████████▌                                                                           | 6821/14681 [00:00<00:00, 68197.06it/s]
  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 13952/14681 [00:00<00:00, 70024.46it/s]
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5522 [6.0 s]	dev=(HR@5:0.2346,NDCG@5:0.1531) [7.0 s] *
Epoch 2     loss=0.3603 [6.4 s]	dev=(HR@5:0.2596,NDCG@5:0.1766) [7.2 s] *
Epoch 3     loss=0.2605 [7.0 s]	dev=(HR@5:0.2676,NDCG@5:0.1856) [7.5 s] *
Epoch 4     loss=0.1924 [6.6 s]	dev=(HR@5:0.2666,NDCG@5:0.1868) [7.2 s] *
Epoch 5     loss=0.1457 [6.6 s]	dev=(HR@5:0.2671,NDCG@5:0.1872) [7.2 s] *
Epoch 6     loss=0.1128 [6.4 s]	dev=(HR@5:0.2616,NDCG@5:0.1839) [7.1 s] *
Epoch 7     loss=0.0909 [4.5 s]	dev=(HR@5:0.2644,NDCG@5:0.1858) [7.2 s] *
Epoch 8     loss=0.0770 [6.8 s]	dev=(HR@5:0.2639,NDCG@5:0.1845) [7.6 s] *
Epoch 9     loss=0.0653 [5.4 s]	dev=(HR@5:0.2599,NDCG@5:0.1827) [8.2 s] *
Epoch 10    loss=0.4772 [11.3 s]	dev=(HR@5:0.2551,NDCG@5:0.1751) [8.6 s] *
Epoch 11    loss=0.4624 [12.2 s]	dev=(HR@5:0.2522,NDCG@5:0.1723) [8.5 s] *
Epoch 12    loss=0.4587 [9.9 s]	dev=(HR@5:0.2525,NDCG@5:0.1721) [7.8 s] *
Epoch 13    loss=0.4590 [10.3 s]	dev=(HR@5:0.2526,NDCG@5:0.1720) [7.8 s] *
Epoch 14    loss=0.4584 [11.3 s]	dev=(HR@5:0.2535,NDCG@5:0.1723) [7.9 s] *
Epoch 15    loss=0.5267 [11.9 s]	dev=(HR@5:0.2558,NDCG@5:0.1703) [7.9 s] *
Epoch 16    loss=0.4534 [10.3 s]	dev=(HR@5:0.2682,NDCG@5:0.1783) [7.7 s] *
Epoch 17    loss=0.4325 [10.8 s]	dev=(HR@5:0.2712,NDCG@5:0.1788) [7.7 s] *
Epoch 18    loss=0.4261 [11.7 s]	dev=(HR@5:0.2684,NDCG@5:0.1784) [7.8 s] *
Epoch 19    loss=0.4196 [12.2 s]	dev=(HR@5:0.2684,NDCG@5:0.1792) [8.6 s] *
Epoch 20    loss=0.4185 [11.7 s]	dev=(HR@5:0.2673,NDCG@5:0.1809) [7.8 s] *
Epoch 21    loss=0.4115 [10.6 s]	dev=(HR@5:0.2673,NDCG@5:0.1793) [7.6 s] *
Epoch 22    loss=0.4128 [10.3 s]	dev=(HR@5:0.2693,NDCG@5:0.1822) [7.6 s] *
Epoch 23    loss=0.4113 [11.5 s]	dev=(HR@5:0.2708,NDCG@5:0.1822) [7.6 s] *
Epoch 24    loss=0.4101 [9.7 s]	dev=(HR@5:0.2671,NDCG@5:0.1802) [7.5 s] *
Epoch 25    loss=0.4080 [9.9 s]	dev=(HR@5:0.2671,NDCG@5:0.1775) [7.8 s] *
Epoch 26    loss=0.4069 [11.6 s]	dev=(HR@5:0.2712,NDCG@5:0.1808) [7.4 s] *
Epoch 27    loss=0.4081 [11.7 s]	dev=(HR@5:0.2684,NDCG@5:0.1780) [7.8 s] *
Epoch 28    loss=0.4067 [10.9 s]	dev=(HR@5:0.2689,NDCG@5:0.1790) [7.5 s] *
Epoch 29    loss=0.4062 [11.2 s]	dev=(HR@5:0.2706,NDCG@5:0.1796) [7.7 s] *
Epoch 30    loss=0.4029 [12.3 s]	dev=(HR@5:0.2702,NDCG@5:0.1799) [7.4 s] *
Epoch 31    loss=0.4040 [11.9 s]	dev=(HR@5:0.2727,NDCG@5:0.1825) [7.3 s] *
Epoch 32    loss=0.4044 [8.8 s]	dev=(HR@5:0.2693,NDCG@5:0.1792) [7.7 s] *
Epoch 33    loss=0.4027 [12.6 s]	dev=(HR@5:0.2712,NDCG@5:0.1802) [7.8 s] *
Epoch 34    loss=0.4024 [9.7 s]	dev=(HR@5:0.2700,NDCG@5:0.1802) [7.6 s] *
Epoch 35    loss=0.3996 [12.9 s]	dev=(HR@5:0.2733,NDCG@5:0.1822) [7.8 s] *
Epoch 36    loss=0.4004 [11.8 s]	dev=(HR@5:0.2680,NDCG@5:0.1789) [7.5 s] *
Epoch 37    loss=0.4020 [8.3 s]	dev=(HR@5:0.2715,NDCG@5:0.1804) [7.1 s] *
Epoch 38    loss=0.4015 [12.9 s]	dev=(HR@5:0.2748,NDCG@5:0.1828) [8.6 s] *
Epoch 39    loss=0.4001 [10.8 s]	dev=(HR@5:0.2707,NDCG@5:0.1811) [8.6 s] *
Epoch 40    loss=0.3984 [11.6 s]	dev=(HR@5:0.2726,NDCG@5:0.1833) [7.6 s] *
Epoch 41    loss=0.4000 [11.9 s]	dev=(HR@5:0.2671,NDCG@5:0.1785) [8.3 s] *
Epoch 42    loss=0.3989 [12.5 s]	dev=(HR@5:0.2694,NDCG@5:0.1804) [7.7 s] *
Epoch 43    loss=0.3991 [12.2 s]	dev=(HR@5:0.2647,NDCG@5:0.1769) [7.6 s] *
Epoch 44    loss=0.3989 [11.2 s]	dev=(HR@5:0.2683,NDCG@5:0.1797) [8.7 s] *
Epoch 45    loss=0.3972 [13.1 s]	dev=(HR@5:0.2701,NDCG@5:0.1804) [8.3 s] *
Epoch 46    loss=0.3990 [11.5 s]	dev=(HR@5:0.2663,NDCG@5:0.1769) [8.1 s] *
Epoch 47    loss=0.3982 [11.3 s]	dev=(HR@5:0.2680,NDCG@5:0.1781) [7.7 s] *
Epoch 48    loss=0.3988 [10.7 s]	dev=(HR@5:0.2665,NDCG@5:0.1764) [7.7 s] *
Epoch 49    loss=0.3964 [11.4 s]	dev=(HR@5:0.2725,NDCG@5:0.1815) [7.6 s] *
Epoch 50    loss=0.3983 [12.5 s]	dev=(HR@5:0.2724,NDCG@5:0.1824) [8.2 s] *
Epoch 51    loss=0.3972 [12.6 s]	dev=(HR@5:0.2711,NDCG@5:0.1817) [7.9 s] *
Epoch 52    loss=0.3960 [10.5 s]	dev=(HR@5:0.2711,NDCG@5:0.1813) [7.6 s] *
Epoch 53    loss=0.3970 [10.6 s]	dev=(HR@5:0.2693,NDCG@5:0.1790) [8.7 s] *
Epoch 54    loss=0.3954 [11.7 s]	dev=(HR@5:0.2699,NDCG@5:0.1824) [8.8 s] *
Epoch 55    loss=0.3946 [12.5 s]	dev=(HR@5:0.2674,NDCG@5:0.1784) [8.3 s] *
Epoch 56    loss=0.3956 [12.2 s]	dev=(HR@5:0.2700,NDCG@5:0.1799) [7.9 s] *
Epoch 57    loss=0.3961 [11.8 s]	dev=(HR@5:0.2733,NDCG@5:0.1806) [7.6 s] *
Epoch 58    loss=0.3945 [12.3 s]	dev=(HR@5:0.2702,NDCG@5:0.1810) [7.7 s] *
Epoch 59    loss=0.3956 [13.0 s]	dev=(HR@5:0.2680,NDCG@5:0.1791) [8.0 s] *
Epoch 60    loss=0.3958 [10.1 s]	dev=(HR@5:0.2673,NDCG@5:0.1789) [7.5 s] *
Epoch 61    loss=0.3949 [12.4 s]	dev=(HR@5:0.2693,NDCG@5:0.1790) [7.7 s] *
Epoch 62    loss=0.3959 [12.8 s]	dev=(HR@5:0.2714,NDCG@5:0.1814) [7.4 s] *
Epoch 63    loss=0.3957 [11.2 s]	dev=(HR@5:0.2679,NDCG@5:0.1789) [8.3 s] *
Epoch 64    loss=0.3948 [11.7 s]	dev=(HR@5:0.2706,NDCG@5:0.1810) [7.7 s] *
Epoch 65    loss=0.3953 [12.9 s]	dev=(HR@5:0.2678,NDCG@5:0.1799) [7.7 s] *
Epoch 66    loss=0.3923 [11.1 s]	dev=(HR@5:0.2693,NDCG@5:0.1798) [7.8 s] *
Epoch 67    loss=0.3961 [12.0 s]	dev=(HR@5:0.2703,NDCG@5:0.1803) [7.5 s] *
Epoch 68    loss=0.3923 [8.5 s]	dev=(HR@5:0.2706,NDCG@5:0.1815) [7.6 s] *
Epoch 69    loss=0.3947 [10.9 s]	dev=(HR@5:0.2675,NDCG@5:0.1791) [8.3 s] *
Epoch 70    loss=0.3943 [8.8 s]	dev=(HR@5:0.2694,NDCG@5:0.1803) [7.7 s] *
Epoch 71    loss=0.3927 [11.2 s]	dev=(HR@5:0.2695,NDCG@5:0.1811) [7.8 s] *
Epoch 72    loss=0.3936 [10.3 s]	dev=(HR@5:0.2702,NDCG@5:0.1812) [7.8 s] *
Epoch 73    loss=0.3957 [8.8 s]	dev=(HR@5:0.2706,NDCG@5:0.1808) [7.4 s] *
Epoch 74    loss=0.3926 [9.8 s]	dev=(HR@5:0.2697,NDCG@5:0.1808) [7.8 s] *
Epoch 75    loss=0.3940 [8.7 s]	dev=(HR@5:0.2703,NDCG@5:0.1814) [7.5 s] *
Epoch 76    loss=0.3944 [7.9 s]	dev=(HR@5:0.2703,NDCG@5:0.1815) [9.3 s] *
Epoch 77    loss=0.3923 [9.7 s]	dev=(HR@5:0.2695,NDCG@5:0.1806) [7.8 s] *
Epoch 78    loss=0.3920 [7.2 s]	dev=(HR@5:0.2686,NDCG@5:0.1815) [7.7 s] *
Epoch 79    loss=0.3935 [9.6 s]	dev=(HR@5:0.2680,NDCG@5:0.1792) [7.6 s] *
Epoch 80    loss=0.3935 [9.5 s]	dev=(HR@5:0.2703,NDCG@5:0.1811) [7.5 s] *
Epoch 81    loss=0.3914 [9.6 s]	dev=(HR@5:0.2708,NDCG@5:0.1808) [8.1 s] *
Epoch 82    loss=0.3937 [9.4 s]	dev=(HR@5:0.2718,NDCG@5:0.1810) [7.5 s] *
Epoch 83    loss=0.3937 [9.8 s]	dev=(HR@5:0.2740,NDCG@5:0.1819) [7.9 s] *
Epoch 84    loss=0.3921 [9.1 s]	dev=(HR@5:0.2663,NDCG@5:0.1780) [7.5 s] *
Epoch 85    loss=0.3915 [8.6 s]	dev=(HR@5:0.2701,NDCG@5:0.1806) [7.9 s] *
Epoch 86    loss=0.3935 [9.7 s]	dev=(HR@5:0.2667,NDCG@5:0.1787) [7.4 s] *
Epoch 87    loss=0.3939 [9.9 s]	dev=(HR@5:0.2674,NDCG@5:0.1798) [7.9 s] *
Epoch 88    loss=0.3929 [9.3 s]	dev=(HR@5:0.2667,NDCG@5:0.1789) [8.1 s] *
Epoch 89    loss=0.3919 [11.2 s]	dev=(HR@5:0.2684,NDCG@5:0.1800) [8.0 s] *
Epoch 90    loss=0.3914 [9.1 s]	dev=(HR@5:0.2696,NDCG@5:0.1799) [7.9 s] *
Epoch 91    loss=0.3927 [9.6 s]	dev=(HR@5:0.2689,NDCG@5:0.1797) [7.9 s] *
Epoch 92    loss=0.3909 [9.9 s]	dev=(HR@5:0.2691,NDCG@5:0.1807) [7.7 s] *
Epoch 93    loss=0.3936 [9.9 s]	dev=(HR@5:0.2679,NDCG@5:0.1795) [7.9 s] *
Epoch 94    loss=0.3923 [10.4 s]	dev=(HR@5:0.2712,NDCG@5:0.1810) [7.7 s] *
Epoch 95    loss=0.3929 [11.5 s]	dev=(HR@5:0.2693,NDCG@5:0.1789) [7.6 s] *
Epoch 96    loss=0.3921 [9.2 s]	dev=(HR@5:0.2691,NDCG@5:0.1798) [7.7 s] *
Epoch 97    loss=0.3936 [8.6 s]	dev=(HR@5:0.2671,NDCG@5:0.1789) [8.1 s] *
Epoch 98    loss=0.3910 [8.7 s]	dev=(HR@5:0.2701,NDCG@5:0.1802) [7.6 s] *
Epoch 99    loss=0.3925 [9.7 s]	dev=(HR@5:0.2691,NDCG@5:0.1795) [7.6 s] *
Epoch 100   loss=0.3911 [8.8 s]	dev=(HR@5:0.2682,NDCG@5:0.1791) [7.4 s] *
Best Iter(dev)=    5	 dev=(HR@5:0.2671,NDCG@5:0.1872) [1813.2 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
Dev  After Training: (HR@5:0.2682,NDCG@5:0.1791,HR@10:0.3943,NDCG@10:0.2197,HR@20:0.5316,NDCG@20:0.2544,HR@50:0.7339,NDCG@50:0.2945)
Test After Training: (HR@5:0.2306,NDCG@5:0.1501,HR@10:0.3434,NDCG@10:0.1865,HR@20:0.4712,NDCG@20:0.2187,HR@50:0.6782,NDCG@50:0.2597)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!
--------------------------------------------- END: 2025-12-26 20:45:42 ---------------------------------------------
所有实验已完成！结果已保存到 logs/results/experiment_results.txt

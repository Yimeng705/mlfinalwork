开始运行所有实验...
========================
1. 模型对比实验 - Grocery_and_Gourmet_Food 数据集
-------------------------------------------------
运行 SASRec...
Namespace(model_name='SASRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 14:03:04 ---------------------------------------------

===========================================
 Arguments          | Values               
===========================================
 batch_size         | 256                 
 data_appendix      |                     
 dataset            | Grocery_and_Gourm...
 dropout            | 0.3                 
 early_stop         | 10                  
 emb_size           | 128                 
 epoch              | 100                 
 eval_batch_size    | 256                 
 gpu                | 0                   
 history_max        | 20                  
 l2                 | 1e-05               
 lr                 | 0.0005              
 main_metric        |                     
 num_heads          | 4                   
 num_layers         | 2                   
 num_neg            | 1                   
 num_workers        | 5                   
 optimizer          | Adam                
 random_seed        | 0                   
 save_final_results | 1                   
 test_all           | 0                   
 topk               | 5,10,20,50          
===========================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1284224
SASRec(
  (i_embeddings): Embedding(8714, 128)
  (p_embeddings): Embedding(21, 128)
  (transformer_block): ModuleList(
    (0): TransformerLayer(
      (masked_attn_head): MultiHeadAttention(
        (q_linear): Linear(in_features=128, out_features=128, bias=True)
        (k_linear): Linear(in_features=128, out_features=128, bias=True)
        (v_linear): Linear(in_features=128, out_features=128, bias=True)
      )
      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.3, inplace=False)
      (linear1): Linear(in_features=128, out_features=128, bias=True)
      (linear2): Linear(in_features=128, out_features=128, bias=True)
      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout2): Dropout(p=0.3, inplace=False)
    )
    (1): TransformerLayer(
      (masked_attn_head): MultiHeadAttention(
        (q_linear): Linear(in_features=128, out_features=128, bias=True)
        (k_linear): Linear(in_features=128, out_features=128, bias=True)
        (v_linear): Linear(in_features=128, out_features=128, bias=True)
      )
      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.3, inplace=False)
      (linear1): Linear(in_features=128, out_features=128, bias=True)
      (linear2): Linear(in_features=128, out_features=128, bias=True)
      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout2): Dropout(p=0.3, inplace=False)
    )
  )
)

Test Before Training: (HR@5:0.0457,NDCG@5:0.0274,HR@10:0.0963,NDCG@10:0.0436,HR@20:0.1941,NDCG@20:0.0680,HR@50:0.4908,NDCG@50:0.1259)
Optimizer: Adam

Epoch 1     loss=0.4821 [4.6 s]	dev=(HR@5:0.3314,NDCG@5:0.2250) [0.4 s] *

Epoch 2     loss=0.3578 [4.5 s]	dev=(HR@5:0.3763,NDCG@5:0.2669) [0.3 s] *

Epoch 3     loss=0.2621 [4.5 s]	dev=(HR@5:0.4139,NDCG@5:0.3014) [0.3 s] *

Epoch 4     loss=0.1876 [4.4 s]	dev=(HR@5:0.4235,NDCG@5:0.3161) [0.3 s] *

Epoch 5     loss=0.1359 [4.5 s]	dev=(HR@5:0.4273,NDCG@5:0.3216) [0.3 s] *

Epoch 6     loss=0.1015 [4.5 s]	dev=(HR@5:0.4323,NDCG@5:0.3280) [0.4 s] *

Epoch 7     loss=0.0805 [4.5 s]	dev=(HR@5:0.4282,NDCG@5:0.3275) [0.3 s]

Epoch 8     loss=0.0666 [4.5 s]	dev=(HR@5:0.4254,NDCG@5:0.3237) [0.4 s]

Epoch 9     loss=0.0543 [4.4 s]	dev=(HR@5:0.4183,NDCG@5:0.3214) [0.4 s]

Epoch 10    loss=0.0482 [4.4 s]	dev=(HR@5:0.4220,NDCG@5:0.3250) [0.4 s]

Epoch 11    loss=0.0414 [4.5 s]	dev=(HR@5:0.4200,NDCG@5:0.3224) [0.3 s]

Epoch 12    loss=0.0359 [4.5 s]	dev=(HR@5:0.4227,NDCG@5:0.3259) [0.3 s]

Epoch 13    loss=0.0334 [4.5 s]	dev=(HR@5:0.4176,NDCG@5:0.3225) [0.3 s]

Epoch 14    loss=0.0317 [4.5 s]	dev=(HR@5:0.4148,NDCG@5:0.3211) [0.3 s]

Epoch 15    loss=0.0305 [4.5 s]	dev=(HR@5:0.4175,NDCG@5:0.3238) [0.3 s]
Early stop at 15 based on dev result.

Best Iter(dev)=    6	 dev=(HR@5:0.4323,NDCG@5:0.3280) [72.6 s] 
Load model from ../model/SASRec/SASRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.4323,NDCG@5:0.3280,HR@10:0.5277,NDCG@10:0.3589,HR@20:0.6310,NDCG@20:0.3848,HR@50:0.8132,NDCG@50:0.4208)

Test After Training: (HR@5:0.3841,NDCG@5:0.2846,HR@10:0.4784,NDCG@10:0.3150,HR@20:0.5843,NDCG@20:0.3417,HR@50:0.7806,NDCG@50:0.3804)
Saving top-100 recommendation results to: ../log/SASRec/SASRec__Grocery_and_Gourmet_Food__0__lr=0/rec-SASRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/SASRec/SASRec__Grocery_and_Gourmet_Food__0__lr=0/rec-SASRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 14:04:23 ---------------------------------------------
运行 GRU4Rec...
Namespace(model_name='GRU4Rec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 14:04:24 ---------------------------------------------

===========================================
 Arguments          | Values               
===========================================
 batch_size         | 256                 
 data_appendix      |                     
 dataset            | Grocery_and_Gourm...
 dropout            | 0.3                 
 early_stop         | 10                  
 emb_size           | 128                 
 epoch              | 100                 
 eval_batch_size    | 256                 
 gpu                | 0                   
 hidden_size        | 128                 
 history_max        | 20                  
 l2                 | 1e-05               
 lr                 | 0.0005              
 main_metric        |                     
 num_neg            | 1                   
 num_workers        | 5                   
 optimizer          | Adam                
 random_seed        | 0                   
 save_final_results | 1                   
 test_all           | 0                   
 topk               | 5,10,20,50          
===========================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1230976
GRU4Rec(
  (i_embeddings): Embedding(8714, 128)
  (rnn): GRU(128, 128, batch_first=True)
  (out): Linear(in_features=128, out_features=128, bias=True)
)

Test Before Training: (HR@5:0.0539,NDCG@5:0.0315,HR@10:0.1031,NDCG@10:0.0472,HR@20:0.2016,NDCG@20:0.0718,HR@50:0.5068,NDCG@50:0.1315)
Optimizer: Adam

Epoch 1     loss=0.4938 [2.3 s]	dev=(HR@5:0.2404,NDCG@5:0.1564) [0.3 s] *

Epoch 2     loss=0.4267 [2.1 s]	dev=(HR@5:0.2880,NDCG@5:0.1922) [0.3 s] *

Epoch 3     loss=0.3960 [2.1 s]	dev=(HR@5:0.3220,NDCG@5:0.2153) [0.3 s] *

Epoch 4     loss=0.3722 [2.1 s]	dev=(HR@5:0.3446,NDCG@5:0.2334) [0.3 s] *

Epoch 5     loss=0.3512 [2.2 s]	dev=(HR@5:0.3538,NDCG@5:0.2405) [0.3 s] *

Epoch 6     loss=0.3343 [2.1 s]	dev=(HR@5:0.3610,NDCG@5:0.2458) [0.3 s] *

Epoch 7     loss=0.3219 [2.1 s]	dev=(HR@5:0.3681,NDCG@5:0.2524) [0.3 s] *

Epoch 8     loss=0.3095 [2.2 s]	dev=(HR@5:0.3740,NDCG@5:0.2595) [0.3 s] *

Epoch 9     loss=0.2956 [2.2 s]	dev=(HR@5:0.3718,NDCG@5:0.2568) [0.3 s]

Epoch 10    loss=0.2833 [2.1 s]	dev=(HR@5:0.3748,NDCG@5:0.2602) [0.3 s] *

Epoch 11    loss=0.2729 [2.1 s]	dev=(HR@5:0.3743,NDCG@5:0.2593) [0.3 s]

Epoch 12    loss=0.2616 [2.1 s]	dev=(HR@5:0.3733,NDCG@5:0.2582) [0.3 s]

Epoch 13    loss=0.2524 [2.1 s]	dev=(HR@5:0.3766,NDCG@5:0.2626) [0.3 s] *

Epoch 14    loss=0.2449 [2.2 s]	dev=(HR@5:0.3747,NDCG@5:0.2605) [0.3 s]

Epoch 15    loss=0.2397 [2.1 s]	dev=(HR@5:0.3702,NDCG@5:0.2613) [0.3 s]

Epoch 16    loss=0.2326 [2.2 s]	dev=(HR@5:0.3784,NDCG@5:0.2625) [0.3 s]

Epoch 17    loss=0.2233 [2.2 s]	dev=(HR@5:0.3694,NDCG@5:0.2591) [0.3 s]

Epoch 18    loss=0.2140 [2.1 s]	dev=(HR@5:0.3826,NDCG@5:0.2720) [0.3 s] *

Epoch 19    loss=0.2071 [2.2 s]	dev=(HR@5:0.3742,NDCG@5:0.2677) [0.3 s]

Epoch 20    loss=0.2007 [2.1 s]	dev=(HR@5:0.3832,NDCG@5:0.2754) [0.3 s] *

Epoch 21    loss=0.1919 [2.1 s]	dev=(HR@5:0.3802,NDCG@5:0.2709) [0.3 s]

Epoch 22    loss=0.1885 [2.4 s]	dev=(HR@5:0.3796,NDCG@5:0.2750) [0.3 s]

Epoch 23    loss=0.1852 [2.2 s]	dev=(HR@5:0.3769,NDCG@5:0.2724) [0.3 s]

Epoch 24    loss=0.1828 [2.2 s]	dev=(HR@5:0.3842,NDCG@5:0.2782) [0.3 s] *

Epoch 25    loss=0.1734 [2.2 s]	dev=(HR@5:0.3891,NDCG@5:0.2819) [0.3 s] *

Epoch 26    loss=0.1724 [2.2 s]	dev=(HR@5:0.3846,NDCG@5:0.2783) [0.3 s]

Epoch 27    loss=0.1669 [2.1 s]	dev=(HR@5:0.3857,NDCG@5:0.2808) [0.3 s]

Epoch 28    loss=0.1657 [2.3 s]	dev=(HR@5:0.3861,NDCG@5:0.2819) [0.3 s]

Epoch 29    loss=0.1604 [2.2 s]	dev=(HR@5:0.3783,NDCG@5:0.2740) [0.3 s]

Epoch 30    loss=0.1544 [2.3 s]	dev=(HR@5:0.3859,NDCG@5:0.2803) [0.3 s]

Epoch 31    loss=0.1526 [2.3 s]	dev=(HR@5:0.3921,NDCG@5:0.2849) [0.3 s] *

Epoch 32    loss=0.1498 [2.2 s]	dev=(HR@5:0.3860,NDCG@5:0.2790) [0.3 s]

Epoch 33    loss=0.1459 [2.2 s]	dev=(HR@5:0.3889,NDCG@5:0.2854) [0.3 s] *

Epoch 34    loss=0.1435 [2.3 s]	dev=(HR@5:0.3860,NDCG@5:0.2825) [0.3 s]

Epoch 35    loss=0.1402 [2.3 s]	dev=(HR@5:0.3894,NDCG@5:0.2839) [0.3 s]

Epoch 36    loss=0.1352 [2.2 s]	dev=(HR@5:0.3836,NDCG@5:0.2806) [0.3 s]

Epoch 37    loss=0.1347 [2.3 s]	dev=(HR@5:0.3865,NDCG@5:0.2833) [0.3 s]

Epoch 38    loss=0.1308 [2.2 s]	dev=(HR@5:0.3907,NDCG@5:0.2853) [0.3 s]

Epoch 39    loss=0.1271 [2.3 s]	dev=(HR@5:0.3846,NDCG@5:0.2793) [0.3 s]

Epoch 40    loss=0.1237 [2.3 s]	dev=(HR@5:0.3859,NDCG@5:0.2836) [0.3 s]

Epoch 41    loss=0.1241 [2.3 s]	dev=(HR@5:0.3889,NDCG@5:0.2853) [0.3 s]

Epoch 42    loss=0.1192 [2.3 s]	dev=(HR@5:0.3904,NDCG@5:0.2853) [0.3 s]
Early stop at 42 based on dev result.

Best Iter(dev)=   33	 dev=(HR@5:0.3889,NDCG@5:0.2854) [104.4 s] 
Load model from ../model/GRU4Rec/GRU4Rec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.3889,NDCG@5:0.2854,HR@10:0.4920,NDCG@10:0.3186,HR@20:0.6137,NDCG@20:0.3492,HR@50:0.8271,NDCG@50:0.3916)

Test After Training: (HR@5:0.3466,NDCG@5:0.2488,HR@10:0.4487,NDCG@10:0.2818,HR@20:0.5730,NDCG@20:0.3131,HR@50:0.7977,NDCG@50:0.3575)
Saving top-100 recommendation results to: ../log/GRU4Rec/GRU4Rec__Grocery_and_Gourmet_Food__0__lr=0/rec-GRU4Rec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/GRU4Rec/GRU4Rec__Grocery_and_Gourmet_Food__0__lr=0/rec-GRU4Rec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 14:06:14 ---------------------------------------------
运行 DreamRec...
Namespace(model_name='DreamRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 14:06:15 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_scale             | 1.0                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 10                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 schedule_sampler_name | uniform             
 test_all              | 0                   
 topk                  | 5,10,20,50          
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1906176
DreamRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8715, 128, padding_idx=0)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (net): Diffu_xstart(
    (time_embed): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): SiLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
    )
    (norm_diffu_rep): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (mlp): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): SiLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=512, out_features=128, bias=True)
      (4): Linear(in_features=128, out_features=512, bias=True)
      (5): SiLU()
      (6): Dropout(p=0.3, inplace=False)
      (7): Linear(in_features=512, out_features=128, bias=True)
    )
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (ag_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): Sequential(
        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=128, out_features=512, bias=True)
        (2): SiLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=512, out_features=128, bias=True)
        (5): Dropout(p=0.3, inplace=False)
      )
      (1): Sequential(
        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=128, out_features=512, bias=True)
        (2): SiLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=512, out_features=128, bias=True)
        (5): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0502,NDCG@5:0.0295,HR@10:0.1014,NDCG@10:0.0459,HR@20:0.2050,NDCG@20:0.0717,HR@50:0.4985,NDCG@50:0.1291)
Optimizer: Adam

Epoch 1     loss=0.5060 [5.1 s]	dev=(HR@5:0.2381,NDCG@5:0.1558) [3.5 s] *

Epoch 2     loss=0.4522 [5.1 s]	dev=(HR@5:0.2467,NDCG@5:0.1619) [3.5 s] *

Epoch 3     loss=0.4384 [5.1 s]	dev=(HR@5:0.2571,NDCG@5:0.1684) [3.5 s] *

Epoch 4     loss=0.4309 [5.1 s]	dev=(HR@5:0.2608,NDCG@5:0.1705) [3.5 s] *

Epoch 5     loss=0.4260 [5.2 s]	dev=(HR@5:0.2644,NDCG@5:0.1715) [3.5 s] *

Epoch 6     loss=0.4221 [5.2 s]	dev=(HR@5:0.2622,NDCG@5:0.1702) [3.5 s]

Epoch 7     loss=0.4195 [5.1 s]	dev=(HR@5:0.2654,NDCG@5:0.1728) [3.5 s] *

Epoch 8     loss=0.4203 [5.1 s]	dev=(HR@5:0.2611,NDCG@5:0.1695) [3.5 s]

Epoch 9     loss=0.4189 [5.2 s]	dev=(HR@5:0.2635,NDCG@5:0.1707) [3.5 s]

Epoch 10    loss=0.4177 [5.0 s]	dev=(HR@5:0.2603,NDCG@5:0.1684) [3.5 s]

Epoch 11    loss=0.4179 [5.0 s]	dev=(HR@5:0.2630,NDCG@5:0.1704) [3.5 s]

Epoch 12    loss=0.4171 [5.1 s]	dev=(HR@5:0.2650,NDCG@5:0.1708) [3.5 s]

Epoch 13    loss=0.4157 [5.0 s]	dev=(HR@5:0.2614,NDCG@5:0.1702) [3.5 s]

Epoch 14    loss=0.4143 [5.1 s]	dev=(HR@5:0.2653,NDCG@5:0.1723) [3.5 s]

Epoch 15    loss=0.4148 [5.1 s]	dev=(HR@5:0.2680,NDCG@5:0.1727) [3.5 s]

Epoch 16    loss=0.4154 [5.1 s]	dev=(HR@5:0.2636,NDCG@5:0.1706) [3.5 s]
Early stop at 16 based on dev result.

Best Iter(dev)=    7	 dev=(HR@5:0.2654,NDCG@5:0.1728) [137.7 s] 
Load model from ../model/DreamRec/DreamRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2654,NDCG@5:0.1728,HR@10:0.3942,NDCG@10:0.2142,HR@20:0.5340,NDCG@20:0.2495,HR@50:0.7348,NDCG@50:0.2893)

Test After Training: (HR@5:0.2261,NDCG@5:0.1425,HR@10:0.3438,NDCG@10:0.1805,HR@20:0.4759,NDCG@20:0.2139,HR@50:0.6861,NDCG@50:0.2556)
Saving top-100 recommendation results to: ../log/DreamRec/DreamRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DreamRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/DreamRec/DreamRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DreamRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 14:08:55 ---------------------------------------------
运行 DiffuRec...
Namespace(model_name='DiffuRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 14:08:56 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_scale             | 1.0                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 10                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 1                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent           | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 schedule_sampler_name | uniform             
 test_all              | 0                   
 topk                  | 5,10,20,50          
==============================================
Device: cpu
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1775616
DiffuRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8715, 128, padding_idx=0)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (net): Diffu_xstart(
    (time_embed): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): SiLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
    )
    (transencoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (norm_diffu_rep): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0480,NDCG@5:0.0281,HR@10:0.0975,NDCG@10:0.0438,HR@20:0.2001,NDCG@20:0.0695,HR@50:0.5024,NDCG@50:0.1285)
Optimizer: Adam

Epoch 1     loss=0.5168 [36.2 s]	dev=(HR@5:0.2378,NDCG@5:0.1552) [67.0 s] *

Epoch 2     loss=0.4515 [37.1 s]	dev=(HR@5:0.2426,NDCG@5:0.1587) [65.2 s] *

Epoch 3     loss=0.4342 [36.0 s]	dev=(HR@5:0.2567,NDCG@5:0.1683) [64.5 s] *

Epoch 4     loss=0.4218 [36.3 s]	dev=(HR@5:0.2671,NDCG@5:0.1747) [64.2 s] *

Epoch 5     loss=0.4125 [36.9 s]	dev=(HR@5:0.2650,NDCG@5:0.1738) [64.9 s]

Epoch 6     loss=0.4041 [36.8 s]	dev=(HR@5:0.2669,NDCG@5:0.1741) [64.9 s]

Epoch 7     loss=0.3986 [37.6 s]	dev=(HR@5:0.2650,NDCG@5:0.1747) [66.1 s] *

Epoch 8     loss=0.3959 [37.4 s]	dev=(HR@5:0.2643,NDCG@5:0.1731) [63.6 s]

Epoch 9     loss=0.3917 [37.8 s]	dev=(HR@5:0.2667,NDCG@5:0.1765) [64.3 s] *

Epoch 10    loss=0.3885 [36.9 s]	dev=(HR@5:0.2686,NDCG@5:0.1778) [66.2 s] *

Epoch 11    loss=0.3867 [37.3 s]	dev=(HR@5:0.2661,NDCG@5:0.1734) [65.9 s]

Epoch 12    loss=0.3834 [37.7 s]	dev=(HR@5:0.2676,NDCG@5:0.1766) [65.1 s]

Epoch 13    loss=0.3805 [39.0 s]	dev=(HR@5:0.2662,NDCG@5:0.1762) [64.6 s]

Epoch 14    loss=0.3794 [37.7 s]	dev=(HR@5:0.2671,NDCG@5:0.1773) [66.3 s]

Epoch 15    loss=0.3791 [37.7 s]	dev=(HR@5:0.2691,NDCG@5:0.1778) [64.3 s] *

Epoch 16    loss=0.3775 [37.6 s]	dev=(HR@5:0.2686,NDCG@5:0.1783) [64.3 s] *

Epoch 17    loss=0.3753 [37.5 s]	dev=(HR@5:0.2687,NDCG@5:0.1771) [70.6 s]

Epoch 18    loss=0.3757 [38.2 s]	dev=(HR@5:0.2690,NDCG@5:0.1785) [63.2 s] *

Epoch 19    loss=0.3732 [37.2 s]	dev=(HR@5:0.2685,NDCG@5:0.1791) [65.8 s] *

Epoch 20    loss=0.3748 [37.0 s]	dev=(HR@5:0.2662,NDCG@5:0.1781) [66.9 s]

Epoch 21    loss=0.3712 [38.3 s]	dev=(HR@5:0.2689,NDCG@5:0.1806) [69.3 s] *

Epoch 22    loss=0.3718 [37.4 s]	dev=(HR@5:0.2692,NDCG@5:0.1808) [71.0 s] *

Epoch 23    loss=0.3710 [37.5 s]	dev=(HR@5:0.2683,NDCG@5:0.1800) [70.3 s]

Epoch 24    loss=0.3714 [38.2 s]	dev=(HR@5:0.2695,NDCG@5:0.1808) [67.3 s] *

Epoch 25    loss=0.3691 [36.9 s]	dev=(HR@5:0.2670,NDCG@5:0.1797) [68.1 s]

Epoch 26    loss=0.3698 [37.6 s]	dev=(HR@5:0.2684,NDCG@5:0.1798) [67.2 s]

Epoch 27    loss=0.3696 [37.9 s]	dev=(HR@5:0.2671,NDCG@5:0.1793) [64.3 s]

Epoch 28    loss=0.3692 [37.8 s]	dev=(HR@5:0.2696,NDCG@5:0.1808) [67.3 s]

Epoch 29    loss=0.3701 [37.2 s]	dev=(HR@5:0.2707,NDCG@5:0.1804) [66.5 s]

Epoch 30    loss=0.3675 [37.0 s]	dev=(HR@5:0.2682,NDCG@5:0.1798) [67.3 s]

Epoch 31    loss=0.3687 [38.6 s]	dev=(HR@5:0.2725,NDCG@5:0.1825) [65.7 s] *

Epoch 32    loss=0.3689 [37.9 s]	dev=(HR@5:0.2701,NDCG@5:0.1798) [64.5 s]

Epoch 33    loss=0.3675 [37.2 s]	dev=(HR@5:0.2674,NDCG@5:0.1787) [66.9 s]

Epoch 34    loss=0.3674 [37.5 s]	dev=(HR@5:0.2679,NDCG@5:0.1794) [63.9 s]

Epoch 35    loss=0.3656 [36.1 s]	dev=(HR@5:0.2705,NDCG@5:0.1807) [63.6 s]

Epoch 36    loss=0.3659 [35.5 s]	dev=(HR@5:0.2689,NDCG@5:0.1817) [63.6 s]

Epoch 37    loss=0.3682 [37.7 s]	dev=(HR@5:0.2697,NDCG@5:0.1808) [64.8 s]

Epoch 38    loss=0.3677 [38.1 s]	dev=(HR@5:0.2729,NDCG@5:0.1832) [65.2 s] *

Epoch 39    loss=0.3665 [37.3 s]	dev=(HR@5:0.2705,NDCG@5:0.1821) [64.0 s]

Epoch 40    loss=0.3659 [36.8 s]	dev=(HR@5:0.2706,NDCG@5:0.1822) [65.0 s]

Epoch 41    loss=0.3672 [37.6 s]	dev=(HR@5:0.2692,NDCG@5:0.1805) [66.4 s]

Epoch 42    loss=0.3655 [38.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1829) [65.1 s]

Epoch 43    loss=0.3665 [36.5 s]	dev=(HR@5:0.2685,NDCG@5:0.1813) [63.8 s]

Epoch 44    loss=0.3663 [36.5 s]	dev=(HR@5:0.2682,NDCG@5:0.1806) [64.9 s]

Epoch 45    loss=0.3640 [36.0 s]	dev=(HR@5:0.2676,NDCG@5:0.1801) [65.1 s]

Epoch 46    loss=0.3661 [38.6 s]	dev=(HR@5:0.2650,NDCG@5:0.1782) [66.8 s]

Epoch 47    loss=0.3663 [37.4 s]	dev=(HR@5:0.2683,NDCG@5:0.1806) [64.3 s]
Early stop at 47 based on dev result.

Best Iter(dev)=   38	 dev=(HR@5:0.2729,NDCG@5:0.1832) [4845.2 s] 
Load model from ../model/DiffuRec/DiffuRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2730,NDCG@5:0.1832,HR@10:0.3943,NDCG@10:0.2222,HR@20:0.5303,NDCG@20:0.2566,HR@50:0.7340,NDCG@50:0.2969)

Test After Training: (HR@5:0.2302,NDCG@5:0.1503,HR@10:0.3430,NDCG@10:0.1867,HR@20:0.4705,NDCG@20:0.2190,HR@50:0.6802,NDCG@50:0.2605)
Saving top-100 recommendation results to: ../log/DiffuRec/DiffuRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DiffuRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/DiffuRec/DiffuRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DiffuRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 15:35:14 ---------------------------------------------
运行 ADRec...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 19:36:34 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 100                 
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5518 [4.3 s] dev=(HR@5:0.2363,NDCG@5:0.1543) [11.5 s] *                          
Epoch 2     loss=0.3598 [4.3 s] dev=(HR@5:0.2621,NDCG@5:0.1773) [11.5 s] *                          
Epoch 3     loss=0.2607 [4.3 s] dev=(HR@5:0.2678,NDCG@5:0.1854) [11.4 s] *                          
Epoch 4     loss=0.1930 [4.2 s] dev=(HR@5:0.2694,NDCG@5:0.1877) [11.5 s] *                          
Epoch 5     loss=0.1454 [4.2 s] dev=(HR@5:0.2699,NDCG@5:0.1885) [11.5 s] *                          
Epoch 6     loss=0.1129 [4.3 s] dev=(HR@5:0.2650,NDCG@5:0.1857) [11.5 s] *                          
Epoch 7     loss=0.0917 [4.3 s] dev=(HR@5:0.2663,NDCG@5:0.1879) [11.5 s] *                          
Epoch 8     loss=0.0765 [4.3 s] dev=(HR@5:0.2637,NDCG@5:0.1850) [11.5 s] *                          
Epoch 9     loss=0.0651 [4.2 s] dev=(HR@5:0.2632,NDCG@5:0.1841) [11.5 s] *                          
Epoch 10    loss=0.0582 [4.3 s] dev=(HR@5:0.2626,NDCG@5:0.1840) [11.5 s] *                          
Epoch 11    loss=0.0505 [4.3 s] dev=(HR@5:0.2595,NDCG@5:0.1828) [11.5 s] *                          
Epoch 12    loss=0.0454 [4.3 s] dev=(HR@5:0.2658,NDCG@5:0.1857) [11.4 s] *                          
Epoch 13    loss=0.0428 [4.2 s] dev=(HR@5:0.2622,NDCG@5:0.1845) [11.5 s] *                          
Epoch 14    loss=0.0407 [4.3 s] dev=(HR@5:0.2654,NDCG@5:0.1845) [11.5 s] *                          
Epoch 15    loss=0.0380 [4.2 s] dev=(HR@5:0.2644,NDCG@5:0.1819) [11.5 s] *                          
Epoch 16    loss=0.0355 [4.2 s] dev=(HR@5:0.2633,NDCG@5:0.1836) [11.5 s] *                          
Epoch 17    loss=0.0329 [4.3 s] dev=(HR@5:0.2637,NDCG@5:0.1841) [11.5 s] *                          
Epoch 18    loss=0.0329 [4.3 s] dev=(HR@5:0.2626,NDCG@5:0.1816) [11.5 s] *                          
Epoch 19    loss=0.0307 [4.3 s] dev=(HR@5:0.2637,NDCG@5:0.1840) [11.5 s] *                          
Epoch 20    loss=0.0306 [4.3 s] dev=(HR@5:0.2664,NDCG@5:0.1851) [11.5 s] *                          
Epoch 21    loss=0.0292 [4.3 s] dev=(HR@5:0.2667,NDCG@5:0.1842) [11.5 s] *                          
Epoch 22    loss=0.0276 [4.3 s] dev=(HR@5:0.2710,NDCG@5:0.1872) [11.5 s] *                          
Epoch 23    loss=0.0273 [4.3 s] dev=(HR@5:0.2697,NDCG@5:0.1864) [11.5 s] *                          
Epoch 24    loss=0.0277 [4.3 s] dev=(HR@5:0.2736,NDCG@5:0.1885) [11.4 s] *                          
Epoch 25    loss=0.0269 [4.3 s] dev=(HR@5:0.2702,NDCG@5:0.1855) [11.5 s] *                          
Epoch 26    loss=0.0257 [4.3 s] dev=(HR@5:0.2682,NDCG@5:0.1849) [11.5 s] *                          
Epoch 27    loss=0.0263 [4.3 s] dev=(HR@5:0.2698,NDCG@5:0.1871) [11.5 s] *                          
Epoch 28    loss=0.0255 [4.2 s] dev=(HR@5:0.2702,NDCG@5:0.1850) [11.5 s] *                          
Epoch 29    loss=0.0242 [4.3 s] dev=(HR@5:0.2718,NDCG@5:0.1858) [11.5 s] *                          
Epoch 30    loss=0.0245 [4.2 s] dev=(HR@5:0.2710,NDCG@5:0.1856) [11.5 s] *                          
Epoch 31    loss=0.0240 [4.3 s] dev=(HR@5:0.2695,NDCG@5:0.1865) [11.4 s] *                          
Epoch 32    loss=0.0243 [4.2 s] dev=(HR@5:0.2672,NDCG@5:0.1859) [11.5 s] *                          
Epoch 33    loss=0.0239 [4.2 s] dev=(HR@5:0.2672,NDCG@5:0.1859) [11.5 s] *                          
Epoch 34    loss=0.0227 [4.3 s] dev=(HR@5:0.2687,NDCG@5:0.1856) [11.5 s] *                          
Epoch 35    loss=0.0227 [4.2 s] dev=(HR@5:0.2677,NDCG@5:0.1859) [11.5 s] *                          
Epoch 36    loss=0.0223 [4.3 s] dev=(HR@5:0.2689,NDCG@5:0.1867) [11.5 s] *                          
Epoch 37    loss=0.0227 [4.3 s] dev=(HR@5:0.2706,NDCG@5:0.1879) [11.5 s] *                          
Epoch 38    loss=0.0228 [4.3 s] dev=(HR@5:0.2650,NDCG@5:0.1839) [11.5 s] *                          
Epoch 39    loss=0.0225 [4.2 s] dev=(HR@5:0.2670,NDCG@5:0.1843) [11.5 s] *                          
Epoch 40    loss=0.0209 [4.3 s] dev=(HR@5:0.2717,NDCG@5:0.1862) [11.5 s] *                          
Epoch 41    loss=0.0225 [4.3 s] dev=(HR@5:0.2695,NDCG@5:0.1855) [11.5 s] *                          
Epoch 42    loss=0.0229 [4.2 s] dev=(HR@5:0.2691,NDCG@5:0.1842) [11.5 s] *                          
Epoch 43    loss=0.0219 [4.2 s] dev=(HR@5:0.2683,NDCG@5:0.1853) [11.5 s] *                          
Epoch 44    loss=0.0215 [4.2 s] dev=(HR@5:0.2696,NDCG@5:0.1859) [11.5 s] *                          
Epoch 45    loss=0.0208 [4.2 s] dev=(HR@5:0.2710,NDCG@5:0.1877) [11.5 s] *                          
Epoch 46    loss=0.0219 [4.2 s] dev=(HR@5:0.2688,NDCG@5:0.1862) [11.5 s] *                          
Epoch 47    loss=0.0226 [4.2 s] dev=(HR@5:0.2693,NDCG@5:0.1866) [11.5 s] *                          
Epoch 48    loss=0.0214 [4.3 s] dev=(HR@5:0.2711,NDCG@5:0.1863) [11.4 s] *                          
Epoch 49    loss=0.0216 [4.2 s] dev=(HR@5:0.2743,NDCG@5:0.1892) [11.5 s] *                          
Epoch 50    loss=0.0210 [4.2 s] dev=(HR@5:0.2720,NDCG@5:0.1879) [11.5 s] *                          
Epoch 51    loss=0.0207 [4.2 s] dev=(HR@5:0.2713,NDCG@5:0.1876) [11.5 s] *                          
Epoch 52    loss=0.0206 [4.3 s] dev=(HR@5:0.2693,NDCG@5:0.1870) [11.5 s] *                          
Epoch 53    loss=0.0202 [4.3 s] dev=(HR@5:0.2736,NDCG@5:0.1885) [11.5 s] *                          
Epoch 54    loss=0.0203 [4.3 s] dev=(HR@5:0.2718,NDCG@5:0.1876) [11.4 s] *                          
Epoch 55    loss=0.0204 [4.2 s] dev=(HR@5:0.2704,NDCG@5:0.1876) [11.5 s] *                          
Epoch 56    loss=0.0193 [4.3 s] dev=(HR@5:0.2717,NDCG@5:0.1880) [11.5 s] *                          
Epoch 57    loss=0.0196 [4.3 s] dev=(HR@5:0.2740,NDCG@5:0.1889) [11.5 s] *                          
Epoch 58    loss=0.0202 [4.2 s] dev=(HR@5:0.2749,NDCG@5:0.1885) [11.5 s] *                          
Epoch 59    loss=0.0203 [4.3 s] dev=(HR@5:0.2740,NDCG@5:0.1891) [11.4 s] *                          
Epoch 60    loss=0.0209 [4.3 s] dev=(HR@5:0.2729,NDCG@5:0.1881) [11.5 s] *                          
Epoch 61    loss=0.0211 [4.2 s] dev=(HR@5:0.2730,NDCG@5:0.1878) [11.5 s] *                          
Epoch 62    loss=0.0202 [4.2 s] dev=(HR@5:0.2717,NDCG@5:0.1871) [11.5 s] *                          
Epoch 63    loss=0.0200 [4.3 s] dev=(HR@5:0.2737,NDCG@5:0.1879) [11.5 s] *                          
Epoch 64    loss=0.0204 [4.3 s] dev=(HR@5:0.2701,NDCG@5:0.1869) [11.5 s] *                          
Epoch 65    loss=0.0203 [4.3 s] dev=(HR@5:0.2707,NDCG@5:0.1875) [11.5 s] *                          
Epoch 66    loss=0.0194 [4.3 s] dev=(HR@5:0.2708,NDCG@5:0.1863) [11.5 s] *                          
Epoch 67    loss=0.0196 [4.3 s] dev=(HR@5:0.2687,NDCG@5:0.1868) [11.5 s] *                          
Epoch 68    loss=0.0200 [4.2 s] dev=(HR@5:0.2693,NDCG@5:0.1868) [11.4 s] *                          
Epoch 69    loss=0.0197 [4.3 s] dev=(HR@5:0.2685,NDCG@5:0.1861) [11.4 s] *                          
Epoch 70    loss=0.0200 [4.3 s] dev=(HR@5:0.2698,NDCG@5:0.1874) [11.5 s] *                          
Epoch 71    loss=0.0198 [4.3 s] dev=(HR@5:0.2723,NDCG@5:0.1900) [11.5 s] *                          
Epoch 72    loss=0.0191 [4.3 s] dev=(HR@5:0.2702,NDCG@5:0.1889) [11.5 s] *                          
Epoch 73    loss=0.0192 [4.3 s] dev=(HR@5:0.2737,NDCG@5:0.1896) [11.5 s] *                          
Epoch 74    loss=0.0197 [4.3 s] dev=(HR@5:0.2749,NDCG@5:0.1890) [11.5 s] *                          
Epoch 75    loss=0.0188 [4.2 s] dev=(HR@5:0.2756,NDCG@5:0.1901) [11.5 s] *                          
Epoch 76    loss=0.0203 [4.2 s] dev=(HR@5:0.2748,NDCG@5:0.1901) [11.5 s] *                          
Epoch 77    loss=0.0200 [4.3 s] dev=(HR@5:0.2726,NDCG@5:0.1890) [11.5 s] *                          
Epoch 78    loss=0.0186 [4.3 s] dev=(HR@5:0.2727,NDCG@5:0.1892) [11.5 s] *                          
Epoch 79    loss=0.0194 [4.4 s] dev=(HR@5:0.2744,NDCG@5:0.1905) [11.6 s] *                          
Epoch 80    loss=0.0199 [4.3 s] dev=(HR@5:0.2750,NDCG@5:0.1903) [11.6 s] *                          
Epoch 81    loss=0.0186 [4.3 s] dev=(HR@5:0.2766,NDCG@5:0.1910) [11.7 s] *                          
Epoch 82    loss=0.0187 [4.4 s] dev=(HR@5:0.2769,NDCG@5:0.1914) [11.7 s] *                          
Epoch 83    loss=0.0195 [4.3 s] dev=(HR@5:0.2775,NDCG@5:0.1921) [11.5 s] *                          
Epoch 84    loss=0.0191 [4.3 s] dev=(HR@5:0.2797,NDCG@5:0.1927) [11.5 s] *                          
Epoch 85    loss=0.0194 [4.3 s] dev=(HR@5:0.2766,NDCG@5:0.1915) [11.6 s] *                          
Epoch 86    loss=0.0197 [4.3 s] dev=(HR@5:0.2763,NDCG@5:0.1909) [11.6 s] *                          
Epoch 87    loss=0.0186 [4.3 s] dev=(HR@5:0.2727,NDCG@5:0.1890) [11.6 s] *                          
Epoch 88    loss=0.0183 [4.4 s] dev=(HR@5:0.2725,NDCG@5:0.1895) [11.6 s] *                          
Epoch 89    loss=0.0188 [4.3 s] dev=(HR@5:0.2731,NDCG@5:0.1887) [11.6 s] *                          
Epoch 90    loss=0.0188 [4.4 s] dev=(HR@5:0.2716,NDCG@5:0.1886) [11.7 s] *                          
Epoch 91    loss=0.0194 [4.4 s] dev=(HR@5:0.2703,NDCG@5:0.1878) [11.7 s] *                          
Epoch 92    loss=0.0186 [4.4 s] dev=(HR@5:0.2704,NDCG@5:0.1872) [11.5 s] *                          
Epoch 93    loss=0.0193 [4.3 s] dev=(HR@5:0.2718,NDCG@5:0.1878) [11.5 s] *                          
Epoch 94    loss=0.0193 [4.3 s] dev=(HR@5:0.2700,NDCG@5:0.1862) [11.5 s] *                          
Epoch 95    loss=0.0194 [4.2 s] dev=(HR@5:0.2676,NDCG@5:0.1849) [11.5 s] *                          
Epoch 96    loss=0.0191 [4.3 s] dev=(HR@5:0.2725,NDCG@5:0.1886) [11.5 s] *                          
Epoch 97    loss=0.0188 [4.2 s] dev=(HR@5:0.2721,NDCG@5:0.1886) [11.5 s] *                          
Epoch 98    loss=0.0194 [4.3 s] dev=(HR@5:0.2732,NDCG@5:0.1881) [11.5 s] *                          
Epoch 99    loss=0.0192 [4.3 s] dev=(HR@5:0.2732,NDCG@5:0.1879) [11.5 s] *                          
Epoch 100   loss=0.0189 [4.2 s] dev=(HR@5:0.2744,NDCG@5:0.1882) [11.5 s] *                          

Best Iter(dev)=   84     dev=(HR@5:0.2797,NDCG@5:0.1927) [1578.4 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
                                                                                                    
Dev  After Training: (HR@5:0.2744,NDCG@5:0.1882,HR@10:0.3718,NDCG@10:0.2198,HR@20:0.4853,NDCG@20:0.2483,HR@50:0.7064,NDCG@50:0.2918)
                                                                                                    
Test After Training: (HR@5:0.2393,NDCG@5:0.1661,HR@10:0.3319,NDCG@10:0.1960,HR@20:0.4373,NDCG@20:0.2226,HR@50:0.6669,NDCG@50:0.2678)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!                                                                       
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!                                                                      

--------------------------------------------- END: 2025-12-23 20:03:55 ---------------------------------------------
1. 模型对比实验 - MovieLens_1M 数据集
-------------------------------------
运行 SASRec...
Namespace(model_name='SASRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 15:45:22 ---------------------------------------------

===================================
 Arguments          | Values       
===================================
 batch_size         | 256         
 data_appendix      |             
 dataset            | MovieLens_1M
 dropout            | 0.3         
 early_stop         | 10          
 emb_size           | 128         
 epoch              | 100         
 eval_batch_size    | 256         
 gpu                | 0           
 history_max        | 20          
 l2                 | 1e-05       
 lr                 | 0.0005      
 main_metric        |             
 num_heads          | 4           
 num_layers         | 2           
 num_neg            | 1           
 num_workers        | 5           
 optimizer          | Adam        
 random_seed        | 0           
 save_final_results | 1           
 test_all           | 0           
 topk               | 5,10,20,50  
===================================
Device: cuda
Load corpus from data/MovieLens_1M/SeqReader.pkl
#params: 568960
SASRec(
  (i_embeddings): Embedding(3126, 128)
  (p_embeddings): Embedding(21, 128)
  (transformer_block): ModuleList(
    (0): TransformerLayer(
      (masked_attn_head): MultiHeadAttention(
        (q_linear): Linear(in_features=128, out_features=128, bias=True)
        (k_linear): Linear(in_features=128, out_features=128, bias=True)
        (v_linear): Linear(in_features=128, out_features=128, bias=True)
      )
      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.3, inplace=False)
      (linear1): Linear(in_features=128, out_features=128, bias=True)
      (linear2): Linear(in_features=128, out_features=128, bias=True)
      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout2): Dropout(p=0.3, inplace=False)
    )
    (1): TransformerLayer(
      (masked_attn_head): MultiHeadAttention(
        (q_linear): Linear(in_features=128, out_features=128, bias=True)
        (k_linear): Linear(in_features=128, out_features=128, bias=True)
        (v_linear): Linear(in_features=128, out_features=128, bias=True)
      )
      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout1): Dropout(p=0.3, inplace=False)
      (linear1): Linear(in_features=128, out_features=128, bias=True)
      (linear2): Linear(in_features=128, out_features=128, bias=True)
      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (dropout2): Dropout(p=0.3, inplace=False)
    )
  )
)

Test Before Training: (HR@5:0.0525,NDCG@5:0.0305,HR@10:0.1051,NDCG@10:0.0473,HR@20:0.2032,NDCG@20:0.0718,HR@50:0.5077,NDCG@50:0.1313)
Optimizer: Adam

Epoch 1     loss=0.2450 [22.7 s]	dev=(HR@5:0.4528,NDCG@5:0.3128) [0.2 s] *

Epoch 2     loss=0.1540 [22.7 s]	dev=(HR@5:0.4988,NDCG@5:0.3455) [0.2 s] *

Epoch 3     loss=0.1337 [22.8 s]	dev=(HR@5:0.4949,NDCG@5:0.3482) [0.2 s] *

Epoch 4     loss=0.1240 [22.8 s]	dev=(HR@5:0.5160,NDCG@5:0.3620) [0.2 s] *

Epoch 5     loss=0.1182 [23.1 s]	dev=(HR@5:0.4914,NDCG@5:0.3546) [0.2 s]

Epoch 6     loss=0.1132 [23.1 s]	dev=(HR@5:0.5059,NDCG@5:0.3571) [0.2 s]

Epoch 7     loss=0.1086 [23.0 s]	dev=(HR@5:0.5031,NDCG@5:0.3576) [0.2 s]

Epoch 8     loss=0.1060 [22.7 s]	dev=(HR@5:0.5141,NDCG@5:0.3626) [0.2 s] *

Epoch 9     loss=0.1031 [23.0 s]	dev=(HR@5:0.5043,NDCG@5:0.3596) [0.2 s]

Epoch 10    loss=0.1010 [22.8 s]	dev=(HR@5:0.5285,NDCG@5:0.3766) [0.2 s] *

Epoch 11    loss=0.0985 [22.9 s]	dev=(HR@5:0.5281,NDCG@5:0.3781) [0.2 s] *

Epoch 12    loss=0.0971 [22.7 s]	dev=(HR@5:0.5187,NDCG@5:0.3738) [0.2 s]

Epoch 13    loss=0.0946 [22.5 s]	dev=(HR@5:0.5238,NDCG@5:0.3753) [0.2 s]

Epoch 14    loss=0.0931 [22.7 s]	dev=(HR@5:0.5203,NDCG@5:0.3734) [0.2 s]

Epoch 15    loss=0.0928 [23.1 s]	dev=(HR@5:0.5183,NDCG@5:0.3672) [0.2 s]

Epoch 16    loss=0.0921 [22.7 s]	dev=(HR@5:0.5285,NDCG@5:0.3774) [0.2 s]

Epoch 17    loss=0.0905 [23.3 s]	dev=(HR@5:0.5183,NDCG@5:0.3691) [0.2 s]

Epoch 18    loss=0.0891 [23.0 s]	dev=(HR@5:0.5234,NDCG@5:0.3720) [0.2 s]

Epoch 19    loss=0.0886 [22.9 s]	dev=(HR@5:0.5129,NDCG@5:0.3639) [0.2 s]

Epoch 20    loss=0.0879 [23.0 s]	dev=(HR@5:0.5207,NDCG@5:0.3711) [0.2 s]
Early stop at 20 based on dev result.

Best Iter(dev)=   11	 dev=(HR@5:0.5281,NDCG@5:0.3781) [461.9 s] 
Load model from ../model/SASRec/SASRec__MovieLens_1M__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.5281,NDCG@5:0.3781,HR@10:0.6749,NDCG@10:0.4258,HR@20:0.8068,NDCG@20:0.4593,HR@50:0.9559,NDCG@50:0.4892)

Test After Training: (HR@5:0.5344,NDCG@5:0.3948,HR@10:0.6775,NDCG@10:0.4409,HR@20:0.8159,NDCG@20:0.4760,HR@50:0.9582,NDCG@50:0.5046)
Saving top-100 recommendation results to: ../log/SASRec/SASRec__MovieLens_1M__0__lr=0/rec-SASRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/SASRec/SASRec__MovieLens_1M__0__lr=0/rec-SASRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 15:53:07 ---------------------------------------------
运行 GRU4Rec...
Namespace(model_name='GRU4Rec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 15:53:08 ---------------------------------------------

===================================
 Arguments          | Values       
===================================
 batch_size         | 256         
 data_appendix      |             
 dataset            | MovieLens_1M
 dropout            | 0.3         
 early_stop         | 10          
 emb_size           | 128         
 epoch              | 100         
 eval_batch_size    | 256         
 gpu                | 0           
 hidden_size        | 128         
 history_max        | 20          
 l2                 | 1e-05       
 lr                 | 0.0005      
 main_metric        |             
 num_neg            | 1           
 num_workers        | 5           
 optimizer          | Adam        
 random_seed        | 0           
 save_final_results | 1           
 test_all           | 0           
 topk               | 5,10,20,50  
===================================
Device: cuda
Load corpus from data/MovieLens_1M/SeqReader.pkl
#params: 515712
GRU4Rec(
  (i_embeddings): Embedding(3126, 128)
  (rnn): GRU(128, 128, batch_first=True)
  (out): Linear(in_features=128, out_features=128, bias=True)
)

Test Before Training: (HR@5:0.0393,NDCG@5:0.0236,HR@10:0.0929,NDCG@10:0.0408,HR@20:0.1910,NDCG@20:0.0652,HR@50:0.5052,NDCG@50:0.1268)
Optimizer: Adam

Epoch 1     loss=0.3144 [10.7 s]	dev=(HR@5:0.3770,NDCG@5:0.2502) [0.2 s] *

Epoch 2     loss=0.2460 [10.7 s]	dev=(HR@5:0.3891,NDCG@5:0.2628) [0.2 s] *

Epoch 3     loss=0.2113 [10.7 s]	dev=(HR@5:0.4219,NDCG@5:0.2838) [0.2 s] *

Epoch 4     loss=0.1916 [10.7 s]	dev=(HR@5:0.4305,NDCG@5:0.2989) [0.2 s] *

Epoch 5     loss=0.1750 [10.5 s]	dev=(HR@5:0.4422,NDCG@5:0.3074) [0.2 s] *

Epoch 6     loss=0.1619 [10.5 s]	dev=(HR@5:0.4637,NDCG@5:0.3191) [0.2 s] *

Epoch 7     loss=0.1522 [10.6 s]	dev=(HR@5:0.4696,NDCG@5:0.3263) [0.2 s] *

Epoch 8     loss=0.1451 [10.6 s]	dev=(HR@5:0.4809,NDCG@5:0.3331) [0.2 s] *

Epoch 9     loss=0.1389 [10.7 s]	dev=(HR@5:0.4762,NDCG@5:0.3292) [0.2 s]

Epoch 10    loss=0.1346 [10.5 s]	dev=(HR@5:0.4805,NDCG@5:0.3344) [0.2 s] *

Epoch 11    loss=0.1313 [10.5 s]	dev=(HR@5:0.4957,NDCG@5:0.3435) [0.2 s] *

Epoch 12    loss=0.1283 [10.5 s]	dev=(HR@5:0.4965,NDCG@5:0.3481) [0.2 s] *

Epoch 13    loss=0.1245 [10.6 s]	dev=(HR@5:0.5023,NDCG@5:0.3519) [0.2 s] *

Epoch 14    loss=0.1219 [10.6 s]	dev=(HR@5:0.5012,NDCG@5:0.3536) [0.2 s] *

Epoch 15    loss=0.1197 [10.5 s]	dev=(HR@5:0.5012,NDCG@5:0.3505) [0.2 s]

Epoch 16    loss=0.1180 [10.7 s]	dev=(HR@5:0.5051,NDCG@5:0.3556) [0.2 s] *

Epoch 17    loss=0.1142 [10.5 s]	dev=(HR@5:0.5023,NDCG@5:0.3520) [0.2 s]

Epoch 18    loss=0.1115 [10.4 s]	dev=(HR@5:0.5051,NDCG@5:0.3581) [0.2 s] *

Epoch 19    loss=0.1099 [10.6 s]	dev=(HR@5:0.5156,NDCG@5:0.3624) [0.2 s] *

Epoch 20    loss=0.1088 [10.6 s]	dev=(HR@5:0.5055,NDCG@5:0.3521) [0.2 s]

Epoch 21    loss=0.1065 [10.6 s]	dev=(HR@5:0.5137,NDCG@5:0.3643) [0.2 s] *

Epoch 22    loss=0.1047 [10.5 s]	dev=(HR@5:0.5121,NDCG@5:0.3569) [0.2 s]

Epoch 23    loss=0.1042 [10.5 s]	dev=(HR@5:0.5152,NDCG@5:0.3627) [0.2 s]

Epoch 24    loss=0.1030 [10.5 s]	dev=(HR@5:0.5133,NDCG@5:0.3582) [0.2 s]

Epoch 25    loss=0.1019 [10.6 s]	dev=(HR@5:0.5222,NDCG@5:0.3632) [0.2 s]

Epoch 26    loss=0.1011 [10.5 s]	dev=(HR@5:0.5117,NDCG@5:0.3621) [0.2 s]

Epoch 27    loss=0.1000 [10.7 s]	dev=(HR@5:0.5222,NDCG@5:0.3675) [0.2 s] *

Epoch 28    loss=0.0991 [10.6 s]	dev=(HR@5:0.5262,NDCG@5:0.3708) [0.2 s] *

Epoch 29    loss=0.0979 [10.7 s]	dev=(HR@5:0.5301,NDCG@5:0.3707) [0.2 s]

Epoch 30    loss=0.0971 [10.6 s]	dev=(HR@5:0.5234,NDCG@5:0.3695) [0.2 s]

Epoch 31    loss=0.0961 [10.6 s]	dev=(HR@5:0.5371,NDCG@5:0.3746) [0.2 s] *

Epoch 32    loss=0.0950 [10.7 s]	dev=(HR@5:0.5316,NDCG@5:0.3729) [0.2 s]

Epoch 33    loss=0.0941 [10.5 s]	dev=(HR@5:0.5222,NDCG@5:0.3702) [0.2 s]

Epoch 34    loss=0.0924 [10.5 s]	dev=(HR@5:0.5199,NDCG@5:0.3668) [0.2 s]

Epoch 35    loss=0.0937 [10.4 s]	dev=(HR@5:0.5164,NDCG@5:0.3653) [0.2 s]

Epoch 36    loss=0.0915 [10.5 s]	dev=(HR@5:0.5234,NDCG@5:0.3694) [0.2 s]

Epoch 37    loss=0.0925 [10.7 s]	dev=(HR@5:0.5269,NDCG@5:0.3744) [0.2 s]

Epoch 38    loss=0.0913 [10.6 s]	dev=(HR@5:0.5340,NDCG@5:0.3780) [0.2 s] *

Epoch 39    loss=0.0905 [10.5 s]	dev=(HR@5:0.5230,NDCG@5:0.3699) [0.2 s]

Epoch 40    loss=0.0892 [10.7 s]	dev=(HR@5:0.5234,NDCG@5:0.3739) [0.2 s]

Epoch 41    loss=0.0889 [10.5 s]	dev=(HR@5:0.5195,NDCG@5:0.3730) [0.2 s]

Epoch 42    loss=0.0898 [10.5 s]	dev=(HR@5:0.5386,NDCG@5:0.3815) [0.2 s] *

Epoch 43    loss=0.0892 [10.7 s]	dev=(HR@5:0.5125,NDCG@5:0.3630) [0.2 s]

Epoch 44    loss=0.0876 [10.4 s]	dev=(HR@5:0.5117,NDCG@5:0.3637) [0.2 s]

Epoch 45    loss=0.0872 [10.6 s]	dev=(HR@5:0.5258,NDCG@5:0.3739) [0.2 s]

Epoch 46    loss=0.0871 [10.6 s]	dev=(HR@5:0.5219,NDCG@5:0.3747) [0.2 s]

Epoch 47    loss=0.0864 [10.7 s]	dev=(HR@5:0.5308,NDCG@5:0.3751) [0.2 s]

Epoch 48    loss=0.0864 [10.6 s]	dev=(HR@5:0.5250,NDCG@5:0.3750) [0.2 s]

Epoch 49    loss=0.0855 [10.7 s]	dev=(HR@5:0.5183,NDCG@5:0.3644) [0.2 s]

Epoch 50    loss=0.0861 [10.3 s]	dev=(HR@5:0.5293,NDCG@5:0.3720) [0.2 s]

Epoch 51    loss=0.0850 [10.3 s]	dev=(HR@5:0.5265,NDCG@5:0.3768) [0.2 s]
Early stop at 51 based on dev result.

Best Iter(dev)=   42	 dev=(HR@5:0.5386,NDCG@5:0.3815) [550.5 s] 
Load model from ../model/GRU4Rec/GRU4Rec__MovieLens_1M__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.5386,NDCG@5:0.3815,HR@10:0.6760,NDCG@10:0.4258,HR@20:0.8173,NDCG@20:0.4616,HR@50:0.9567,NDCG@50:0.4896)

Test After Training: (HR@5:0.5327,NDCG@5:0.3890,HR@10:0.6823,NDCG@10:0.4371,HR@20:0.8205,NDCG@20:0.4719,HR@50:0.9537,NDCG@50:0.4986)
make dirs: ../log/GRU4Rec/GRU4Rec__MovieLens_1M__0__lr=0
Saving top-100 recommendation results to: ../log/GRU4Rec/GRU4Rec__MovieLens_1M__0__lr=0/rec-GRU4Rec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/GRU4Rec/GRU4Rec__MovieLens_1M__0__lr=0/rec-GRU4Rec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 16:02:22 ---------------------------------------------
运行 DreamRec...
Namespace(model_name='DreamRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 16:02:23 ---------------------------------------------

======================================
 Arguments             | Values       
======================================
 batch_size            | 256         
 ce_loss_weight        | 0.3         
 cfg_scale             | 1.0         
 data_appendix         |             
 dataset               | MovieLens_1M
 diffusion_loss_weight | 0.7         
 diffusion_steps       | 50          
 dropout               | 0.3         
 early_stop            | 10          
 emb_size              | 128         
 epoch                 | 100         
 eval_batch_size       | 256         
 gpu                   | 0           
 hidden_size           | 128         
 history_max           | 20          
 l2                    | 1e-05       
 lambda_uncertainty    | 0.001       
 lr                    | 0.0005      
 main_metric           |             
 noise_schedule        | linear      
 num_neg               | 1           
 num_workers           | 5           
 optimizer             | Adam        
 random_seed           | 0           
 rescale_timesteps     | False       
 save_final_results    | 1           
 schedule_sampler_name | uniform     
 test_all              | 0           
 topk                  | 5,10,20,50  
======================================
Device: cuda
Load corpus from data/MovieLens_1M/SeqReader.pkl
#params: 1190912
DreamRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(3127, 128, padding_idx=0)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (net): Diffu_xstart(
    (time_embed): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): SiLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
    )
    (norm_diffu_rep): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (mlp): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): SiLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=512, out_features=128, bias=True)
      (4): Linear(in_features=128, out_features=512, bias=True)
      (5): SiLU()
      (6): Dropout(p=0.3, inplace=False)
      (7): Linear(in_features=512, out_features=128, bias=True)
    )
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (ag_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): Sequential(
        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=128, out_features=512, bias=True)
        (2): SiLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=512, out_features=128, bias=True)
        (5): Dropout(p=0.3, inplace=False)
      )
      (1): Sequential(
        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=128, out_features=512, bias=True)
        (2): SiLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=512, out_features=128, bias=True)
        (5): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0445,NDCG@5:0.0264,HR@10:0.0926,NDCG@10:0.0416,HR@20:0.1924,NDCG@20:0.0666,HR@50:0.5108,NDCG@50:0.1288)
Optimizer: Adam

Epoch 1     loss=0.3322 [25.3 s]	dev=(HR@5:0.3653,NDCG@5:0.2378) [0.8 s] *

Epoch 2     loss=0.2825 [25.2 s]	dev=(HR@5:0.3532,NDCG@5:0.2320) [0.8 s]

Epoch 3     loss=0.2648 [25.3 s]	dev=(HR@5:0.3415,NDCG@5:0.2253) [0.8 s]

Epoch 4     loss=0.2549 [25.3 s]	dev=(HR@5:0.3302,NDCG@5:0.2202) [0.8 s]

Epoch 5     loss=0.2478 [25.2 s]	dev=(HR@5:0.3224,NDCG@5:0.2169) [0.8 s]

Epoch 6     loss=0.2406 [25.3 s]	dev=(HR@5:0.3064,NDCG@5:0.2059) [0.8 s]

Epoch 7     loss=0.2333 [25.3 s]	dev=(HR@5:0.2998,NDCG@5:0.2024) [0.8 s]

Epoch 8     loss=0.2281 [25.2 s]	dev=(HR@5:0.3033,NDCG@5:0.1998) [0.8 s]

Epoch 9     loss=0.2231 [25.0 s]	dev=(HR@5:0.2939,NDCG@5:0.1965) [0.8 s]

Epoch 10    loss=0.2198 [25.1 s]	dev=(HR@5:0.3314,NDCG@5:0.2205) [0.8 s]

Epoch 11    loss=0.2181 [25.2 s]	dev=(HR@5:0.3037,NDCG@5:0.2030) [0.8 s]
Early stop at 11 based on dev result.

Best Iter(dev)=    1	 dev=(HR@5:0.3653,NDCG@5:0.2378) [285.9 s] 
Load model from ../model/DreamRec/DreamRec__MovieLens_1M__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.3649,NDCG@5:0.2376,HR@10:0.5183,NDCG@10:0.2874,HR@20:0.7147,NDCG@20:0.3372,HR@50:0.9262,NDCG@50:0.3798)

Test After Training: (HR@5:0.3386,NDCG@5:0.2234,HR@10:0.5191,NDCG@10:0.2818,HR@20:0.7112,NDCG@20:0.3303,HR@50:0.9374,NDCG@50:0.3758)
make dirs: ../log/DreamRec/DreamRec__MovieLens_1M__0__lr=0
Saving top-100 recommendation results to: ../log/DreamRec/DreamRec__MovieLens_1M__0__lr=0/rec-DreamRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/DreamRec/DreamRec__MovieLens_1M__0__lr=0/rec-DreamRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 16:07:15 ---------------------------------------------
运行 DiffuRec...
Namespace(model_name='DiffuRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 16:07:16 ---------------------------------------------

======================================
 Arguments             | Values       
======================================
 batch_size            | 256         
 ce_loss_weight        | 0.3         
 cfg_scale             | 1.0         
 data_appendix         |             
 dataset               | MovieLens_1M
 diffusion_loss_weight | 0.7         
 diffusion_steps       | 50          
 dropout               | 0.3         
 early_stop            | 10          
 emb_size              | 128         
 epoch                 | 100         
 eval_batch_size       | 256         
 gpu                   | 1           
 hidden_size           | 128         
 history_max           | 20          
 independent           | False       
 l2                    | 1e-05       
 lambda_uncertainty    | 0.001       
 lr                    | 0.0005      
 main_metric           |             
 noise_schedule        | linear      
 num_neg               | 1           
 num_workers           | 5           
 optimizer             | Adam        
 random_seed           | 0           
 rescale_timesteps     | False       
 save_final_results    | 1           
 schedule_sampler_name | uniform     
 test_all              | 0           
 topk                  | 5,10,20,50  
======================================
Device: cpu
Load corpus from data/MovieLens_1M/SeqReader.pkl
#params: 1060352
DiffuRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(3127, 128, padding_idx=0)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (net): Diffu_xstart(
    (time_embed): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): SiLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
    )
    (transencoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (norm_diffu_rep): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0473,NDCG@5:0.0275,HR@10:0.0964,NDCG@10:0.0431,HR@20:0.1917,NDCG@20:0.0669,HR@50:0.4965,NDCG@50:0.1265)
Optimizer: Adam

Epoch 1     loss=0.3283 [177.8 s]	dev=(HR@5:0.3786,NDCG@5:0.2502) [15.4 s] *

Epoch 2     loss=0.2552 [183.0 s]	dev=(HR@5:0.3743,NDCG@5:0.2537) [16.0 s] *

Epoch 3     loss=0.2408 [181.3 s]	dev=(HR@5:0.3829,NDCG@5:0.2619) [15.2 s] *

Epoch 4     loss=0.2347 [181.3 s]	dev=(HR@5:0.3790,NDCG@5:0.2615) [14.7 s]

Epoch 5     loss=0.2290 [182.6 s]	dev=(HR@5:0.3907,NDCG@5:0.2694) [15.6 s] *

Epoch 6     loss=0.2231 [183.6 s]	dev=(HR@5:0.3860,NDCG@5:0.2662) [15.7 s]

Epoch 7     loss=0.2199 [181.8 s]	dev=(HR@5:0.3927,NDCG@5:0.2692) [15.1 s]

Epoch 8     loss=0.2165 [184.2 s]	dev=(HR@5:0.3806,NDCG@5:0.2609) [15.5 s]

Epoch 9     loss=0.2139 [184.5 s]	dev=(HR@5:0.3860,NDCG@5:0.2666) [15.3 s]

Epoch 10    loss=0.2115 [182.4 s]	dev=(HR@5:0.3825,NDCG@5:0.2635) [15.6 s]

Epoch 11    loss=0.2113 [184.5 s]	dev=(HR@5:0.3927,NDCG@5:0.2687) [15.5 s]

Epoch 12    loss=0.2087 [184.0 s]	dev=(HR@5:0.3841,NDCG@5:0.2657) [15.4 s]

Epoch 13    loss=0.2065 [183.9 s]	dev=(HR@5:0.3942,NDCG@5:0.2668) [15.2 s]

Epoch 14    loss=0.2058 [182.9 s]	dev=(HR@5:0.3856,NDCG@5:0.2633) [15.3 s]
Early stop at 14 based on dev result.

Best Iter(dev)=    5	 dev=(HR@5:0.3907,NDCG@5:0.2694) [2773.3 s] 
Load model from ../model/DiffuRec/DiffuRec__MovieLens_1M__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.3907,NDCG@5:0.2695,HR@10:0.5496,NDCG@10:0.3204,HR@20:0.7198,NDCG@20:0.3637,HR@50:0.9231,NDCG@50:0.4043)

Test After Training: (HR@5:0.3779,NDCG@5:0.2650,HR@10:0.5505,NDCG@10:0.3208,HR@20:0.7154,NDCG@20:0.3628,HR@50:0.9332,NDCG@50:0.4064)
make dirs: ../log/DiffuRec/DiffuRec__MovieLens_1M__0__lr=0
Saving top-100 recommendation results to: ../log/DiffuRec/DiffuRec__MovieLens_1M__0__lr=0/rec-DiffuRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/DiffuRec/DiffuRec__MovieLens_1M__0__lr=0/rec-DiffuRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 16:54:51 ---------------------------------------------
运行 ADRec...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 16:54:55 ---------------------------------------------

======================================
 Arguments             | Values       
======================================
 batch_size            | 256         
 ce_loss_weight        | 0.3         
 cfg_dropout_rate      | 0.1         
 cfg_scale             | 1.2         
 data_appendix         |             
 dataset               | MovieLens_1M
 diffusion_loss_weight | 0.7         
 diffusion_steps       | 50          
 dropout               | 0.3         
 early_stop            | 30          
 emb_size              | 128         
 epoch                 | 100         
 eval_batch_size       | 256         
 gpu                   | 0           
 hidden_size           | 128         
 history_max           | 20          
 independent_diffusion | False       
 l2                    | 1e-05       
 lambda_uncertainty    | 0.001       
 lr                    | 0.0005      
 main_metric           |             
 noise_schedule        | linear      
 num_blocks            | 4           
 num_neg               | 1           
 num_workers           | 5           
 optimizer             | Adam        
 pretrain_epochs       | 10          
 random_seed           | 0           
 rescale_timesteps     | False       
 save_final_results    | 1           
 test_all              | 0           
 topk                  | 5,10,20,50  
 training_stage        | stage1      
 warmup_epochs         | 5           
======================================
Device: cuda
Load corpus from data/MovieLens_1M/SeqReader.pkl
#params: 400384
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(3126, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0536,NDCG@5:0.0308,HR@10:0.1075,NDCG@10:0.0479,HR@20:0.2063,NDCG@20:0.0726,HR@50:0.4951,NDCG@50:0.1289)
Optimizer: Adam

Epoch 1     loss=0.2977 [20.2 s]	dev=(HR@5:0.4083,NDCG@5:0.2834) [2.2 s] *

Epoch 2     loss=0.2041 [20.0 s]	dev=(HR@5:0.4204,NDCG@5:0.2835) [2.2 s] *

Epoch 3     loss=0.1886 [20.2 s]	dev=(HR@5:0.4063,NDCG@5:0.2798) [2.2 s] *

Epoch 4     loss=0.1807 [20.1 s]	dev=(HR@5:0.4075,NDCG@5:0.2791) [2.2 s] *

Epoch 5     loss=0.1743 [20.1 s]	dev=(HR@5:0.4036,NDCG@5:0.2791) [2.2 s] *

Epoch 6     loss=0.1692 [20.2 s]	dev=(HR@5:0.4188,NDCG@5:0.2872) [2.2 s] *

Epoch 7     loss=0.1642 [20.2 s]	dev=(HR@5:0.4098,NDCG@5:0.2835) [2.2 s] *

Epoch 8     loss=0.1621 [20.0 s]	dev=(HR@5:0.4137,NDCG@5:0.2838) [2.2 s] *

Epoch 9     loss=0.1593 [20.0 s]	dev=(HR@5:0.4052,NDCG@5:0.2795) [2.2 s] *

Epoch 10    loss=0.1564 [20.1 s]	dev=(HR@5:0.4032,NDCG@5:0.2791) [2.2 s] *

Epoch 11    loss=0.1555 [20.0 s]	dev=(HR@5:0.4118,NDCG@5:0.2800) [2.2 s] *

Epoch 12    loss=0.1537 [20.2 s]	dev=(HR@5:0.4122,NDCG@5:0.2830) [2.2 s] *

Epoch 13    loss=0.1509 [20.3 s]	dev=(HR@5:0.4157,NDCG@5:0.2845) [2.2 s] *

Epoch 14    loss=0.1505 [20.4 s]	dev=(HR@5:0.4083,NDCG@5:0.2836) [2.3 s] *

Epoch 15    loss=0.1485 [20.1 s]	dev=(HR@5:0.4032,NDCG@5:0.2763) [2.2 s] *

Epoch 16    loss=0.1476 [20.1 s]	dev=(HR@5:0.4157,NDCG@5:0.2849) [2.2 s] *

Epoch 17    loss=0.1453 [20.1 s]	dev=(HR@5:0.4020,NDCG@5:0.2781) [2.2 s] *

Epoch 18    loss=0.1442 [20.5 s]	dev=(HR@5:0.4145,NDCG@5:0.2826) [2.2 s] *

Epoch 19    loss=0.1441 [20.1 s]	dev=(HR@5:0.4083,NDCG@5:0.2835) [2.2 s] *

Epoch 20    loss=0.1442 [20.2 s]	dev=(HR@5:0.4091,NDCG@5:0.2800) [2.2 s] *

Epoch 21    loss=0.1425 [20.1 s]	dev=(HR@5:0.4114,NDCG@5:0.2785) [2.2 s] *

Epoch 22    loss=0.1410 [20.0 s]	dev=(HR@5:0.4075,NDCG@5:0.2779) [2.2 s] *

Epoch 23    loss=0.1411 [20.0 s]	dev=(HR@5:0.4126,NDCG@5:0.2801) [2.2 s] *

Epoch 24    loss=0.1403 [20.1 s]	dev=(HR@5:0.4044,NDCG@5:0.2787) [2.2 s] *

Epoch 25    loss=0.1393 [20.1 s]	dev=(HR@5:0.4016,NDCG@5:0.2801) [2.2 s] *

Epoch 26    loss=0.1392 [20.2 s]	dev=(HR@5:0.4067,NDCG@5:0.2838) [2.2 s] *

Epoch 27    loss=0.1387 [20.2 s]	dev=(HR@5:0.4091,NDCG@5:0.2803) [2.2 s] *

Epoch 28    loss=0.1388 [20.1 s]	dev=(HR@5:0.4001,NDCG@5:0.2781) [2.2 s] *

Epoch 29    loss=0.1381 [20.1 s]	dev=(HR@5:0.4067,NDCG@5:0.2823) [2.2 s] *

Epoch 30    loss=0.1383 [20.2 s]	dev=(HR@5:0.4040,NDCG@5:0.2783) [2.2 s] *

Epoch 31    loss=0.1378 [20.2 s]	dev=(HR@5:0.4048,NDCG@5:0.2783) [2.2 s] *

Epoch 32    loss=0.1365 [20.2 s]	dev=(HR@5:0.4040,NDCG@5:0.2790) [2.2 s] *

Epoch 33    loss=0.1359 [20.2 s]	dev=(HR@5:0.4071,NDCG@5:0.2782) [2.2 s] *

Epoch 34    loss=0.1350 [20.1 s]	dev=(HR@5:0.4083,NDCG@5:0.2779) [2.2 s] *

Epoch 35    loss=0.1363 [20.0 s]	dev=(HR@5:0.4040,NDCG@5:0.2772) [2.2 s] *
Early stop at 35 based on dev result.

Best Iter(dev)=    6	 dev=(HR@5:0.4188,NDCG@5:0.2872) [783.0 s] 
Load model from ../model/ADRec/ADRec__MovieLens_1M__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.4040,NDCG@5:0.2772,HR@10:0.5570,NDCG@10:0.3270,HR@20:0.7291,NDCG@20:0.3703,HR@50:0.9251,NDCG@50:0.4097)

Test After Training: (HR@5:0.4245,NDCG@5:0.3041,HR@10:0.5675,NDCG@10:0.3502,HR@20:0.7342,NDCG@20:0.3925,HR@50:0.9269,NDCG@50:0.4313)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__MovieLens_1M__0__lr=0/rec-ADRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__MovieLens_1M__0__lr=0/rec-ADRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 17:08:12 ---------------------------------------------

2. 扩散模型对比实验
-------------------
运行 DreamRec...
Namespace(model_name='DreamRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 17:08:13 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_scale             | 1.0                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 10                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 schedule_sampler_name | uniform             
 test_all              | 0                   
 topk                  | 5,10,20,50          
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1906176
DreamRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8715, 128, padding_idx=0)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (net): Diffu_xstart(
    (time_embed): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): SiLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
    )
    (norm_diffu_rep): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (mlp): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): SiLU()
      (2): Dropout(p=0.3, inplace=False)
      (3): Linear(in_features=512, out_features=128, bias=True)
      (4): Linear(in_features=128, out_features=512, bias=True)
      (5): SiLU()
      (6): Dropout(p=0.3, inplace=False)
      (7): Linear(in_features=512, out_features=128, bias=True)
    )
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (ag_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): Sequential(
        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=128, out_features=512, bias=True)
        (2): SiLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=512, out_features=128, bias=True)
        (5): Dropout(p=0.3, inplace=False)
      )
      (1): Sequential(
        (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (1): Linear(in_features=128, out_features=512, bias=True)
        (2): SiLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=512, out_features=128, bias=True)
        (5): Dropout(p=0.3, inplace=False)
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0502,NDCG@5:0.0295,HR@10:0.1014,NDCG@10:0.0459,HR@20:0.2050,NDCG@20:0.0717,HR@50:0.4985,NDCG@50:0.1291)
Optimizer: Adam

Epoch 1     loss=0.5060 [5.2 s]	dev=(HR@5:0.2381,NDCG@5:0.1558) [3.5 s] *

Epoch 2     loss=0.4522 [5.1 s]	dev=(HR@5:0.2467,NDCG@5:0.1619) [3.5 s] *

Epoch 3     loss=0.4384 [5.1 s]	dev=(HR@5:0.2571,NDCG@5:0.1684) [3.5 s] *

Epoch 4     loss=0.4309 [5.1 s]	dev=(HR@5:0.2608,NDCG@5:0.1705) [3.5 s] *

Epoch 5     loss=0.4260 [5.1 s]	dev=(HR@5:0.2644,NDCG@5:0.1715) [3.5 s] *

Epoch 6     loss=0.4221 [5.1 s]	dev=(HR@5:0.2622,NDCG@5:0.1702) [3.5 s]

Epoch 7     loss=0.4195 [5.1 s]	dev=(HR@5:0.2654,NDCG@5:0.1728) [3.5 s] *

Epoch 8     loss=0.4203 [5.1 s]	dev=(HR@5:0.2611,NDCG@5:0.1695) [3.5 s]

Epoch 9     loss=0.4189 [5.1 s]	dev=(HR@5:0.2635,NDCG@5:0.1707) [3.5 s]

Epoch 10    loss=0.4177 [5.0 s]	dev=(HR@5:0.2603,NDCG@5:0.1684) [3.5 s]

Epoch 11    loss=0.4179 [5.1 s]	dev=(HR@5:0.2630,NDCG@5:0.1704) [3.6 s]

Epoch 12    loss=0.4171 [5.1 s]	dev=(HR@5:0.2650,NDCG@5:0.1708) [3.5 s]

Epoch 13    loss=0.4157 [5.1 s]	dev=(HR@5:0.2614,NDCG@5:0.1702) [3.5 s]

Epoch 14    loss=0.4143 [5.1 s]	dev=(HR@5:0.2653,NDCG@5:0.1723) [3.5 s]

Epoch 15    loss=0.4148 [5.1 s]	dev=(HR@5:0.2680,NDCG@5:0.1727) [3.5 s]

Epoch 16    loss=0.4154 [5.1 s]	dev=(HR@5:0.2636,NDCG@5:0.1706) [3.5 s]
Early stop at 16 based on dev result.

Best Iter(dev)=    7	 dev=(HR@5:0.2654,NDCG@5:0.1728) [138.1 s] 
Load model from ../model/DreamRec/DreamRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2654,NDCG@5:0.1728,HR@10:0.3942,NDCG@10:0.2142,HR@20:0.5340,NDCG@20:0.2495,HR@50:0.7348,NDCG@50:0.2893)

Test After Training: (HR@5:0.2261,NDCG@5:0.1425,HR@10:0.3438,NDCG@10:0.1805,HR@20:0.4759,NDCG@20:0.2139,HR@50:0.6861,NDCG@50:0.2556)
Saving top-100 recommendation results to: ../log/DreamRec/DreamRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DreamRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/DreamRec/DreamRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DreamRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 17:10:53 ---------------------------------------------
运行 DiffuRec...
Namespace(model_name='DiffuRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 17:10:54 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_scale             | 1.0                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 10                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 1                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent           | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 schedule_sampler_name | uniform             
 test_all              | 0                   
 topk                  | 5,10,20,50          
==============================================
Device: cpu
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1775616
DiffuRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8715, 128, padding_idx=0)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (net): Diffu_xstart(
    (time_embed): Sequential(
      (0): Linear(in_features=128, out_features=512, bias=True)
      (1): SiLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
    )
    (transencoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
    (norm_diffu_rep): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (dropout): Dropout(p=0.3, inplace=False)
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0480,NDCG@5:0.0281,HR@10:0.0975,NDCG@10:0.0438,HR@20:0.2001,NDCG@20:0.0695,HR@50:0.5024,NDCG@50:0.1285)
Optimizer: Adam

Epoch 1     loss=0.5168 [35.8 s]	dev=(HR@5:0.2378,NDCG@5:0.1552) [65.4 s] *

Epoch 2     loss=0.4515 [36.5 s]	dev=(HR@5:0.2426,NDCG@5:0.1587) [65.1 s] *

Epoch 3     loss=0.4342 [36.3 s]	dev=(HR@5:0.2567,NDCG@5:0.1683) [67.1 s] *

Epoch 4     loss=0.4218 [36.8 s]	dev=(HR@5:0.2671,NDCG@5:0.1747) [64.7 s] *

Epoch 5     loss=0.4125 [37.8 s]	dev=(HR@5:0.2650,NDCG@5:0.1738) [65.5 s]

Epoch 6     loss=0.4041 [38.6 s]	dev=(HR@5:0.2669,NDCG@5:0.1741) [66.7 s]

Epoch 7     loss=0.3986 [38.8 s]	dev=(HR@5:0.2650,NDCG@5:0.1747) [66.6 s] *

Epoch 8     loss=0.3959 [38.2 s]	dev=(HR@5:0.2643,NDCG@5:0.1731) [65.5 s]

Epoch 9     loss=0.3917 [37.3 s]	dev=(HR@5:0.2667,NDCG@5:0.1765) [65.5 s] *

Epoch 10    loss=0.3885 [37.2 s]	dev=(HR@5:0.2686,NDCG@5:0.1778) [65.2 s] *

Epoch 11    loss=0.3867 [36.9 s]	dev=(HR@5:0.2661,NDCG@5:0.1734) [63.6 s]

Epoch 12    loss=0.3834 [37.7 s]	dev=(HR@5:0.2676,NDCG@5:0.1766) [64.4 s]

Epoch 13    loss=0.3805 [38.4 s]	dev=(HR@5:0.2662,NDCG@5:0.1762) [63.4 s]

Epoch 14    loss=0.3794 [36.3 s]	dev=(HR@5:0.2671,NDCG@5:0.1773) [64.7 s]

Epoch 15    loss=0.3791 [37.8 s]	dev=(HR@5:0.2691,NDCG@5:0.1778) [63.0 s] *

Epoch 16    loss=0.3775 [37.5 s]	dev=(HR@5:0.2686,NDCG@5:0.1783) [63.7 s] *

Epoch 17    loss=0.3753 [38.1 s]	dev=(HR@5:0.2687,NDCG@5:0.1771) [64.3 s]

Epoch 18    loss=0.3757 [38.3 s]	dev=(HR@5:0.2690,NDCG@5:0.1785) [64.6 s] *

Epoch 19    loss=0.3732 [38.7 s]	dev=(HR@5:0.2685,NDCG@5:0.1791) [63.9 s] *

Epoch 20    loss=0.3748 [37.7 s]	dev=(HR@5:0.2662,NDCG@5:0.1781) [54.1 s]

Epoch 21    loss=0.3712 [27.1 s]	dev=(HR@5:0.2689,NDCG@5:0.1806) [49.1 s] *

Epoch 22    loss=0.3718 [27.1 s]	dev=(HR@5:0.2692,NDCG@5:0.1808) [49.1 s] *

Epoch 23    loss=0.3710 [27.2 s]	dev=(HR@5:0.2683,NDCG@5:0.1800) [49.0 s]

Epoch 24    loss=0.3714 [27.0 s]	dev=(HR@5:0.2695,NDCG@5:0.1808) [49.1 s] *

Epoch 25    loss=0.3691 [27.0 s]	dev=(HR@5:0.2670,NDCG@5:0.1797) [49.2 s]

Epoch 26    loss=0.3698 [26.8 s]	dev=(HR@5:0.2684,NDCG@5:0.1798) [49.0 s]

Epoch 27    loss=0.3696 [27.0 s]	dev=(HR@5:0.2671,NDCG@5:0.1793) [49.3 s]

Epoch 28    loss=0.3692 [26.9 s]	dev=(HR@5:0.2696,NDCG@5:0.1808) [49.2 s]

Epoch 29    loss=0.3701 [27.0 s]	dev=(HR@5:0.2707,NDCG@5:0.1804) [48.9 s]

Epoch 30    loss=0.3675 [27.1 s]	dev=(HR@5:0.2682,NDCG@5:0.1798) [49.1 s]

Epoch 31    loss=0.3687 [26.9 s]	dev=(HR@5:0.2725,NDCG@5:0.1825) [49.0 s] *

Epoch 32    loss=0.3689 [26.9 s]	dev=(HR@5:0.2701,NDCG@5:0.1798) [49.1 s]

Epoch 33    loss=0.3675 [26.8 s]	dev=(HR@5:0.2674,NDCG@5:0.1787) [49.0 s]

Epoch 34    loss=0.3674 [27.1 s]	dev=(HR@5:0.2679,NDCG@5:0.1794) [49.2 s]

Epoch 35    loss=0.3656 [27.0 s]	dev=(HR@5:0.2705,NDCG@5:0.1807) [49.0 s]

Epoch 36    loss=0.3659 [26.8 s]	dev=(HR@5:0.2689,NDCG@5:0.1817) [49.0 s]

Epoch 37    loss=0.3682 [27.2 s]	dev=(HR@5:0.2697,NDCG@5:0.1808) [49.1 s]

Epoch 38    loss=0.3677 [27.0 s]	dev=(HR@5:0.2729,NDCG@5:0.1832) [49.1 s] *

Epoch 39    loss=0.3665 [27.2 s]	dev=(HR@5:0.2705,NDCG@5:0.1821) [49.0 s]

Epoch 40    loss=0.3659 [26.9 s]	dev=(HR@5:0.2706,NDCG@5:0.1822) [49.1 s]

Epoch 41    loss=0.3672 [27.1 s]	dev=(HR@5:0.2692,NDCG@5:0.1805) [49.1 s]

Epoch 42    loss=0.3655 [27.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1829) [49.3 s]

Epoch 43    loss=0.3665 [27.2 s]	dev=(HR@5:0.2685,NDCG@5:0.1813) [51.5 s]

Epoch 44    loss=0.3663 [26.9 s]	dev=(HR@5:0.2682,NDCG@5:0.1806) [49.2 s]

Epoch 45    loss=0.3640 [26.9 s]	dev=(HR@5:0.2676,NDCG@5:0.1801) [49.1 s]

Epoch 46    loss=0.3661 [27.0 s]	dev=(HR@5:0.2650,NDCG@5:0.1782) [49.4 s]

Epoch 47    loss=0.3663 [27.2 s]	dev=(HR@5:0.2683,NDCG@5:0.1806) [49.2 s]
Early stop at 47 based on dev result.

Best Iter(dev)=   38	 dev=(HR@5:0.2729,NDCG@5:0.1832) [4095.5 s] 
Load model from ../model/DiffuRec/DiffuRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2730,NDCG@5:0.1832,HR@10:0.3943,NDCG@10:0.2222,HR@20:0.5303,NDCG@20:0.2566,HR@50:0.7340,NDCG@50:0.2969)

Test After Training: (HR@5:0.2302,NDCG@5:0.1503,HR@10:0.3430,NDCG@10:0.1867,HR@20:0.4705,NDCG@20:0.2190,HR@50:0.6802,NDCG@50:0.2605)
Saving top-100 recommendation results to: ../log/DiffuRec/DiffuRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DiffuRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/DiffuRec/DiffuRec__Grocery_and_Gourmet_Food__0__lr=0/rec-DiffuRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 18:23:33 ---------------------------------------------
运行 ADRec...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 18:23:35 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.0                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 2                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0557,NDCG@5:0.0321,HR@10:0.1028,NDCG@10:0.0472,HR@20:0.1988,NDCG@20:0.0712,HR@50:0.4894,NDCG@50:0.1278)
Optimizer: Adam

Epoch 1     loss=0.5530 [2.7 s]	dev=(HR@5:0.2402,NDCG@5:0.1570) [6.0 s] *

Epoch 2     loss=0.3603 [2.6 s]	dev=(HR@5:0.2635,NDCG@5:0.1772) [6.0 s] *

Epoch 3     loss=0.2612 [2.6 s]	dev=(HR@5:0.2703,NDCG@5:0.1874) [6.0 s] *

Epoch 4     loss=0.1932 [2.6 s]	dev=(HR@5:0.2684,NDCG@5:0.1877) [6.0 s] *

Epoch 5     loss=0.1459 [2.6 s]	dev=(HR@5:0.2712,NDCG@5:0.1905) [6.0 s] *

Epoch 6     loss=0.1146 [2.6 s]	dev=(HR@5:0.2665,NDCG@5:0.1864) [6.0 s] *

Epoch 7     loss=0.0922 [2.6 s]	dev=(HR@5:0.2693,NDCG@5:0.1879) [6.0 s] *

Epoch 8     loss=0.0771 [2.6 s]	dev=(HR@5:0.2682,NDCG@5:0.1877) [6.0 s] *

Epoch 9     loss=0.0653 [2.6 s]	dev=(HR@5:0.2638,NDCG@5:0.1851) [6.0 s] *

Epoch 10    loss=0.0576 [2.6 s]	dev=(HR@5:0.2620,NDCG@5:0.1842) [6.0 s] *

Epoch 11    loss=0.0508 [2.6 s]	dev=(HR@5:0.2633,NDCG@5:0.1848) [6.0 s] *

Epoch 12    loss=0.0456 [2.6 s]	dev=(HR@5:0.2668,NDCG@5:0.1878) [6.0 s] *

Epoch 13    loss=0.0424 [2.6 s]	dev=(HR@5:0.2629,NDCG@5:0.1849) [6.0 s] *

Epoch 14    loss=0.0395 [2.6 s]	dev=(HR@5:0.2671,NDCG@5:0.1880) [6.0 s] *

Epoch 15    loss=0.0385 [2.6 s]	dev=(HR@5:0.2648,NDCG@5:0.1865) [6.0 s] *

Epoch 16    loss=0.0350 [2.6 s]	dev=(HR@5:0.2677,NDCG@5:0.1869) [6.0 s] *

Epoch 17    loss=0.0334 [2.6 s]	dev=(HR@5:0.2663,NDCG@5:0.1872) [6.0 s] *

Epoch 18    loss=0.0321 [2.6 s]	dev=(HR@5:0.2737,NDCG@5:0.1901) [6.0 s] *

Epoch 19    loss=0.0309 [2.6 s]	dev=(HR@5:0.2665,NDCG@5:0.1877) [6.0 s] *

Epoch 20    loss=0.0303 [2.6 s]	dev=(HR@5:0.2701,NDCG@5:0.1886) [6.0 s] *

Epoch 21    loss=0.0288 [2.6 s]	dev=(HR@5:0.2731,NDCG@5:0.1895) [6.0 s] *

Epoch 22    loss=0.0272 [2.6 s]	dev=(HR@5:0.2740,NDCG@5:0.1906) [6.0 s] *

Epoch 23    loss=0.0273 [2.6 s]	dev=(HR@5:0.2738,NDCG@5:0.1911) [6.0 s] *

Epoch 24    loss=0.0260 [2.6 s]	dev=(HR@5:0.2736,NDCG@5:0.1905) [6.0 s] *

Epoch 25    loss=0.0272 [2.6 s]	dev=(HR@5:0.2718,NDCG@5:0.1880) [6.0 s] *

Epoch 26    loss=0.0258 [2.6 s]	dev=(HR@5:0.2695,NDCG@5:0.1866) [6.0 s] *

Epoch 27    loss=0.0248 [2.6 s]	dev=(HR@5:0.2719,NDCG@5:0.1894) [6.0 s] *

Epoch 28    loss=0.0254 [2.6 s]	dev=(HR@5:0.2699,NDCG@5:0.1887) [6.0 s] *

Epoch 29    loss=0.0247 [2.6 s]	dev=(HR@5:0.2664,NDCG@5:0.1852) [6.0 s] *

Epoch 30    loss=0.0243 [2.6 s]	dev=(HR@5:0.2708,NDCG@5:0.1881) [6.0 s] *

Epoch 31    loss=0.0240 [2.6 s]	dev=(HR@5:0.2700,NDCG@5:0.1871) [6.0 s] *

Epoch 32    loss=0.0243 [2.6 s]	dev=(HR@5:0.2672,NDCG@5:0.1859) [6.0 s] *

Epoch 33    loss=0.0230 [2.6 s]	dev=(HR@5:0.2691,NDCG@5:0.1864) [6.0 s] *

Epoch 34    loss=0.0232 [2.6 s]	dev=(HR@5:0.2688,NDCG@5:0.1879) [6.0 s] *

Epoch 35    loss=0.0232 [2.6 s]	dev=(HR@5:0.2739,NDCG@5:0.1895) [6.0 s] *

Epoch 36    loss=0.0228 [2.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1870) [6.0 s] *

Epoch 37    loss=0.0224 [2.6 s]	dev=(HR@5:0.2727,NDCG@5:0.1904) [6.0 s] *

Epoch 38    loss=0.0223 [2.6 s]	dev=(HR@5:0.2718,NDCG@5:0.1890) [6.0 s] *

Epoch 39    loss=0.0222 [2.6 s]	dev=(HR@5:0.2713,NDCG@5:0.1886) [6.0 s] *

Epoch 40    loss=0.0206 [2.6 s]	dev=(HR@5:0.2726,NDCG@5:0.1891) [6.0 s] *

Epoch 41    loss=0.0223 [2.6 s]	dev=(HR@5:0.2711,NDCG@5:0.1883) [6.0 s] *

Epoch 42    loss=0.0228 [2.6 s]	dev=(HR@5:0.2765,NDCG@5:0.1910) [6.0 s] *

Epoch 43    loss=0.0219 [2.6 s]	dev=(HR@5:0.2733,NDCG@5:0.1902) [6.0 s] *

Epoch 44    loss=0.0219 [2.6 s]	dev=(HR@5:0.2721,NDCG@5:0.1893) [6.0 s] *

Epoch 45    loss=0.0209 [2.6 s]	dev=(HR@5:0.2743,NDCG@5:0.1915) [6.0 s] *

Epoch 46    loss=0.0218 [2.6 s]	dev=(HR@5:0.2711,NDCG@5:0.1892) [6.0 s] *

Epoch 47    loss=0.0219 [2.6 s]	dev=(HR@5:0.2673,NDCG@5:0.1883) [6.0 s] *

Epoch 48    loss=0.0212 [2.6 s]	dev=(HR@5:0.2710,NDCG@5:0.1898) [6.0 s] *

Epoch 49    loss=0.0209 [2.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1908) [6.0 s] *

Epoch 50    loss=0.0216 [2.6 s]	dev=(HR@5:0.2722,NDCG@5:0.1903) [6.0 s] *

Epoch 51    loss=0.0205 [2.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1890) [6.0 s] *

Epoch 52    loss=0.0214 [2.6 s]	dev=(HR@5:0.2707,NDCG@5:0.1896) [6.0 s] *

Epoch 53    loss=0.0204 [2.6 s]	dev=(HR@5:0.2752,NDCG@5:0.1923) [6.0 s] *

Epoch 54    loss=0.0204 [2.6 s]	dev=(HR@5:0.2729,NDCG@5:0.1918) [6.0 s] *

Epoch 55    loss=0.0210 [2.6 s]	dev=(HR@5:0.2740,NDCG@5:0.1930) [6.0 s] *

Epoch 56    loss=0.0199 [2.6 s]	dev=(HR@5:0.2744,NDCG@5:0.1929) [6.0 s] *

Epoch 57    loss=0.0195 [2.6 s]	dev=(HR@5:0.2751,NDCG@5:0.1927) [6.0 s] *

Epoch 58    loss=0.0209 [2.6 s]	dev=(HR@5:0.2729,NDCG@5:0.1919) [6.0 s] *

Epoch 59    loss=0.0203 [2.6 s]	dev=(HR@5:0.2740,NDCG@5:0.1922) [6.0 s] *

Epoch 60    loss=0.0210 [2.6 s]	dev=(HR@5:0.2733,NDCG@5:0.1920) [6.0 s] *

Epoch 61    loss=0.0205 [2.6 s]	dev=(HR@5:0.2731,NDCG@5:0.1923) [6.0 s] *

Epoch 62    loss=0.0192 [2.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1902) [6.0 s] *

Epoch 63    loss=0.0196 [2.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1900) [6.0 s] *

Epoch 64    loss=0.0201 [2.6 s]	dev=(HR@5:0.2718,NDCG@5:0.1903) [6.0 s] *

Epoch 65    loss=0.0217 [2.6 s]	dev=(HR@5:0.2706,NDCG@5:0.1904) [6.0 s] *

Epoch 66    loss=0.0199 [2.6 s]	dev=(HR@5:0.2673,NDCG@5:0.1887) [6.0 s] *

Epoch 67    loss=0.0205 [2.6 s]	dev=(HR@5:0.2673,NDCG@5:0.1889) [6.0 s] *

Epoch 68    loss=0.0190 [2.6 s]	dev=(HR@5:0.2716,NDCG@5:0.1907) [6.0 s] *

Epoch 69    loss=0.0201 [2.6 s]	dev=(HR@5:0.2698,NDCG@5:0.1894) [6.0 s] *

Epoch 70    loss=0.0202 [2.6 s]	dev=(HR@5:0.2712,NDCG@5:0.1902) [6.0 s] *

Epoch 71    loss=0.0193 [2.6 s]	dev=(HR@5:0.2714,NDCG@5:0.1909) [6.0 s] *

Epoch 72    loss=0.0192 [2.6 s]	dev=(HR@5:0.2726,NDCG@5:0.1913) [6.0 s] *

Epoch 73    loss=0.0196 [2.6 s]	dev=(HR@5:0.2723,NDCG@5:0.1902) [6.0 s] *

Epoch 74    loss=0.0204 [2.6 s]	dev=(HR@5:0.2682,NDCG@5:0.1877) [6.0 s] *

Epoch 75    loss=0.0198 [2.6 s]	dev=(HR@5:0.2684,NDCG@5:0.1883) [6.0 s] *

Epoch 76    loss=0.0203 [2.6 s]	dev=(HR@5:0.2742,NDCG@5:0.1918) [6.0 s] *

Epoch 77    loss=0.0200 [2.6 s]	dev=(HR@5:0.2731,NDCG@5:0.1914) [6.0 s] *

Epoch 78    loss=0.0193 [2.6 s]	dev=(HR@5:0.2726,NDCG@5:0.1905) [6.0 s] *

Epoch 79    loss=0.0198 [2.6 s]	dev=(HR@5:0.2745,NDCG@5:0.1919) [6.0 s] *

Epoch 80    loss=0.0199 [2.6 s]	dev=(HR@5:0.2742,NDCG@5:0.1919) [6.0 s] *

Epoch 81    loss=0.0193 [2.6 s]	dev=(HR@5:0.2720,NDCG@5:0.1914) [6.0 s] *

Epoch 82    loss=0.0195 [2.6 s]	dev=(HR@5:0.2751,NDCG@5:0.1925) [6.0 s] *

Epoch 83    loss=0.0189 [2.6 s]	dev=(HR@5:0.2699,NDCG@5:0.1903) [6.0 s] *

Epoch 84    loss=0.0180 [2.6 s]	dev=(HR@5:0.2725,NDCG@5:0.1909) [6.0 s] *
Early stop at 84 based on dev result.

Best Iter(dev)=   55	 dev=(HR@5:0.2740,NDCG@5:0.1930) [721.7 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2725,NDCG@5:0.1909,HR@10:0.3732,NDCG@10:0.2234,HR@20:0.4893,NDCG@20:0.2527,HR@50:0.7057,NDCG@50:0.2954)

Test After Training: (HR@5:0.2417,NDCG@5:0.1689,HR@10:0.3347,NDCG@10:0.1989,HR@20:0.4453,NDCG@20:0.2267,HR@50:0.6653,NDCG@50:0.2700)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 18:36:11 ---------------------------------------------

3. 消融实验
------------
运行 ADRec (完整版)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 22:25:23 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 32                  
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 32                  
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 278912
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 32)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): SiLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
Test Before Training: (HR@5:0.0506,NDCG@5:0.0298,HR@10:0.1000,NDCG@10:0.0455,HR@20:0.2053,NDCG@20:0.0719,HR@50:0.5064,NDCG@50:0.1304)
Optimizer: Adam
Epoch 1     loss=0.6132 [2.3 s] dev=(HR@5:0.2211,NDCG@5:0.1404) [1.1 s] *                           
Epoch 2     loss=0.4592 [2.5 s] dev=(HR@5:0.2440,NDCG@5:0.1561) [1.2 s] *                           
Epoch 3     loss=0.3837 [2.4 s] dev=(HR@5:0.2576,NDCG@5:0.1677) [1.1 s] *                           
Epoch 4     loss=0.3367 [2.5 s] dev=(HR@5:0.2665,NDCG@5:0.1781) [1.1 s] *                           
Epoch 5     loss=0.2977 [2.2 s] dev=(HR@5:0.2719,NDCG@5:0.1855) [1.1 s] *                           
Epoch 6     loss=0.2653 [2.1 s] dev=(HR@5:0.2725,NDCG@5:0.1859) [1.1 s] *                           
Epoch 7     loss=0.2389 [2.2 s] dev=(HR@5:0.2723,NDCG@5:0.1883) [1.1 s] *                           
Epoch 8     loss=0.2168 [2.2 s] dev=(HR@5:0.2713,NDCG@5:0.1864) [1.1 s] *                           
Epoch 9     loss=0.1992 [2.2 s] dev=(HR@5:0.2661,NDCG@5:0.1845) [1.1 s] *                           
Epoch 10    loss=0.4891 [2.9 s] dev=(HR@5:0.2644,NDCG@5:0.1816) [1.1 s] *                           
Epoch 11    loss=0.4742 [2.8 s] dev=(HR@5:0.2616,NDCG@5:0.1790) [1.1 s] *                           
Epoch 12    loss=0.4658 [2.8 s] dev=(HR@5:0.2605,NDCG@5:0.1776) [1.1 s] *                           
Epoch 13    loss=0.4650 [2.9 s] dev=(HR@5:0.2597,NDCG@5:0.1765) [1.2 s] *                           
Epoch 14    loss=0.4641 [2.9 s] dev=(HR@5:0.2595,NDCG@5:0.1763) [1.1 s] *                           
Epoch 15    loss=0.4942 [3.3 s] dev=(HR@5:0.2609,NDCG@5:0.1758) [1.1 s] *                           
Epoch 16    loss=0.4574 [3.2 s] dev=(HR@5:0.2620,NDCG@5:0.1739) [1.1 s] *                           
Epoch 17    loss=0.4405 [3.3 s] dev=(HR@5:0.2688,NDCG@5:0.1787) [1.1 s] *                           
Epoch 18    loss=0.4360 [3.3 s] dev=(HR@5:0.2689,NDCG@5:0.1798) [1.1 s] *                           
Epoch 19    loss=0.4292 [3.3 s] dev=(HR@5:0.2730,NDCG@5:0.1832) [1.1 s] *                           
Epoch 20    loss=0.4275 [3.3 s] dev=(HR@5:0.2708,NDCG@5:0.1827) [1.1 s] *                           
Epoch 21    loss=0.4215 [3.2 s] dev=(HR@5:0.2686,NDCG@5:0.1808) [1.2 s] *                           
Epoch 22    loss=0.4210 [3.2 s] dev=(HR@5:0.2713,NDCG@5:0.1828) [1.1 s] *                           
Epoch 23    loss=0.4186 [3.3 s] dev=(HR@5:0.2710,NDCG@5:0.1815) [1.1 s] *                           
Epoch 24    loss=0.4189 [3.3 s] dev=(HR@5:0.2660,NDCG@5:0.1789) [1.2 s] *                           
Epoch 25    loss=0.4156 [3.7 s] dev=(HR@5:0.2666,NDCG@5:0.1778) [1.2 s] *                           
Epoch 26    loss=0.4147 [3.4 s] dev=(HR@5:0.2736,NDCG@5:0.1840) [1.1 s] *                           
Epoch 27    loss=0.4129 [3.3 s] dev=(HR@5:0.2672,NDCG@5:0.1766) [1.2 s] *                           
Epoch 28    loss=0.4130 [3.6 s] dev=(HR@5:0.2693,NDCG@5:0.1798) [1.4 s] *                           
Epoch 29    loss=0.4122 [3.8 s] dev=(HR@5:0.2719,NDCG@5:0.1814) [1.3 s] *                           
Epoch 30    loss=0.4104 [3.6 s] dev=(HR@5:0.2706,NDCG@5:0.1805) [1.2 s] *                           
Epoch 31    loss=0.4107 [3.4 s] dev=(HR@5:0.2743,NDCG@5:0.1826) [1.2 s] *                           
Epoch 32    loss=0.4108 [3.5 s] dev=(HR@5:0.2712,NDCG@5:0.1806) [1.2 s] *                           
Epoch 33    loss=0.4100 [3.2 s] dev=(HR@5:0.2736,NDCG@5:0.1835) [1.1 s] *                           
Epoch 34    loss=0.4077 [3.1 s] dev=(HR@5:0.2684,NDCG@5:0.1805) [1.2 s] *                           
Epoch 35    loss=0.4063 [3.4 s] dev=(HR@5:0.2693,NDCG@5:0.1793) [1.2 s] *                           
Epoch 36    loss=0.4067 [3.3 s] dev=(HR@5:0.2716,NDCG@5:0.1816) [1.1 s] *                           
Early stop at 36 based on dev result.

Best Iter(dev)=    7     dev=(HR@5:0.2723,NDCG@5:0.1883) [150.6 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=32.pt
                                                                                                    
Dev  After Training: (HR@5:0.2716,NDCG@5:0.1816,HR@10:0.3959,NDCG@10:0.2217,HR@20:0.5344,NDCG@20:0.2567,HR@50:0.7412,NDCG@50:0.2976)
                                                                                                    
Test After Training: (HR@5:0.2340,NDCG@5:0.1538,HR@10:0.3419,NDCG@10:0.1885,HR@20:0.4729,NDCG@20:0.2216,HR@50:0.6802,NDCG@50:0.2627)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!                                                                       
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!                                                                      

--------------------------------------------- END: 2025-12-23 22:28:04 ---------------------------------------------
运行 ADRec (去掉三阶段训练)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 22:44:54 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 20                  
 emb_size              | 32                  
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 32                  
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage3              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 337760
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 32)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=32, out_features=128, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=128, out_features=32, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=32, out_features=128, bias=True)
        (1): SiLU()
        (2): Linear(in_features=128, out_features=32, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=32, out_features=128, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=128, out_features=32, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
Test Before Training: (HR@5:0.0506,NDCG@5:0.0298,HR@10:0.1000,NDCG@10:0.0455,HR@20:0.2053,NDCG@20:0.0719,HR@50:0.5064,NDCG@50:0.1304)                                                                                                                                                                                             
Optimizer: Adam
Epoch 1     loss=0.5164 [4.0 s] dev=(HR@5:0.2389,NDCG@5:0.1552) [1.1 s] *                           
Epoch 2     loss=0.4520 [3.9 s] dev=(HR@5:0.2492,NDCG@5:0.1626) [1.2 s] *                           
Epoch 3     loss=0.4366 [4.1 s] dev=(HR@5:0.2538,NDCG@5:0.1672) [1.1 s] *                           
Epoch 4     loss=0.4278 [3.9 s] dev=(HR@5:0.2600,NDCG@5:0.1711) [1.2 s] *                           
Epoch 5     loss=0.4218 [3.9 s] dev=(HR@5:0.2619,NDCG@5:0.1711) [1.2 s]                             
Epoch 6     loss=0.4157 [3.9 s] dev=(HR@5:0.2656,NDCG@5:0.1719) [1.1 s] *                           
Epoch 7     loss=0.4135 [4.0 s] dev=(HR@5:0.2627,NDCG@5:0.1728) [1.2 s] *                           
Epoch 8     loss=0.4118 [3.9 s] dev=(HR@5:0.2619,NDCG@5:0.1707) [1.1 s]                             
Epoch 9     loss=0.4086 [3.9 s] dev=(HR@5:0.2639,NDCG@5:0.1717) [1.1 s]                             
Epoch 10    loss=0.4062 [3.9 s] dev=(HR@5:0.2642,NDCG@5:0.1722) [1.2 s]                             
Epoch 11    loss=0.4049 [3.8 s] dev=(HR@5:0.2641,NDCG@5:0.1718) [1.1 s]                             
Epoch 12    loss=0.4025 [4.0 s] dev=(HR@5:0.2665,NDCG@5:0.1753) [1.2 s] *                           
Epoch 13    loss=0.3998 [3.9 s] dev=(HR@5:0.2658,NDCG@5:0.1752) [1.1 s]                             
Epoch 14    loss=0.3987 [4.1 s] dev=(HR@5:0.2644,NDCG@5:0.1736) [1.2 s]                             
Epoch 15    loss=0.3980 [4.2 s] dev=(HR@5:0.2654,NDCG@5:0.1734) [1.3 s]                             
Epoch 16    loss=0.3957 [4.6 s] dev=(HR@5:0.2667,NDCG@5:0.1738) [1.3 s]                             
Epoch 17    loss=0.3931 [4.0 s] dev=(HR@5:0.2640,NDCG@5:0.1719) [1.2 s]                             
Epoch 18    loss=0.3934 [4.1 s] dev=(HR@5:0.2667,NDCG@5:0.1743) [1.2 s]                             
Epoch 19    loss=0.3912 [4.0 s] dev=(HR@5:0.2664,NDCG@5:0.1747) [1.2 s]                             
Epoch 20    loss=0.3931 [4.0 s] dev=(HR@5:0.2666,NDCG@5:0.1757) [1.2 s] *                           
Epoch 21    loss=0.3880 [4.1 s] dev=(HR@5:0.2643,NDCG@5:0.1739) [1.2 s]                             
Epoch 22    loss=0.3887 [4.0 s] dev=(HR@5:0.2675,NDCG@5:0.1766) [1.2 s] *                           
Epoch 23    loss=0.3880 [3.8 s] dev=(HR@5:0.2682,NDCG@5:0.1769) [1.2 s] *                           
Epoch 24    loss=0.3880 [3.9 s] dev=(HR@5:0.2646,NDCG@5:0.1738) [1.2 s]                             
Epoch 25    loss=0.3848 [3.9 s] dev=(HR@5:0.2659,NDCG@5:0.1761) [1.2 s]                             
Epoch 26    loss=0.3850 [3.9 s] dev=(HR@5:0.2665,NDCG@5:0.1777) [1.2 s] *                           
Epoch 27    loss=0.3849 [3.9 s] dev=(HR@5:0.2674,NDCG@5:0.1763) [1.1 s]                             
Epoch 28    loss=0.3840 [3.9 s] dev=(HR@5:0.2648,NDCG@5:0.1750) [1.1 s]                             
Epoch 29    loss=0.3851 [4.0 s] dev=(HR@5:0.2678,NDCG@5:0.1760) [1.1 s]                             
Epoch 30    loss=0.3822 [4.1 s] dev=(HR@5:0.2666,NDCG@5:0.1763) [1.1 s]                             
Epoch 31    loss=0.3826 [3.9 s] dev=(HR@5:0.2691,NDCG@5:0.1775) [1.1 s]                             
Epoch 32    loss=0.3830 [4.0 s] dev=(HR@5:0.2678,NDCG@5:0.1762) [1.1 s]                             
Epoch 33    loss=0.3825 [4.0 s] dev=(HR@5:0.2670,NDCG@5:0.1782) [1.1 s] *                           
Epoch 34    loss=0.3814 [3.9 s] dev=(HR@5:0.2650,NDCG@5:0.1752) [1.2 s]                             
Epoch 35    loss=0.3795 [3.9 s] dev=(HR@5:0.2689,NDCG@5:0.1774) [1.1 s]                             
Epoch 36    loss=0.3792 [4.0 s] dev=(HR@5:0.2700,NDCG@5:0.1792) [1.2 s] *                           
Epoch 37    loss=0.3817 [4.0 s] dev=(HR@5:0.2688,NDCG@5:0.1791) [1.2 s]                             
Epoch 38    loss=0.3807 [4.0 s] dev=(HR@5:0.2727,NDCG@5:0.1814) [1.2 s] *                           
Epoch 39    loss=0.3779 [4.1 s] dev=(HR@5:0.2677,NDCG@5:0.1783) [1.1 s]                             
Epoch 40    loss=0.3774 [3.9 s] dev=(HR@5:0.2694,NDCG@5:0.1800) [1.1 s]                             
Epoch 41    loss=0.3781 [3.9 s] dev=(HR@5:0.2662,NDCG@5:0.1776) [1.1 s]                             
Epoch 42    loss=0.3771 [3.9 s] dev=(HR@5:0.2701,NDCG@5:0.1793) [1.2 s]                             
Epoch 43    loss=0.3778 [3.9 s] dev=(HR@5:0.2671,NDCG@5:0.1784) [1.1 s]                             
Epoch 44    loss=0.3780 [4.0 s] dev=(HR@5:0.2651,NDCG@5:0.1766) [1.1 s]                             
Epoch 45    loss=0.3739 [4.0 s] dev=(HR@5:0.2665,NDCG@5:0.1776) [1.1 s]                             
Epoch 46    loss=0.3768 [4.0 s] dev=(HR@5:0.2689,NDCG@5:0.1802) [1.1 s]                             
Epoch 47    loss=0.3765 [3.9 s] dev=(HR@5:0.2687,NDCG@5:0.1794) [1.1 s]                             
Epoch 48    loss=0.3756 [3.9 s] dev=(HR@5:0.2684,NDCG@5:0.1787) [1.1 s]                             
Epoch 49    loss=0.3748 [4.0 s] dev=(HR@5:0.2689,NDCG@5:0.1792) [1.2 s]                             
Epoch 50    loss=0.3769 [4.0 s] dev=(HR@5:0.2682,NDCG@5:0.1785) [1.1 s]                             
Epoch 51    loss=0.3738 [3.8 s] dev=(HR@5:0.2684,NDCG@5:0.1794) [1.1 s]                             
Epoch 52    loss=0.3750 [3.9 s] dev=(HR@5:0.2697,NDCG@5:0.1804) [1.2 s]                             
Epoch 53    loss=0.3741 [3.9 s] dev=(HR@5:0.2695,NDCG@5:0.1796) [1.1 s]                             
Epoch 54    loss=0.3739 [3.9 s] dev=(HR@5:0.2694,NDCG@5:0.1806) [1.2 s]                             
Epoch 55    loss=0.3728 [4.0 s] dev=(HR@5:0.2697,NDCG@5:0.1796) [1.2 s]                             
Epoch 56    loss=0.3733 [3.8 s] dev=(HR@5:0.2671,NDCG@5:0.1782) [1.2 s]                             
Epoch 57    loss=0.3754 [3.9 s] dev=(HR@5:0.2715,NDCG@5:0.1803) [1.1 s]                             
Early stop at 57 based on dev result.

Best Iter(dev)=   38     dev=(HR@5:0.2727,NDCG@5:0.1814) [292.4 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=32.pt
                                                                                                    
Dev  After Training: (HR@5:0.2727,NDCG@5:0.1814,HR@10:0.3954,NDCG@10:0.2209,HR@20:0.5354,NDCG@20:0.2562,HR@50:0.7339,NDCG@50:0.2956)
                                                                                                    
Test After Training: (HR@5:0.2321,NDCG@5:0.1516,HR@10:0.3472,NDCG@10:0.1887,HR@20:0.4729,NDCG@20:0.2205,HR@50:0.6830,NDCG@50:0.2621)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!                                                                       
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!                                                                      

--------------------------------------------- END: 2025-12-23 22:49:57 ---------------------------------------------
==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | True                
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam

Epoch 1     loss=0.5518 [4.3 s]	dev=(HR@5:0.2363,NDCG@5:0.1543) [11.5 s] *

Epoch 2     loss=0.3598 [4.3 s]	dev=(HR@5:0.2621,NDCG@5:0.1773) [11.5 s] *

Epoch 3     loss=0.2607 [4.2 s]	dev=(HR@5:0.2678,NDCG@5:0.1854) [11.5 s] *

Epoch 4     loss=0.1930 [4.3 s]	dev=(HR@5:0.2694,NDCG@5:0.1877) [11.5 s] *

Epoch 5     loss=0.1454 [4.3 s]	dev=(HR@5:0.2699,NDCG@5:0.1885) [11.5 s] *

Epoch 6     loss=0.1129 [4.3 s]	dev=(HR@5:0.2650,NDCG@5:0.1857) [11.5 s] *

Epoch 7     loss=0.0917 [4.3 s]	dev=(HR@5:0.2663,NDCG@5:0.1879) [11.5 s] *

Epoch 8     loss=0.0765 [4.3 s]	dev=(HR@5:0.2637,NDCG@5:0.1850) [11.5 s] *

Epoch 9     loss=0.0651 [4.3 s]	dev=(HR@5:0.2632,NDCG@5:0.1841) [11.5 s] *

Epoch 10    loss=0.0582 [4.3 s]	dev=(HR@5:0.2626,NDCG@5:0.1840) [11.5 s] *

Epoch 11    loss=0.0505 [4.3 s]	dev=(HR@5:0.2595,NDCG@5:0.1828) [11.5 s] *

Epoch 12    loss=0.0454 [4.3 s]	dev=(HR@5:0.2658,NDCG@5:0.1857) [11.6 s] *

Epoch 13    loss=0.0428 [4.4 s]	dev=(HR@5:0.2622,NDCG@5:0.1845) [11.6 s] *

Epoch 14    loss=0.0407 [4.3 s]	dev=(HR@5:0.2654,NDCG@5:0.1845) [11.6 s] *

Epoch 15    loss=0.0380 [4.4 s]	dev=(HR@5:0.2644,NDCG@5:0.1819) [11.5 s] *

Epoch 16    loss=0.0355 [4.3 s]	dev=(HR@5:0.2633,NDCG@5:0.1836) [11.6 s] *

Epoch 17    loss=0.0329 [4.4 s]	dev=(HR@5:0.2637,NDCG@5:0.1841) [11.6 s] *

Epoch 18    loss=0.0329 [4.3 s]	dev=(HR@5:0.2626,NDCG@5:0.1816) [11.5 s] *

Epoch 19    loss=0.0307 [4.3 s]	dev=(HR@5:0.2637,NDCG@5:0.1840) [11.5 s] *

Epoch 20    loss=0.0306 [4.2 s]	dev=(HR@5:0.2664,NDCG@5:0.1851) [11.5 s] *

Epoch 21    loss=0.0292 [4.3 s]	dev=(HR@5:0.2667,NDCG@5:0.1842) [11.5 s] *

Epoch 22    loss=0.0276 [4.3 s]	dev=(HR@5:0.2710,NDCG@5:0.1872) [11.5 s] *

Epoch 23    loss=0.0273 [4.3 s]	dev=(HR@5:0.2697,NDCG@5:0.1864) [11.6 s] *

Epoch 24    loss=0.0277 [4.3 s]	dev=(HR@5:0.2736,NDCG@5:0.1885) [11.5 s] *

Epoch 25    loss=0.0269 [4.3 s]	dev=(HR@5:0.2702,NDCG@5:0.1855) [11.6 s] *

Epoch 26    loss=0.0257 [4.4 s]	dev=(HR@5:0.2682,NDCG@5:0.1849) [11.5 s] *

Epoch 27    loss=0.0263 [4.3 s]	dev=(HR@5:0.2698,NDCG@5:0.1871) [11.5 s] *

Epoch 28    loss=0.0255 [4.3 s]	dev=(HR@5:0.2702,NDCG@5:0.1850) [11.5 s] *

Epoch 29    loss=0.0242 [4.3 s]	dev=(HR@5:0.2718,NDCG@5:0.1858) [11.5 s] *

Epoch 30    loss=0.0245 [4.3 s]	dev=(HR@5:0.2710,NDCG@5:0.1856) [11.5 s] *

Epoch 31    loss=0.0240 [4.3 s]	dev=(HR@5:0.2695,NDCG@5:0.1865) [11.5 s] *

Epoch 32    loss=0.0243 [4.3 s]	dev=(HR@5:0.2672,NDCG@5:0.1859) [11.5 s] *

Epoch 33    loss=0.0239 [4.3 s]	dev=(HR@5:0.2672,NDCG@5:0.1859) [11.5 s] *

Epoch 34    loss=0.0227 [4.3 s]	dev=(HR@5:0.2687,NDCG@5:0.1856) [11.5 s] *
Early stop at 34 based on dev result.

Best Iter(dev)=    5	 dev=(HR@5:0.2699,NDCG@5:0.1885) [538.8 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2687,NDCG@5:0.1856,HR@10:0.3673,NDCG@10:0.2174,HR@20:0.4985,NDCG@20:0.2504,HR@50:0.7167,NDCG@50:0.2936)

Test After Training: (HR@5:0.2314,NDCG@5:0.1618,HR@10:0.3259,NDCG@10:0.1923,HR@20:0.4445,NDCG@20:0.2222,HR@50:0.6609,NDCG@50:0.2648)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 18:55:46 ---------------------------------------------

4. 超参数实验
--------------
运行 ADRec (T=5)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 18:55:47 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 5                   
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam

Epoch 1     loss=0.5519 [4.1 s]	dev=(HR@5:0.2348,NDCG@5:0.1532) [1.7 s] *

Epoch 2     loss=0.3595 [4.0 s]	dev=(HR@5:0.2613,NDCG@5:0.1767) [1.7 s] *

Epoch 3     loss=0.2605 [4.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1844) [1.6 s] *

Epoch 4     loss=0.1923 [4.1 s]	dev=(HR@5:0.2704,NDCG@5:0.1888) [1.6 s] *

Epoch 5     loss=0.1449 [4.2 s]	dev=(HR@5:0.2663,NDCG@5:0.1866) [1.7 s] *

Epoch 6     loss=0.1128 [4.1 s]	dev=(HR@5:0.2647,NDCG@5:0.1849) [1.6 s] *

Epoch 7     loss=0.0913 [4.2 s]	dev=(HR@5:0.2646,NDCG@5:0.1859) [1.6 s] *

Epoch 8     loss=0.0762 [4.7 s]	dev=(HR@5:0.2645,NDCG@5:0.1839) [1.7 s] *

Epoch 9     loss=0.0655 [4.2 s]	dev=(HR@5:0.2637,NDCG@5:0.1843) [1.6 s] *

Epoch 10    loss=0.0581 [4.2 s]	dev=(HR@5:0.2619,NDCG@5:0.1834) [1.6 s] *

Epoch 11    loss=0.0508 [4.1 s]	dev=(HR@5:0.2628,NDCG@5:0.1845) [1.7 s] *

Epoch 12    loss=0.0459 [4.1 s]	dev=(HR@5:0.2622,NDCG@5:0.1836) [1.7 s] *

Epoch 13    loss=0.0419 [4.1 s]	dev=(HR@5:0.2623,NDCG@5:0.1845) [1.6 s] *

Epoch 14    loss=0.0403 [4.2 s]	dev=(HR@5:0.2669,NDCG@5:0.1847) [1.7 s] *

Epoch 15    loss=0.0383 [4.3 s]	dev=(HR@5:0.2644,NDCG@5:0.1827) [1.7 s] *

Epoch 16    loss=0.0353 [4.2 s]	dev=(HR@5:0.2668,NDCG@5:0.1851) [1.7 s] *

Epoch 17    loss=0.0334 [4.1 s]	dev=(HR@5:0.2648,NDCG@5:0.1835) [1.7 s] *

Epoch 18    loss=0.0327 [4.2 s]	dev=(HR@5:0.2680,NDCG@5:0.1846) [1.6 s] *

Epoch 19    loss=0.0306 [4.1 s]	dev=(HR@5:0.2670,NDCG@5:0.1855) [1.6 s] *

Epoch 20    loss=0.0299 [4.1 s]	dev=(HR@5:0.2678,NDCG@5:0.1859) [1.6 s] *

Epoch 21    loss=0.0287 [4.1 s]	dev=(HR@5:0.2682,NDCG@5:0.1861) [1.6 s] *

Epoch 22    loss=0.0272 [4.1 s]	dev=(HR@5:0.2697,NDCG@5:0.1866) [1.6 s] *

Epoch 23    loss=0.0278 [4.1 s]	dev=(HR@5:0.2678,NDCG@5:0.1864) [1.6 s] *

Epoch 24    loss=0.0269 [4.1 s]	dev=(HR@5:0.2719,NDCG@5:0.1876) [1.6 s] *

Epoch 25    loss=0.0276 [4.1 s]	dev=(HR@5:0.2717,NDCG@5:0.1852) [1.6 s] *

Epoch 26    loss=0.0260 [4.1 s]	dev=(HR@5:0.2695,NDCG@5:0.1848) [1.6 s] *

Epoch 27    loss=0.0260 [4.1 s]	dev=(HR@5:0.2725,NDCG@5:0.1879) [1.6 s] *

Epoch 28    loss=0.0252 [4.2 s]	dev=(HR@5:0.2704,NDCG@5:0.1868) [1.6 s] *

Epoch 29    loss=0.0245 [4.1 s]	dev=(HR@5:0.2701,NDCG@5:0.1861) [1.6 s] *

Epoch 30    loss=0.0235 [4.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1868) [1.6 s] *

Epoch 31    loss=0.0240 [4.1 s]	dev=(HR@5:0.2701,NDCG@5:0.1869) [1.6 s] *

Epoch 32    loss=0.0240 [4.1 s]	dev=(HR@5:0.2698,NDCG@5:0.1863) [1.6 s] *

Epoch 33    loss=0.0240 [4.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1868) [1.6 s] *
Early stop at 33 based on dev result.

Best Iter(dev)=    4	 dev=(HR@5:0.2704,NDCG@5:0.1888) [191.7 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2703,NDCG@5:0.1868,HR@10:0.3776,NDCG@10:0.2213,HR@20:0.5034,NDCG@20:0.2530,HR@50:0.7153,NDCG@50:0.2949)

Test After Training: (HR@5:0.2419,NDCG@5:0.1664,HR@10:0.3354,NDCG@10:0.1966,HR@20:0.4482,NDCG@20:0.2249,HR@50:0.6624,NDCG@50:0.2671)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 18:59:12 ---------------------------------------------
运行 ADRec (T=10)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 18:59:13 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 10                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam

Epoch 1     loss=0.5518 [4.1 s]	dev=(HR@5:0.2365,NDCG@5:0.1542) [2.8 s] *

Epoch 2     loss=0.3598 [4.2 s]	dev=(HR@5:0.2621,NDCG@5:0.1778) [2.8 s] *

Epoch 3     loss=0.2604 [4.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1855) [2.7 s] *

Epoch 4     loss=0.1930 [4.1 s]	dev=(HR@5:0.2689,NDCG@5:0.1874) [2.7 s] *

Epoch 5     loss=0.1452 [4.1 s]	dev=(HR@5:0.2686,NDCG@5:0.1876) [2.7 s] *

Epoch 6     loss=0.1131 [4.1 s]	dev=(HR@5:0.2644,NDCG@5:0.1850) [2.7 s] *

Epoch 7     loss=0.0917 [4.1 s]	dev=(HR@5:0.2655,NDCG@5:0.1862) [2.7 s] *

Epoch 8     loss=0.0763 [4.1 s]	dev=(HR@5:0.2637,NDCG@5:0.1847) [2.7 s] *

Epoch 9     loss=0.0658 [4.1 s]	dev=(HR@5:0.2621,NDCG@5:0.1837) [2.7 s] *

Epoch 10    loss=0.0585 [4.0 s]	dev=(HR@5:0.2635,NDCG@5:0.1850) [2.8 s] *

Epoch 11    loss=0.0508 [4.1 s]	dev=(HR@5:0.2609,NDCG@5:0.1836) [2.8 s] *

Epoch 12    loss=0.0458 [4.1 s]	dev=(HR@5:0.2644,NDCG@5:0.1852) [2.7 s] *

Epoch 13    loss=0.0428 [4.0 s]	dev=(HR@5:0.2614,NDCG@5:0.1835) [2.7 s] *

Epoch 14    loss=0.0416 [4.1 s]	dev=(HR@5:0.2654,NDCG@5:0.1843) [2.7 s] *

Epoch 15    loss=0.0388 [4.1 s]	dev=(HR@5:0.2677,NDCG@5:0.1841) [2.7 s] *

Epoch 16    loss=0.0351 [4.1 s]	dev=(HR@5:0.2656,NDCG@5:0.1847) [2.7 s] *

Epoch 17    loss=0.0332 [4.1 s]	dev=(HR@5:0.2676,NDCG@5:0.1862) [2.7 s] *

Epoch 18    loss=0.0327 [4.1 s]	dev=(HR@5:0.2656,NDCG@5:0.1825) [2.7 s] *

Epoch 19    loss=0.0309 [4.1 s]	dev=(HR@5:0.2631,NDCG@5:0.1836) [2.7 s] *

Epoch 20    loss=0.0305 [4.1 s]	dev=(HR@5:0.2645,NDCG@5:0.1852) [2.7 s] *

Epoch 21    loss=0.0286 [4.1 s]	dev=(HR@5:0.2652,NDCG@5:0.1843) [2.7 s] *

Epoch 22    loss=0.0276 [4.1 s]	dev=(HR@5:0.2633,NDCG@5:0.1845) [2.7 s] *

Epoch 23    loss=0.0279 [4.1 s]	dev=(HR@5:0.2654,NDCG@5:0.1846) [2.8 s] *

Epoch 24    loss=0.0267 [4.1 s]	dev=(HR@5:0.2693,NDCG@5:0.1872) [2.8 s] *

Epoch 25    loss=0.0269 [4.1 s]	dev=(HR@5:0.2676,NDCG@5:0.1849) [2.7 s] *

Epoch 26    loss=0.0257 [4.1 s]	dev=(HR@5:0.2647,NDCG@5:0.1822) [2.8 s] *

Epoch 27    loss=0.0262 [4.1 s]	dev=(HR@5:0.2684,NDCG@5:0.1857) [2.8 s] *

Epoch 28    loss=0.0251 [4.2 s]	dev=(HR@5:0.2684,NDCG@5:0.1859) [2.7 s] *

Epoch 29    loss=0.0244 [4.1 s]	dev=(HR@5:0.2684,NDCG@5:0.1866) [2.7 s] *

Epoch 30    loss=0.0235 [4.1 s]	dev=(HR@5:0.2665,NDCG@5:0.1868) [2.8 s] *

Epoch 31    loss=0.0243 [4.1 s]	dev=(HR@5:0.2685,NDCG@5:0.1881) [2.7 s] *

Epoch 32    loss=0.0241 [4.1 s]	dev=(HR@5:0.2657,NDCG@5:0.1858) [2.7 s] *

Epoch 33    loss=0.0239 [4.1 s]	dev=(HR@5:0.2701,NDCG@5:0.1872) [2.8 s] *

Epoch 34    loss=0.0229 [4.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1864) [2.7 s] *

Epoch 35    loss=0.0231 [4.1 s]	dev=(HR@5:0.2691,NDCG@5:0.1854) [2.7 s] *

Epoch 36    loss=0.0223 [4.1 s]	dev=(HR@5:0.2695,NDCG@5:0.1859) [2.8 s] *

Epoch 37    loss=0.0221 [4.1 s]	dev=(HR@5:0.2712,NDCG@5:0.1875) [2.8 s] *

Epoch 38    loss=0.0229 [4.1 s]	dev=(HR@5:0.2678,NDCG@5:0.1849) [2.8 s] *

Epoch 39    loss=0.0226 [4.1 s]	dev=(HR@5:0.2695,NDCG@5:0.1864) [2.7 s] *

Epoch 40    loss=0.0209 [4.1 s]	dev=(HR@5:0.2710,NDCG@5:0.1874) [2.7 s] *

Epoch 41    loss=0.0216 [4.1 s]	dev=(HR@5:0.2716,NDCG@5:0.1883) [2.8 s] *

Epoch 42    loss=0.0220 [4.1 s]	dev=(HR@5:0.2704,NDCG@5:0.1872) [2.7 s] *

Epoch 43    loss=0.0221 [4.1 s]	dev=(HR@5:0.2702,NDCG@5:0.1865) [2.7 s] *

Epoch 44    loss=0.0218 [4.1 s]	dev=(HR@5:0.2690,NDCG@5:0.1844) [2.7 s] *

Epoch 45    loss=0.0206 [4.1 s]	dev=(HR@5:0.2715,NDCG@5:0.1853) [2.7 s] *

Epoch 46    loss=0.0231 [4.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1861) [2.7 s] *

Epoch 47    loss=0.0224 [4.1 s]	dev=(HR@5:0.2717,NDCG@5:0.1881) [2.7 s] *

Epoch 48    loss=0.0214 [4.2 s]	dev=(HR@5:0.2714,NDCG@5:0.1873) [2.7 s] *

Epoch 49    loss=0.0214 [4.1 s]	dev=(HR@5:0.2700,NDCG@5:0.1877) [2.7 s] *

Epoch 50    loss=0.0212 [4.1 s]	dev=(HR@5:0.2687,NDCG@5:0.1867) [2.7 s] *

Epoch 51    loss=0.0210 [4.1 s]	dev=(HR@5:0.2661,NDCG@5:0.1854) [2.7 s] *

Epoch 52    loss=0.0211 [4.0 s]	dev=(HR@5:0.2687,NDCG@5:0.1871) [2.8 s] *

Epoch 53    loss=0.0202 [4.1 s]	dev=(HR@5:0.2709,NDCG@5:0.1893) [2.8 s] *

Epoch 54    loss=0.0204 [4.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1881) [2.7 s] *

Epoch 55    loss=0.0193 [4.1 s]	dev=(HR@5:0.2721,NDCG@5:0.1889) [2.7 s] *

Epoch 56    loss=0.0203 [4.1 s]	dev=(HR@5:0.2712,NDCG@5:0.1889) [2.7 s] *

Epoch 57    loss=0.0199 [4.1 s]	dev=(HR@5:0.2725,NDCG@5:0.1879) [2.7 s] *

Epoch 58    loss=0.0204 [4.1 s]	dev=(HR@5:0.2716,NDCG@5:0.1869) [2.7 s] *

Epoch 59    loss=0.0193 [4.1 s]	dev=(HR@5:0.2716,NDCG@5:0.1870) [2.7 s] *

Epoch 60    loss=0.0209 [4.1 s]	dev=(HR@5:0.2688,NDCG@5:0.1869) [2.7 s] *

Epoch 61    loss=0.0205 [4.1 s]	dev=(HR@5:0.2676,NDCG@5:0.1854) [2.7 s] *

Epoch 62    loss=0.0193 [4.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1861) [2.7 s] *

Epoch 63    loss=0.0198 [4.1 s]	dev=(HR@5:0.2705,NDCG@5:0.1861) [2.7 s] *

Epoch 64    loss=0.0203 [4.1 s]	dev=(HR@5:0.2734,NDCG@5:0.1873) [2.7 s] *

Epoch 65    loss=0.0200 [4.0 s]	dev=(HR@5:0.2731,NDCG@5:0.1871) [2.7 s] *

Epoch 66    loss=0.0200 [4.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1865) [2.7 s] *

Epoch 67    loss=0.0195 [4.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1858) [2.8 s] *

Epoch 68    loss=0.0193 [4.0 s]	dev=(HR@5:0.2716,NDCG@5:0.1856) [2.7 s] *

Epoch 69    loss=0.0196 [4.1 s]	dev=(HR@5:0.2731,NDCG@5:0.1888) [2.7 s] *

Epoch 70    loss=0.0193 [4.1 s]	dev=(HR@5:0.2728,NDCG@5:0.1892) [2.7 s] *

Epoch 71    loss=0.0196 [4.1 s]	dev=(HR@5:0.2724,NDCG@5:0.1891) [2.7 s] *

Epoch 72    loss=0.0193 [4.0 s]	dev=(HR@5:0.2731,NDCG@5:0.1878) [2.7 s] *

Epoch 73    loss=0.0196 [4.1 s]	dev=(HR@5:0.2694,NDCG@5:0.1862) [2.7 s] *

Epoch 74    loss=0.0203 [4.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1860) [2.7 s] *

Epoch 75    loss=0.0195 [4.1 s]	dev=(HR@5:0.2743,NDCG@5:0.1883) [2.8 s] *

Epoch 76    loss=0.0199 [4.1 s]	dev=(HR@5:0.2752,NDCG@5:0.1897) [2.7 s] *

Epoch 77    loss=0.0198 [4.1 s]	dev=(HR@5:0.2752,NDCG@5:0.1895) [2.7 s] *

Epoch 78    loss=0.0194 [4.0 s]	dev=(HR@5:0.2759,NDCG@5:0.1895) [2.7 s] *

Epoch 79    loss=0.0195 [4.1 s]	dev=(HR@5:0.2757,NDCG@5:0.1898) [2.7 s] *

Epoch 80    loss=0.0198 [4.1 s]	dev=(HR@5:0.2736,NDCG@5:0.1896) [2.7 s] *

Epoch 81    loss=0.0190 [4.0 s]	dev=(HR@5:0.2699,NDCG@5:0.1869) [2.7 s] *

Epoch 82    loss=0.0199 [4.1 s]	dev=(HR@5:0.2726,NDCG@5:0.1881) [2.7 s] *

Epoch 83    loss=0.0192 [4.1 s]	dev=(HR@5:0.2725,NDCG@5:0.1880) [2.7 s] *

Epoch 84    loss=0.0189 [4.1 s]	dev=(HR@5:0.2744,NDCG@5:0.1898) [2.7 s] *

Epoch 85    loss=0.0192 [4.2 s]	dev=(HR@5:0.2753,NDCG@5:0.1902) [2.7 s] *

Epoch 86    loss=0.0200 [4.1 s]	dev=(HR@5:0.2736,NDCG@5:0.1891) [2.7 s] *

Epoch 87    loss=0.0190 [4.1 s]	dev=(HR@5:0.2737,NDCG@5:0.1890) [2.7 s] *

Epoch 88    loss=0.0189 [4.1 s]	dev=(HR@5:0.2720,NDCG@5:0.1887) [2.7 s] *

Epoch 89    loss=0.0180 [4.1 s]	dev=(HR@5:0.2729,NDCG@5:0.1882) [2.8 s] *

Epoch 90    loss=0.0190 [4.1 s]	dev=(HR@5:0.2746,NDCG@5:0.1889) [2.7 s] *

Epoch 91    loss=0.0193 [4.0 s]	dev=(HR@5:0.2730,NDCG@5:0.1885) [2.7 s] *

Epoch 92    loss=0.0183 [4.1 s]	dev=(HR@5:0.2730,NDCG@5:0.1878) [2.8 s] *

Epoch 93    loss=0.0198 [4.1 s]	dev=(HR@5:0.2744,NDCG@5:0.1902) [2.8 s] *

Epoch 94    loss=0.0187 [4.1 s]	dev=(HR@5:0.2719,NDCG@5:0.1891) [2.7 s] *

Epoch 95    loss=0.0192 [4.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1878) [2.7 s] *

Epoch 96    loss=0.0195 [4.1 s]	dev=(HR@5:0.2695,NDCG@5:0.1874) [2.8 s] *

Epoch 97    loss=0.0190 [4.1 s]	dev=(HR@5:0.2705,NDCG@5:0.1861) [2.7 s] *

Epoch 98    loss=0.0186 [4.1 s]	dev=(HR@5:0.2706,NDCG@5:0.1854) [2.8 s] *

Epoch 99    loss=0.0191 [4.2 s]	dev=(HR@5:0.2697,NDCG@5:0.1847) [2.8 s] *

Epoch 100   loss=0.0188 [4.1 s]	dev=(HR@5:0.2672,NDCG@5:0.1837) [2.7 s] *

Best Iter(dev)=   85	 dev=(HR@5:0.2753,NDCG@5:0.1902) [685.0 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2672,NDCG@5:0.1837,HR@10:0.3708,NDCG@10:0.2172,HR@20:0.4894,NDCG@20:0.2471,HR@50:0.7093,NDCG@50:0.2904)

Test After Training: (HR@5:0.2377,NDCG@5:0.1646,HR@10:0.3329,NDCG@10:0.1953,HR@20:0.4440,NDCG@20:0.2232,HR@50:0.6745,NDCG@50:0.2685)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 19:10:56 ---------------------------------------------
运行 ADRec (T=20)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 19:10:57 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 20                  
 dropout               | 0.3                 
 early_stop            | 30                  
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)

Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam

Epoch 1     loss=0.5520 [4.1 s]	dev=(HR@5:0.2364,NDCG@5:0.1541) [4.9 s] *

Epoch 2     loss=0.3598 [4.1 s]	dev=(HR@5:0.2624,NDCG@5:0.1772) [4.9 s] *

Epoch 3     loss=0.2608 [4.2 s]	dev=(HR@5:0.2657,NDCG@5:0.1841) [4.9 s] *

Epoch 4     loss=0.1932 [4.2 s]	dev=(HR@5:0.2668,NDCG@5:0.1868) [4.9 s] *

Epoch 5     loss=0.1456 [4.2 s]	dev=(HR@5:0.2648,NDCG@5:0.1866) [4.9 s] *

Epoch 6     loss=0.1130 [4.2 s]	dev=(HR@5:0.2637,NDCG@5:0.1848) [4.9 s] *

Epoch 7     loss=0.0915 [4.1 s]	dev=(HR@5:0.2632,NDCG@5:0.1852) [4.9 s] *

Epoch 8     loss=0.0765 [4.2 s]	dev=(HR@5:0.2628,NDCG@5:0.1842) [4.9 s] *

Epoch 9     loss=0.0653 [4.2 s]	dev=(HR@5:0.2612,NDCG@5:0.1827) [4.9 s] *

Epoch 10    loss=0.0579 [4.2 s]	dev=(HR@5:0.2629,NDCG@5:0.1839) [4.9 s] *

Epoch 11    loss=0.0503 [4.1 s]	dev=(HR@5:0.2573,NDCG@5:0.1823) [4.9 s] *

Epoch 12    loss=0.0453 [4.2 s]	dev=(HR@5:0.2609,NDCG@5:0.1830) [4.9 s] *

Epoch 13    loss=0.0427 [4.2 s]	dev=(HR@5:0.2620,NDCG@5:0.1852) [4.9 s] *

Epoch 14    loss=0.0405 [4.1 s]	dev=(HR@5:0.2657,NDCG@5:0.1855) [4.9 s] *

Epoch 15    loss=0.0378 [4.1 s]	dev=(HR@5:0.2614,NDCG@5:0.1818) [4.9 s] *

Epoch 16    loss=0.0352 [4.1 s]	dev=(HR@5:0.2640,NDCG@5:0.1835) [4.9 s] *

Epoch 17    loss=0.0335 [4.1 s]	dev=(HR@5:0.2649,NDCG@5:0.1834) [4.9 s] *

Epoch 18    loss=0.0329 [4.2 s]	dev=(HR@5:0.2671,NDCG@5:0.1845) [4.9 s] *

Epoch 19    loss=0.0305 [4.2 s]	dev=(HR@5:0.2662,NDCG@5:0.1841) [4.9 s] *

Epoch 20    loss=0.0303 [4.1 s]	dev=(HR@5:0.2635,NDCG@5:0.1844) [4.9 s] *

Epoch 21    loss=0.0281 [4.2 s]	dev=(HR@5:0.2664,NDCG@5:0.1850) [4.9 s] *

Epoch 22    loss=0.0269 [4.1 s]	dev=(HR@5:0.2659,NDCG@5:0.1842) [4.9 s] *

Epoch 23    loss=0.0270 [4.2 s]	dev=(HR@5:0.2680,NDCG@5:0.1849) [4.9 s] *

Epoch 24    loss=0.0273 [4.1 s]	dev=(HR@5:0.2694,NDCG@5:0.1866) [4.9 s] *

Epoch 25    loss=0.0269 [4.1 s]	dev=(HR@5:0.2682,NDCG@5:0.1868) [4.9 s] *

Epoch 26    loss=0.0257 [4.1 s]	dev=(HR@5:0.2691,NDCG@5:0.1858) [4.9 s] *

Epoch 27    loss=0.0259 [4.2 s]	dev=(HR@5:0.2676,NDCG@5:0.1861) [4.9 s] *

Epoch 28    loss=0.0256 [4.2 s]	dev=(HR@5:0.2688,NDCG@5:0.1852) [4.9 s] *

Epoch 29    loss=0.0245 [4.1 s]	dev=(HR@5:0.2703,NDCG@5:0.1868) [4.9 s] *

Epoch 30    loss=0.0251 [4.1 s]	dev=(HR@5:0.2677,NDCG@5:0.1855) [4.9 s] *

Epoch 31    loss=0.0242 [4.2 s]	dev=(HR@5:0.2697,NDCG@5:0.1882) [4.9 s] *

Epoch 32    loss=0.0231 [4.2 s]	dev=(HR@5:0.2685,NDCG@5:0.1874) [4.9 s] *

Epoch 33    loss=0.0238 [4.2 s]	dev=(HR@5:0.2697,NDCG@5:0.1858) [4.9 s] *

Epoch 34    loss=0.0228 [4.1 s]	dev=(HR@5:0.2658,NDCG@5:0.1846) [4.9 s] *

Epoch 35    loss=0.0229 [4.2 s]	dev=(HR@5:0.2678,NDCG@5:0.1867) [4.9 s] *

Epoch 36    loss=0.0225 [4.1 s]	dev=(HR@5:0.2667,NDCG@5:0.1856) [4.9 s] *

Epoch 37    loss=0.0224 [4.1 s]	dev=(HR@5:0.2666,NDCG@5:0.1858) [4.9 s] *

Epoch 38    loss=0.0225 [4.1 s]	dev=(HR@5:0.2662,NDCG@5:0.1853) [4.9 s] *

Epoch 39    loss=0.0225 [4.2 s]	dev=(HR@5:0.2646,NDCG@5:0.1846) [4.9 s] *

Epoch 40    loss=0.0207 [4.1 s]	dev=(HR@5:0.2689,NDCG@5:0.1853) [4.9 s] *

Epoch 41    loss=0.0217 [4.1 s]	dev=(HR@5:0.2680,NDCG@5:0.1850) [4.9 s] *

Epoch 42    loss=0.0226 [4.2 s]	dev=(HR@5:0.2689,NDCG@5:0.1847) [4.9 s] *

Epoch 43    loss=0.0222 [4.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1840) [4.9 s] *

Epoch 44    loss=0.0219 [4.1 s]	dev=(HR@5:0.2666,NDCG@5:0.1843) [4.9 s] *

Epoch 45    loss=0.0214 [4.1 s]	dev=(HR@5:0.2697,NDCG@5:0.1861) [4.9 s] *

Epoch 46    loss=0.0221 [4.2 s]	dev=(HR@5:0.2673,NDCG@5:0.1845) [4.9 s] *

Epoch 47    loss=0.0219 [4.1 s]	dev=(HR@5:0.2682,NDCG@5:0.1857) [4.9 s] *

Epoch 48    loss=0.0212 [4.2 s]	dev=(HR@5:0.2712,NDCG@5:0.1871) [4.9 s] *

Epoch 49    loss=0.0213 [4.1 s]	dev=(HR@5:0.2701,NDCG@5:0.1875) [4.9 s] *

Epoch 50    loss=0.0215 [4.1 s]	dev=(HR@5:0.2696,NDCG@5:0.1874) [4.9 s] *

Epoch 51    loss=0.0206 [4.1 s]	dev=(HR@5:0.2686,NDCG@5:0.1861) [4.9 s] *

Epoch 52    loss=0.0215 [4.1 s]	dev=(HR@5:0.2697,NDCG@5:0.1871) [4.9 s] *

Epoch 53    loss=0.0199 [4.1 s]	dev=(HR@5:0.2715,NDCG@5:0.1884) [4.9 s] *

Epoch 54    loss=0.0201 [4.2 s]	dev=(HR@5:0.2738,NDCG@5:0.1896) [4.9 s] *

Epoch 55    loss=0.0200 [4.1 s]	dev=(HR@5:0.2738,NDCG@5:0.1896) [4.9 s] *

Epoch 56    loss=0.0202 [4.1 s]	dev=(HR@5:0.2720,NDCG@5:0.1885) [4.9 s] *

Epoch 57    loss=0.0204 [4.1 s]	dev=(HR@5:0.2718,NDCG@5:0.1885) [4.9 s] *

Epoch 58    loss=0.0204 [4.1 s]	dev=(HR@5:0.2691,NDCG@5:0.1857) [4.9 s] *

Epoch 59    loss=0.0198 [4.1 s]	dev=(HR@5:0.2675,NDCG@5:0.1851) [4.9 s] *

Epoch 60    loss=0.0210 [4.2 s]	dev=(HR@5:0.2672,NDCG@5:0.1853) [5.0 s] *

Epoch 61    loss=0.0194 [4.1 s]	dev=(HR@5:0.2652,NDCG@5:0.1834) [4.9 s] *

Epoch 62    loss=0.0199 [4.2 s]	dev=(HR@5:0.2656,NDCG@5:0.1842) [4.9 s] *

Epoch 63    loss=0.0197 [4.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1852) [4.9 s] *

Epoch 64    loss=0.0199 [4.2 s]	dev=(HR@5:0.2660,NDCG@5:0.1850) [4.9 s] *

Epoch 65    loss=0.0207 [4.2 s]	dev=(HR@5:0.2671,NDCG@5:0.1843) [4.9 s] *

Epoch 66    loss=0.0196 [4.1 s]	dev=(HR@5:0.2689,NDCG@5:0.1858) [4.9 s] *

Epoch 67    loss=0.0202 [4.2 s]	dev=(HR@5:0.2665,NDCG@5:0.1845) [4.9 s] *

Epoch 68    loss=0.0199 [4.2 s]	dev=(HR@5:0.2683,NDCG@5:0.1849) [4.9 s] *

Epoch 69    loss=0.0202 [4.2 s]	dev=(HR@5:0.2674,NDCG@5:0.1855) [4.9 s] *

Epoch 70    loss=0.0197 [4.1 s]	dev=(HR@5:0.2695,NDCG@5:0.1873) [4.9 s] *

Epoch 71    loss=0.0199 [4.2 s]	dev=(HR@5:0.2693,NDCG@5:0.1868) [4.9 s] *

Epoch 72    loss=0.0193 [4.2 s]	dev=(HR@5:0.2685,NDCG@5:0.1854) [4.9 s] *

Epoch 73    loss=0.0196 [4.1 s]	dev=(HR@5:0.2665,NDCG@5:0.1838) [4.9 s] *

Epoch 74    loss=0.0199 [4.2 s]	dev=(HR@5:0.2676,NDCG@5:0.1848) [4.9 s] *

Epoch 75    loss=0.0195 [4.1 s]	dev=(HR@5:0.2671,NDCG@5:0.1846) [4.9 s] *

Epoch 76    loss=0.0197 [4.1 s]	dev=(HR@5:0.2704,NDCG@5:0.1869) [4.9 s] *

Epoch 77    loss=0.0191 [4.2 s]	dev=(HR@5:0.2710,NDCG@5:0.1876) [4.9 s] *

Epoch 78    loss=0.0187 [4.1 s]	dev=(HR@5:0.2715,NDCG@5:0.1877) [4.9 s] *

Epoch 79    loss=0.0199 [4.1 s]	dev=(HR@5:0.2731,NDCG@5:0.1882) [5.0 s] *

Epoch 80    loss=0.0199 [4.1 s]	dev=(HR@5:0.2711,NDCG@5:0.1869) [4.9 s] *

Epoch 81    loss=0.0189 [4.1 s]	dev=(HR@5:0.2682,NDCG@5:0.1854) [4.9 s] *

Epoch 82    loss=0.0194 [4.2 s]	dev=(HR@5:0.2716,NDCG@5:0.1878) [4.9 s] *

Epoch 83    loss=0.0194 [4.1 s]	dev=(HR@5:0.2691,NDCG@5:0.1867) [4.9 s] *
Early stop at 83 based on dev result.

Best Iter(dev)=   54	 dev=(HR@5:0.2738,NDCG@5:0.1896) [753.9 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt

Dev  After Training: (HR@5:0.2691,NDCG@5:0.1867,HR@10:0.3661,NDCG@10:0.2180,HR@20:0.4812,NDCG@20:0.2471,HR@50:0.7057,NDCG@50:0.2913)

Test After Training: (HR@5:0.2395,NDCG@5:0.1666,HR@10:0.3255,NDCG@10:0.1943,HR@20:0.4371,NDCG@20:0.2224,HR@50:0.6651,NDCG@50:0.2672)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv

dev Prediction results saved!
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv

test Prediction results saved!

--------------------------------------------- END: 2025-12-23 19:24:00 ---------------------------------------------
运行 ADRec (T=50)...
Namespace(model_name='ADRec', model_mode='')
--------------------------------------------- BEGIN: 2025-12-23 19:36:34 ---------------------------------------------

==============================================
 Arguments             | Values               
==============================================
 batch_size            | 256                 
 ce_loss_weight        | 0.3                 
 cfg_dropout_rate      | 0.1                 
 cfg_scale             | 1.2                 
 data_appendix         |                     
 dataset               | Grocery_and_Gourm...
 diffusion_loss_weight | 0.7                 
 diffusion_steps       | 50                  
 dropout               | 0.3                 
 early_stop            | 100                 
 emb_size              | 128                 
 epoch                 | 100                 
 eval_batch_size       | 256                 
 gpu                   | 0                   
 hidden_size           | 128                 
 history_max           | 20                  
 independent_diffusion | False               
 l2                    | 1e-05               
 lambda_uncertainty    | 0.001               
 lr                    | 0.0005              
 main_metric           |                     
 noise_schedule        | linear              
 num_blocks            | 4                   
 num_neg               | 1                   
 num_workers           | 5                   
 optimizer             | Adam                
 pretrain_epochs       | 10                  
 random_seed           | 0                   
 rescale_timesteps     | False               
 save_final_results    | 1                   
 test_all              | 0                   
 topk                  | 5,10,20,50          
 training_stage        | stage1              
 warmup_epochs         | 5                   
==============================================
Device: cuda
Load corpus from data/Grocery_and_Gourmet_Food/SeqReader.pkl
#params: 1115648
ADRec(
  (projection): Identity()
  (emb_projection): Identity()
  (i_embeddings): Embedding(8714, 128)
  (embed_dropout): Dropout(p=0.2, inplace=False)
  (hist_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (diffusion): DiffusionModule(
    (denoise_net): DenoisedModel(
      (decoder): TransformerEncoder(
        (layers): ModuleList(
          (0): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
          (1): Sequential(
            (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=128, out_features=512, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.1, inplace=False)
            (4): Linear(in_features=512, out_features=128, bias=True)
            (5): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (time_embed): Sequential(
        (0): Linear(in_features=128, out_features=512, bias=True)
        (1): SiLU()
        (2): Linear(in_features=512, out_features=128, bias=True)
      )
    )
    (condition_encoder): TransformerEncoder(
      (layers): ModuleList(
        (0): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (1): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (2): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
        (3): Sequential(
          (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (1): Linear(in_features=128, out_features=512, bias=True)
          (2): SiLU()
          (3): Dropout(p=0.3, inplace=False)
          (4): Linear(in_features=512, out_features=128, bias=True)
          (5): Dropout(p=0.3, inplace=False)
        )
      )
    )
  )
  (ce_loss): CrossEntropyLoss()
)
Test Before Training: (HR@5:0.0505,NDCG@5:0.0298,HR@10:0.0967,NDCG@10:0.0445,HR@20:0.1975,NDCG@20:0.0697,HR@50:0.5013,NDCG@50:0.1290)
Optimizer: Adam
Epoch 1     loss=0.5518 [4.3 s] dev=(HR@5:0.2363,NDCG@5:0.1543) [11.5 s] *                          
Epoch 2     loss=0.3598 [4.3 s] dev=(HR@5:0.2621,NDCG@5:0.1773) [11.5 s] *                          
Epoch 3     loss=0.2607 [4.3 s] dev=(HR@5:0.2678,NDCG@5:0.1854) [11.4 s] *                          
Epoch 4     loss=0.1930 [4.2 s] dev=(HR@5:0.2694,NDCG@5:0.1877) [11.5 s] *                          
Epoch 5     loss=0.1454 [4.2 s] dev=(HR@5:0.2699,NDCG@5:0.1885) [11.5 s] *                          
Epoch 6     loss=0.1129 [4.3 s] dev=(HR@5:0.2650,NDCG@5:0.1857) [11.5 s] *                          
Epoch 7     loss=0.0917 [4.3 s] dev=(HR@5:0.2663,NDCG@5:0.1879) [11.5 s] *                          
Epoch 8     loss=0.0765 [4.3 s] dev=(HR@5:0.2637,NDCG@5:0.1850) [11.5 s] *                          
Epoch 9     loss=0.0651 [4.2 s] dev=(HR@5:0.2632,NDCG@5:0.1841) [11.5 s] *                          
Epoch 10    loss=0.0582 [4.3 s] dev=(HR@5:0.2626,NDCG@5:0.1840) [11.5 s] *                          
Epoch 11    loss=0.0505 [4.3 s] dev=(HR@5:0.2595,NDCG@5:0.1828) [11.5 s] *                          
Epoch 12    loss=0.0454 [4.3 s] dev=(HR@5:0.2658,NDCG@5:0.1857) [11.4 s] *                          
Epoch 13    loss=0.0428 [4.2 s] dev=(HR@5:0.2622,NDCG@5:0.1845) [11.5 s] *                          
Epoch 14    loss=0.0407 [4.3 s] dev=(HR@5:0.2654,NDCG@5:0.1845) [11.5 s] *                          
Epoch 15    loss=0.0380 [4.2 s] dev=(HR@5:0.2644,NDCG@5:0.1819) [11.5 s] *                          
Epoch 16    loss=0.0355 [4.2 s] dev=(HR@5:0.2633,NDCG@5:0.1836) [11.5 s] *                          
Epoch 17    loss=0.0329 [4.3 s] dev=(HR@5:0.2637,NDCG@5:0.1841) [11.5 s] *                          
Epoch 18    loss=0.0329 [4.3 s] dev=(HR@5:0.2626,NDCG@5:0.1816) [11.5 s] *                          
Epoch 19    loss=0.0307 [4.3 s] dev=(HR@5:0.2637,NDCG@5:0.1840) [11.5 s] *                          
Epoch 20    loss=0.0306 [4.3 s] dev=(HR@5:0.2664,NDCG@5:0.1851) [11.5 s] *                          
Epoch 21    loss=0.0292 [4.3 s] dev=(HR@5:0.2667,NDCG@5:0.1842) [11.5 s] *                          
Epoch 22    loss=0.0276 [4.3 s] dev=(HR@5:0.2710,NDCG@5:0.1872) [11.5 s] *                          
Epoch 23    loss=0.0273 [4.3 s] dev=(HR@5:0.2697,NDCG@5:0.1864) [11.5 s] *                          
Epoch 24    loss=0.0277 [4.3 s] dev=(HR@5:0.2736,NDCG@5:0.1885) [11.4 s] *                          
Epoch 25    loss=0.0269 [4.3 s] dev=(HR@5:0.2702,NDCG@5:0.1855) [11.5 s] *                          
Epoch 26    loss=0.0257 [4.3 s] dev=(HR@5:0.2682,NDCG@5:0.1849) [11.5 s] *                          
Epoch 27    loss=0.0263 [4.3 s] dev=(HR@5:0.2698,NDCG@5:0.1871) [11.5 s] *                          
Epoch 28    loss=0.0255 [4.2 s] dev=(HR@5:0.2702,NDCG@5:0.1850) [11.5 s] *                          
Epoch 29    loss=0.0242 [4.3 s] dev=(HR@5:0.2718,NDCG@5:0.1858) [11.5 s] *                          
Epoch 30    loss=0.0245 [4.2 s] dev=(HR@5:0.2710,NDCG@5:0.1856) [11.5 s] *                          
Epoch 31    loss=0.0240 [4.3 s] dev=(HR@5:0.2695,NDCG@5:0.1865) [11.4 s] *                          
Epoch 32    loss=0.0243 [4.2 s] dev=(HR@5:0.2672,NDCG@5:0.1859) [11.5 s] *                          
Epoch 33    loss=0.0239 [4.2 s] dev=(HR@5:0.2672,NDCG@5:0.1859) [11.5 s] *                          
Epoch 34    loss=0.0227 [4.3 s] dev=(HR@5:0.2687,NDCG@5:0.1856) [11.5 s] *                          
Epoch 35    loss=0.0227 [4.2 s] dev=(HR@5:0.2677,NDCG@5:0.1859) [11.5 s] *                          
Epoch 36    loss=0.0223 [4.3 s] dev=(HR@5:0.2689,NDCG@5:0.1867) [11.5 s] *                          
Epoch 37    loss=0.0227 [4.3 s] dev=(HR@5:0.2706,NDCG@5:0.1879) [11.5 s] *                          
Epoch 38    loss=0.0228 [4.3 s] dev=(HR@5:0.2650,NDCG@5:0.1839) [11.5 s] *                          
Epoch 39    loss=0.0225 [4.2 s] dev=(HR@5:0.2670,NDCG@5:0.1843) [11.5 s] *                          
Epoch 40    loss=0.0209 [4.3 s] dev=(HR@5:0.2717,NDCG@5:0.1862) [11.5 s] *                          
Epoch 41    loss=0.0225 [4.3 s] dev=(HR@5:0.2695,NDCG@5:0.1855) [11.5 s] *                          
Epoch 42    loss=0.0229 [4.2 s] dev=(HR@5:0.2691,NDCG@5:0.1842) [11.5 s] *                          
Epoch 43    loss=0.0219 [4.2 s] dev=(HR@5:0.2683,NDCG@5:0.1853) [11.5 s] *                          
Epoch 44    loss=0.0215 [4.2 s] dev=(HR@5:0.2696,NDCG@5:0.1859) [11.5 s] *                          
Epoch 45    loss=0.0208 [4.2 s] dev=(HR@5:0.2710,NDCG@5:0.1877) [11.5 s] *                          
Epoch 46    loss=0.0219 [4.2 s] dev=(HR@5:0.2688,NDCG@5:0.1862) [11.5 s] *                          
Epoch 47    loss=0.0226 [4.2 s] dev=(HR@5:0.2693,NDCG@5:0.1866) [11.5 s] *                          
Epoch 48    loss=0.0214 [4.3 s] dev=(HR@5:0.2711,NDCG@5:0.1863) [11.4 s] *                          
Epoch 49    loss=0.0216 [4.2 s] dev=(HR@5:0.2743,NDCG@5:0.1892) [11.5 s] *                          
Epoch 50    loss=0.0210 [4.2 s] dev=(HR@5:0.2720,NDCG@5:0.1879) [11.5 s] *                          
Epoch 51    loss=0.0207 [4.2 s] dev=(HR@5:0.2713,NDCG@5:0.1876) [11.5 s] *                          
Epoch 52    loss=0.0206 [4.3 s] dev=(HR@5:0.2693,NDCG@5:0.1870) [11.5 s] *                          
Epoch 53    loss=0.0202 [4.3 s] dev=(HR@5:0.2736,NDCG@5:0.1885) [11.5 s] *                          
Epoch 54    loss=0.0203 [4.3 s] dev=(HR@5:0.2718,NDCG@5:0.1876) [11.4 s] *                          
Epoch 55    loss=0.0204 [4.2 s] dev=(HR@5:0.2704,NDCG@5:0.1876) [11.5 s] *                          
Epoch 56    loss=0.0193 [4.3 s] dev=(HR@5:0.2717,NDCG@5:0.1880) [11.5 s] *                          
Epoch 57    loss=0.0196 [4.3 s] dev=(HR@5:0.2740,NDCG@5:0.1889) [11.5 s] *                          
Epoch 58    loss=0.0202 [4.2 s] dev=(HR@5:0.2749,NDCG@5:0.1885) [11.5 s] *                          
Epoch 59    loss=0.0203 [4.3 s] dev=(HR@5:0.2740,NDCG@5:0.1891) [11.4 s] *                          
Epoch 60    loss=0.0209 [4.3 s] dev=(HR@5:0.2729,NDCG@5:0.1881) [11.5 s] *                          
Epoch 61    loss=0.0211 [4.2 s] dev=(HR@5:0.2730,NDCG@5:0.1878) [11.5 s] *                          
Epoch 62    loss=0.0202 [4.2 s] dev=(HR@5:0.2717,NDCG@5:0.1871) [11.5 s] *                          
Epoch 63    loss=0.0200 [4.3 s] dev=(HR@5:0.2737,NDCG@5:0.1879) [11.5 s] *                          
Epoch 64    loss=0.0204 [4.3 s] dev=(HR@5:0.2701,NDCG@5:0.1869) [11.5 s] *                          
Epoch 65    loss=0.0203 [4.3 s] dev=(HR@5:0.2707,NDCG@5:0.1875) [11.5 s] *                          
Epoch 66    loss=0.0194 [4.3 s] dev=(HR@5:0.2708,NDCG@5:0.1863) [11.5 s] *                          
Epoch 67    loss=0.0196 [4.3 s] dev=(HR@5:0.2687,NDCG@5:0.1868) [11.5 s] *                          
Epoch 68    loss=0.0200 [4.2 s] dev=(HR@5:0.2693,NDCG@5:0.1868) [11.4 s] *                          
Epoch 69    loss=0.0197 [4.3 s] dev=(HR@5:0.2685,NDCG@5:0.1861) [11.4 s] *                          
Epoch 70    loss=0.0200 [4.3 s] dev=(HR@5:0.2698,NDCG@5:0.1874) [11.5 s] *                          
Epoch 71    loss=0.0198 [4.3 s] dev=(HR@5:0.2723,NDCG@5:0.1900) [11.5 s] *                          
Epoch 72    loss=0.0191 [4.3 s] dev=(HR@5:0.2702,NDCG@5:0.1889) [11.5 s] *                          
Epoch 73    loss=0.0192 [4.3 s] dev=(HR@5:0.2737,NDCG@5:0.1896) [11.5 s] *                          
Epoch 74    loss=0.0197 [4.3 s] dev=(HR@5:0.2749,NDCG@5:0.1890) [11.5 s] *                          
Epoch 75    loss=0.0188 [4.2 s] dev=(HR@5:0.2756,NDCG@5:0.1901) [11.5 s] *                          
Epoch 76    loss=0.0203 [4.2 s] dev=(HR@5:0.2748,NDCG@5:0.1901) [11.5 s] *                          
Epoch 77    loss=0.0200 [4.3 s] dev=(HR@5:0.2726,NDCG@5:0.1890) [11.5 s] *                          
Epoch 78    loss=0.0186 [4.3 s] dev=(HR@5:0.2727,NDCG@5:0.1892) [11.5 s] *                          
Epoch 79    loss=0.0194 [4.4 s] dev=(HR@5:0.2744,NDCG@5:0.1905) [11.6 s] *                          
Epoch 80    loss=0.0199 [4.3 s] dev=(HR@5:0.2750,NDCG@5:0.1903) [11.6 s] *                          
Epoch 81    loss=0.0186 [4.3 s] dev=(HR@5:0.2766,NDCG@5:0.1910) [11.7 s] *                          
Epoch 82    loss=0.0187 [4.4 s] dev=(HR@5:0.2769,NDCG@5:0.1914) [11.7 s] *                          
Epoch 83    loss=0.0195 [4.3 s] dev=(HR@5:0.2775,NDCG@5:0.1921) [11.5 s] *                          
Epoch 84    loss=0.0191 [4.3 s] dev=(HR@5:0.2797,NDCG@5:0.1927) [11.5 s] *                          
Epoch 85    loss=0.0194 [4.3 s] dev=(HR@5:0.2766,NDCG@5:0.1915) [11.6 s] *                          
Epoch 86    loss=0.0197 [4.3 s] dev=(HR@5:0.2763,NDCG@5:0.1909) [11.6 s] *                          
Epoch 87    loss=0.0186 [4.3 s] dev=(HR@5:0.2727,NDCG@5:0.1890) [11.6 s] *                          
Epoch 88    loss=0.0183 [4.4 s] dev=(HR@5:0.2725,NDCG@5:0.1895) [11.6 s] *                          
Epoch 89    loss=0.0188 [4.3 s] dev=(HR@5:0.2731,NDCG@5:0.1887) [11.6 s] *                          
Epoch 90    loss=0.0188 [4.4 s] dev=(HR@5:0.2716,NDCG@5:0.1886) [11.7 s] *                          
Epoch 91    loss=0.0194 [4.4 s] dev=(HR@5:0.2703,NDCG@5:0.1878) [11.7 s] *                          
Epoch 92    loss=0.0186 [4.4 s] dev=(HR@5:0.2704,NDCG@5:0.1872) [11.5 s] *                          
Epoch 93    loss=0.0193 [4.3 s] dev=(HR@5:0.2718,NDCG@5:0.1878) [11.5 s] *                          
Epoch 94    loss=0.0193 [4.3 s] dev=(HR@5:0.2700,NDCG@5:0.1862) [11.5 s] *                          
Epoch 95    loss=0.0194 [4.2 s] dev=(HR@5:0.2676,NDCG@5:0.1849) [11.5 s] *                          
Epoch 96    loss=0.0191 [4.3 s] dev=(HR@5:0.2725,NDCG@5:0.1886) [11.5 s] *                          
Epoch 97    loss=0.0188 [4.2 s] dev=(HR@5:0.2721,NDCG@5:0.1886) [11.5 s] *                          
Epoch 98    loss=0.0194 [4.3 s] dev=(HR@5:0.2732,NDCG@5:0.1881) [11.5 s] *                          
Epoch 99    loss=0.0192 [4.3 s] dev=(HR@5:0.2732,NDCG@5:0.1879) [11.5 s] *                          
Epoch 100   loss=0.0189 [4.2 s] dev=(HR@5:0.2744,NDCG@5:0.1882) [11.5 s] *                          

Best Iter(dev)=   84     dev=(HR@5:0.2797,NDCG@5:0.1927) [1578.4 s] 
Load model from ../model/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0.0005__l2=1e-05__emb_size=128.pt
                                                                                                    
Dev  After Training: (HR@5:0.2744,NDCG@5:0.1882,HR@10:0.3718,NDCG@10:0.2198,HR@20:0.4853,NDCG@20:0.2483,HR@50:0.7064,NDCG@50:0.2918)
                                                                                                    
Test After Training: (HR@5:0.2393,NDCG@5:0.1661,HR@10:0.3319,NDCG@10:0.1960,HR@20:0.4373,NDCG@20:0.2226,HR@50:0.6669,NDCG@50:0.2678)
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-dev.csv
dev Prediction results saved!                                                                       
Saving top-100 recommendation results to: ../log/ADRec/ADRec__Grocery_and_Gourmet_Food__0__lr=0/rec-ADRec-test.csv
test Prediction results saved!                                                                      

--------------------------------------------- END: 2025-12-23 20:03:55 ---------------------------------------------

所有实验已完成！结果已保存到 logs/results/experiment_results.txt
